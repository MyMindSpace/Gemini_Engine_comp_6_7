{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cbf4f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Environment Setup Complete\n",
      "Project Root: c:\\Users\\Bhushan\\Desktop\n",
      "Component 5 Path: c:\\Users\\Bhushan\\Desktop\\comp5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any, Optional\n",
    "import traceback\n",
    "\n",
    "# Add project paths\n",
    "project_root = os.path.dirname(os.path.abspath(\"\"))\n",
    "sys.path.insert(0, project_root)\n",
    "comp5_path = os.path.join(project_root, 'comp5')\n",
    "#sys.path.insert(0, comp5_path)\n",
    "\n",
    "print(\"üîß Environment Setup Complete\")\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(f\"Component 5 Path: {comp5_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ddebbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Basic Imports...\n",
      "‚úÖ configu.settings imported successfully\n",
      "‚úÖ shared modules imported successfully\n",
      "‚úÖ Component 5 modules imported successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"üß™ Testing Basic Imports...\")\n",
    "\n",
    "try:\n",
    "    # Test configu import\n",
    "    from configu.settings import settings\n",
    "    print(\"‚úÖ configu.settings imported successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå configu.settings import failed: {e}\")\n",
    "\n",
    "try:\n",
    "    # Test shared imports\n",
    "    from shared.schemas import MemoryContext, UserProfile, EnhancedResponse\n",
    "    from shared.utils import get_logger, generate_correlation_id\n",
    "    print(\"‚úÖ shared modules imported successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå shared modules import failed: {e}\")\n",
    "\n",
    "try:\n",
    "    # Test Component 5 imports\n",
    "    from comp5.config.settings import LSTMConfig\n",
    "    from comp5.core.memory_manager import MemoryManager\n",
    "    print(\"‚úÖ Component 5 modules imported successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Component 5 modules import failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddf60bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† Testing Component 5 Bridge...\n",
      "‚úÖ Component5Bridge created successfully\n",
      "üìä Bridge initialized: False\n",
      "üìä Bridge stats: {'memories_retrieved': 0, 'memories_processed': 0, 'gate_decisions': 0, 'context_assemblies': 0, 'errors': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüß† Testing Component 5 Bridge...\")\n",
    "\n",
    "try:\n",
    "    from component6.comp5_interface import Component5Bridge\n",
    "    \n",
    "    # Create bridge instance\n",
    "    bridge = Component5Bridge()\n",
    "    print(\"‚úÖ Component5Bridge created successfully\")\n",
    "    \n",
    "    # Check initial state\n",
    "    print(f\"üìä Bridge initialized: {bridge._initialized}\")\n",
    "    print(f\"üìä Bridge stats: {bridge.stats}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Component5Bridge creation failed: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b220124f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç DEBUG: Component 5 Astra Configuration...\n",
      "üß™ Testing manual AstraDBConfig creation...\n",
      "üìä Raw env vars:\n",
      "   ASTRA_DB_API_ENDPOINT: 'https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com'\n",
      "   ASTRA_DB_TOKEN: 'AstraCS:zwwrMyRbmlev...'\n",
      "   KEYSPACE: 'memory_db'\n",
      "\n",
      "üß™ Testing AstraDBConfig.from_env()...\n",
      "‚úÖ AstraDBConfig.from_env() successful:\n",
      "   endpoint: 'https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com'\n",
      "   token: 'AstraCS:zwwrMyRbmlev...'\n",
      "   keyspace: 'memory_db'\n",
      "\n",
      "üß™ Testing manual AstraDBConfig creation...\n",
      "‚úÖ Manual AstraDBConfig successful:\n",
      "   endpoint: 'https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com'\n",
      "   token: 'AstraCS:zwwrMyRbmlev...'\n",
      "   keyspace: 'memory_db'\n",
      "\n",
      "üß™ Testing LSTMConfig creation...\n",
      "‚úÖ LSTMConfig created successfully:\n",
      "   astra endpoint: 'https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com'\n",
      "   astra token: 'AstraCS:zwwrMyRbmlev...'\n",
      "   astra keyspace: 'memory_db'\n",
      "\n",
      "üõ†Ô∏è MANUAL FIX: Creating working Astra config...\n",
      "‚úÖ Working Astra config created:\n",
      "   endpoint: https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com\n",
      "   keyspace: memory_db\n",
      "\n",
      "üß™ Testing bridge with fixed config...\n",
      "\n",
      "üîç Component 5 configuration debug completed!\n"
     ]
    }
   ],
   "source": [
    "# DEBUG CELL: Check Astra Configuration in Component 5\n",
    "import os\n",
    "print(\"üîç DEBUG: Component 5 Astra Configuration...\")\n",
    "\n",
    "# Check how Component 5 is creating the Astra config\n",
    "try:\n",
    "    from comp5.config.settings import LSTMConfig, AstraDBConfig\n",
    "    \n",
    "    # Test manual config creation\n",
    "    print(\"üß™ Testing manual AstraDBConfig creation...\")\n",
    "    \n",
    "    # Get environment variables directly\n",
    "    endpoint = os.getenv(\"ASTRA_DB_API_ENDPOINT\")\n",
    "    token = os.getenv(\"ASTRA_DB_TOKEN\")\n",
    "    keyspace = os.getenv(\"KEYSPACE\")\n",
    "    \n",
    "    print(f\"üìä Raw env vars:\")\n",
    "    print(f\"   ASTRA_DB_API_ENDPOINT: '{endpoint}'\")\n",
    "    print(f\"   ASTRA_DB_TOKEN: '{token[:20] if token else None}...'\")\n",
    "    print(f\"   KEYSPACE: '{keyspace}'\")\n",
    "    \n",
    "    # Test AstraDBConfig creation methods\n",
    "    print(\"\\nüß™ Testing AstraDBConfig.from_env()...\")\n",
    "    try:\n",
    "        astra_config = AstraDBConfig.from_env()\n",
    "        print(f\"‚úÖ AstraDBConfig.from_env() successful:\")\n",
    "        print(f\"   endpoint: '{astra_config.endpoint}'\")\n",
    "        print(f\"   token: '{astra_config.token[:20] if astra_config.token else None}...'\")\n",
    "        print(f\"   keyspace: '{astra_config.keyspace}'\")\n",
    "    except Exception as config_error:\n",
    "        print(f\"‚ùå AstraDBConfig.from_env() failed: {config_error}\")\n",
    "    \n",
    "    # Test manual AstraDBConfig creation\n",
    "    print(\"\\nüß™ Testing manual AstraDBConfig creation...\")\n",
    "    try:\n",
    "        manual_astra_config = AstraDBConfig(\n",
    "            endpoint=endpoint,\n",
    "            token=token,\n",
    "            keyspace=keyspace or \"default_keyspace\"\n",
    "        )\n",
    "        print(f\"‚úÖ Manual AstraDBConfig successful:\")\n",
    "        print(f\"   endpoint: '{manual_astra_config.endpoint}'\")\n",
    "        print(f\"   token: '{manual_astra_config.token[:20] if manual_astra_config.token else None}...'\")\n",
    "        print(f\"   keyspace: '{manual_astra_config.keyspace}'\")\n",
    "    except Exception as manual_error:\n",
    "        print(f\"‚ùå Manual AstraDBConfig failed: {manual_error}\")\n",
    "    \n",
    "    # Test full LSTMConfig creation\n",
    "    print(\"\\nüß™ Testing LSTMConfig creation...\")\n",
    "    try:\n",
    "        lstm_config = LSTMConfig()\n",
    "        print(f\"‚úÖ LSTMConfig created successfully:\")\n",
    "        print(f\"   astra endpoint: '{lstm_config.astra_db.endpoint}'\")\n",
    "        print(f\"   astra token: '{lstm_config.astra_db.token[:20] if lstm_config.astra_db.token else None}...'\")\n",
    "        print(f\"   astra keyspace: '{lstm_config.astra_db.keyspace}'\")\n",
    "    except Exception as lstm_error:\n",
    "        print(f\"‚ùå LSTMConfig creation failed: {lstm_error}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Configuration debug failed: {e}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FIX: Create Working Astra Config for Component 5 Bridge\n",
    "# ============================================================================\n",
    "print(\"\\nüõ†Ô∏è MANUAL FIX: Creating working Astra config...\")\n",
    "\n",
    "try:\n",
    "    # Create a working configuration manually\n",
    "    from comp5.config.settings import AstraDBConfig, LSTMConfig\n",
    "    \n",
    "    # Force correct values\n",
    "    working_astra_config = AstraDBConfig(\n",
    "        endpoint=\"https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com\",\n",
    "        token=os.getenv(\"ASTRA_DB_TOKEN\"),\n",
    "        keyspace=\"memory_db\"\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Working Astra config created:\")\n",
    "    print(f\"   endpoint: {working_astra_config.endpoint}\")\n",
    "    print(f\"   keyspace: {working_astra_config.keyspace}\")\n",
    "    \n",
    "    # Test if we can create a new bridge with this config\n",
    "    print(\"\\nüß™ Testing bridge with fixed config...\")\n",
    "    \n",
    "    # Modify the bridge's config\n",
    "    if 'bridge' in locals() and bridge.config:\n",
    "        bridge.config.astra_db = working_astra_config\n",
    "        print(\"‚úÖ Bridge config updated with working Astra settings\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Manual fix failed: {e}\")\n",
    "\n",
    "print(\"\\nüîç Component 5 configuration debug completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c2054a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:15:10,339 - gemini_engine.component5_bridge - INFO - üöÄ Initializing Component 5 LSTM Memory Gates...\n",
      "2025-09-04 17:15:10,342 - comp5.core.memory_manager - INFO - Initializing Memory Manager...\n",
      "2025-09-04 17:15:10,342 - database.astra_connector - INFO - Connecting to Astra DB: https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Initializing Component 5 Bridge...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:15:10,545 - astrapy.data.database - INFO - findCollections\n",
      "2025-09-04 17:15:11,848 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 17:15:11,849 - astrapy.data.database - INFO - finished findCollections\n",
      "2025-09-04 17:15:11,849 - database.astra_connector - INFO - Found collections: []\n",
      "2025-09-04 17:15:13,110 - database.astra_connector - INFO - Successfully connected to Astra DB\n",
      "2025-09-04 17:15:13,112 - comp5.core.memory_manager - INFO - No existing gate network found, using fresh model\n",
      "2025-09-04 17:15:13,113 - comp5.core.memory_manager - INFO - Memory Manager initialized successfully\n",
      "2025-09-04 17:15:13,113 - gemini_engine.component5_bridge - INFO - ‚úÖ Component 5 LSTM system initialized successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Component 5 Bridge initialized successfully\n",
      "üìä Memory Manager: True\n",
      "üìä Gate Network: True\n",
      "üìä Bridge Statistics: {\n",
      "  \"bridge_stats\": {\n",
      "    \"memories_retrieved\": 0,\n",
      "    \"memories_processed\": 0,\n",
      "    \"gate_decisions\": 0,\n",
      "    \"context_assemblies\": 0,\n",
      "    \"errors\": 0\n",
      "  },\n",
      "  \"initialized\": true,\n",
      "  \"memory_manager_stats\": {\n",
      "    \"memory_cache_size\": 0,\n",
      "    \"gate_network_available\": true,\n",
      "    \"db_connector_available\": true,\n",
      "    \"memory_store_available\": true\n",
      "  },\n",
      "  \"memory_manager_available\": true,\n",
      "  \"gate_network_available\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüöÄ Initializing Component 5 Bridge...\")\n",
    "\n",
    "try:\n",
    "    # Initialize the bridge (async call)\n",
    "    init_success = await bridge.initialize()\n",
    "    \n",
    "    if init_success:\n",
    "        print(\"‚úÖ Component 5 Bridge initialized successfully\")\n",
    "        print(f\"üìä Memory Manager: {bridge.memory_manager is not None}\")\n",
    "        print(f\"üìä Gate Network: {bridge.gate_network is not None}\")\n",
    "        \n",
    "        # Get statistics safely\n",
    "        try:\n",
    "            stats = bridge.get_statistics()\n",
    "            print(f\"üìä Bridge Statistics: {json.dumps(stats, indent=2, default=str)}\")\n",
    "        except Exception as stats_error:\n",
    "            print(f\"‚ö†Ô∏è  Could not get full statistics: {stats_error}\")\n",
    "            print(f\"üìä Basic Status: Initialized={bridge._initialized}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Component 5 Bridge initialization failed\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Component 5 Bridge initialization error: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")\n",
    "    \n",
    "    # Check if it's just a database connection issue\n",
    "    if \"Astra DB\" in str(e) or \"Request URL\" in str(e):\n",
    "        print(\"‚ÑπÔ∏è  This appears to be an Astra DB connection issue.\")\n",
    "        print(\"‚ÑπÔ∏è  The LSTM gates may still work for testing with mock data.\")\n",
    "        print(\"‚ÑπÔ∏è  Check your ASTRA_DB_API_ENDPOINT and ASTRA_DB_TOKEN in .env file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3721e206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä ASTRA_DB_API_ENDPOINT: 'https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com'\n",
      "üìä ASTRA_DB_TOKEN: 'AstraCS:zwwrMyRbmlev...' (truncated)\n",
      "üìä KEYSPACE: 'memory_db'\n",
      "üìä .env file exists: True\n",
      "üìä .env file path: c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\.env\n",
      "üìä First 10 lines of .env file:\n",
      "\n",
      "üîç All environment variables containing 'ASTRA':\n",
      "   ASTRA_COLLECTION: memory_embeddings...\n",
      "   ASTRA_DB_API_ENDPOINT: https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-ea...\n",
      "   ASTRA_DB_TOKEN: AstraCS:zwwrMyRbmlevzBlrKlCkxrDR:c561c306f3a1806fc...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Reload environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Check what's actually being read\n",
    "astra_endpoint = os.getenv(\"ASTRA_DB_API_ENDPOINT\")\n",
    "astra_token = os.getenv(\"ASTRA_DB_TOKEN\") \n",
    "keyspace = os.getenv(\"KEYSPACE\")\n",
    "\n",
    "print(f\"üìä ASTRA_DB_API_ENDPOINT: '{astra_endpoint}'\")\n",
    "print(f\"üìä ASTRA_DB_TOKEN: '{astra_token[:20] if astra_token else None}...' (truncated)\")\n",
    "print(f\"üìä KEYSPACE: '{keyspace}'\")\n",
    "\n",
    "# Check if .env file exists and is readable\n",
    "env_file_path = os.path.join(os.getcwd(), \".env\")\n",
    "print(f\"üìä .env file exists: {os.path.exists(env_file_path)}\")\n",
    "\n",
    "if os.path.exists(env_file_path):\n",
    "    print(f\"üìä .env file path: {env_file_path}\")\n",
    "    # Read first few lines to verify content\n",
    "    with open(env_file_path, 'r') as f:\n",
    "        lines = f.readlines()[:10]\n",
    "        print(\"üìä First 10 lines of .env file:\")\n",
    "        for i, line in enumerate(lines, 1):\n",
    "            if \"ASTRA\" in line or \"KEYSPACE\" in line:\n",
    "                print(f\"   {i}: {line.strip()}\")\n",
    "\n",
    "# Check environment variables from all sources\n",
    "print(f\"\\nüîç All environment variables containing 'ASTRA':\")\n",
    "for key, value in os.environ.items():\n",
    "    if 'ASTRA' in key:\n",
    "        print(f\"   {key}: {value[:50] if value else 'None'}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35a1d69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:15:13,135 - gemini_engine.component5_bridge - WARNING - Health check encountered error: MemoryManager.get_relevant_context() missing 1 required positional argument: 'query_features'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç DEBUG: Checking Bridge Components...\n",
      "üìä Bridge initialized: True\n",
      "üìä Bridge has memory_manager: True\n",
      "üìä Memory manager is not None: True\n",
      "üìä Bridge has gate_network: True\n",
      "üìä Gate network is not None: True\n",
      "üìä Memory Manager type: <class 'comp5.core.memory_manager.MemoryManager'>\n",
      "üìä Memory Manager has gate_network: True\n",
      "üìä Memory Manager gate_network is not None: True\n",
      "üìä Gate Network type: <class 'core.gate_networks.LSTMGateNetwork'>\n",
      "üìä Gate Network methods: ['T_destination', 'add_module', 'apply', 'bfloat16', 'buffers', 'call_super_init', 'children', 'compile', 'context_size', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forget_gate', 'forget_threshold', 'forward', 'get_buffer', 'get_extra_state', 'get_gate_decisions', 'get_parameter', 'get_submodule', 'get_thresholds', 'half', 'hidden_size', 'input_gate', 'input_size', 'input_threshold', 'ipu', 'load_model', 'load_state_dict', 'modules', 'mtia', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'output_gate', 'output_threshold', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_load_state_dict_pre_hook', 'register_module', 'register_parameter', 'register_state_dict_post_hook', 'register_state_dict_pre_hook', 'requires_grad_', 'save_model', 'set_extra_state', 'set_submodule', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'update_thresholds', 'xpu', 'zero_grad']\n",
      "üìä Bridge health_check method exists: True\n",
      "\n",
      "üè• Testing Component 5 Health Check...\n",
      "‚úÖ Health check completed\n",
      "üìä Health Status: {\n",
      "  \"initialized\": true,\n",
      "  \"config_valid\": true,\n",
      "  \"memory_manager_healthy\": false,\n",
      "  \"gate_network_healthy\": false,\n",
      "  \"database_connection\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Add this debug cell BEFORE running the health check:\n",
    "\n",
    "print(\"\\nüîç DEBUG: Checking Bridge Components...\")\n",
    "\n",
    "# Check what's actually in the bridge\n",
    "print(f\"üìä Bridge initialized: {bridge._initialized}\")\n",
    "print(f\"üìä Bridge has memory_manager: {hasattr(bridge, 'memory_manager')}\")\n",
    "print(f\"üìä Memory manager is not None: {bridge.memory_manager is not None}\")\n",
    "print(f\"üìä Bridge has gate_network: {hasattr(bridge, 'gate_network')}\")\n",
    "print(f\"üìä Gate network is not None: {bridge.gate_network is not None}\")\n",
    "\n",
    "if bridge.memory_manager:\n",
    "    print(f\"üìä Memory Manager type: {type(bridge.memory_manager)}\")\n",
    "    print(f\"üìä Memory Manager has gate_network: {hasattr(bridge.memory_manager, 'gate_network')}\")\n",
    "    print(f\"üìä Memory Manager gate_network is not None: {bridge.memory_manager.gate_network is not None}\")\n",
    "\n",
    "if bridge.gate_network:\n",
    "    print(f\"üìä Gate Network type: {type(bridge.gate_network)}\")\n",
    "    print(f\"üìä Gate Network methods: {[method for method in dir(bridge.gate_network) if not method.startswith('_')]}\")\n",
    "\n",
    "# Check what methods the health check is trying to call\n",
    "print(f\"üìä Bridge health_check method exists: {hasattr(bridge, 'health_check')}\")\n",
    "\n",
    "# Now run the health check\n",
    "print(\"\\nüè• Testing Component 5 Health Check...\")\n",
    "try:\n",
    "    health = await bridge.health_check()\n",
    "    print(\"‚úÖ Health check completed\")\n",
    "    print(f\"üìä Health Status: {json.dumps(health, indent=2, default=str)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Health check failed: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38416744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:15:13,142 - gemini_engine.component5_bridge - WARNING - Health check encountered error: MemoryManager.get_relevant_context() missing 1 required positional argument: 'query_features'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üè• Testing Component 5 Health Check...\n",
      "‚úÖ Health check completed\n",
      "üìä Health Status: {\n",
      "  \"initialized\": true,\n",
      "  \"config_valid\": true,\n",
      "  \"memory_manager_healthy\": false,\n",
      "  \"gate_network_healthy\": false,\n",
      "  \"database_connection\": false\n",
      "}\n",
      "üîß Initialized: True\n",
      "üîß Config Valid: True\n",
      "üîß Memory Manager: False\n",
      "üîß Gate Network: False\n",
      "üîß Database: False\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüè• Testing Component 5 Health Check...\")\n",
    "\n",
    "try:\n",
    "    health = await bridge.health_check()\n",
    "    print(\"‚úÖ Health check completed\")\n",
    "    print(f\"üìä Health Status: {json.dumps(health, indent=2, default=str)}\")\n",
    "    \n",
    "    # Check individual components\n",
    "    print(f\"üîß Initialized: {health.get('initialized', False)}\")\n",
    "    print(f\"üîß Config Valid: {health.get('config_valid', False)}\")\n",
    "    print(f\"üîß Memory Manager: {health.get('memory_manager_healthy', False)}\")\n",
    "    print(f\"üîß Gate Network: {health.get('gate_network_healthy', False)}\")\n",
    "    print(f\"üîß Database: {health.get('database_connection', False)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Health check failed: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfef375f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:15:13,151 - gemini_engine.component5_bridge - INFO - Getting memory context for user test_user_123\n",
      "2025-09-04 17:15:13,152 - comp5.core.memory_manager - INFO - Assembling context for user test_user_123\n",
      "2025-09-04 17:15:13,157 - astrapy.data.cursors.cursor - INFO - cursor fetching a page: (empty page state) from memory_embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí≠ Testing Memory Context Retrieval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:15:13,784 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db/memory_embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 17:15:13,785 - astrapy.utils.api_commander - WARNING - The Data API returned a warning: {'errorCode': 'IN_MEMORY_SORTING_DUE_TO_NON_PARTITION_SORTING', 'message': 'The command used columns in the sort clause that are not part of the partition sorting, and so the query was sorted in memory.\\n      \\nThe table memory_db.memory_embeddings has the partition sorting columns: [None].\\nThe command sorted on the columns: created_at.\\n\\nThe command was executed using in memory sorting rather than taking advantage of the partition sorting on disk. This can have performance implications on large tables.\\n\\nSee documentation for best practices for sorting.', 'family': 'REQUEST', 'scope': 'WARNING', 'title': 'Sorting by non partition sorting columns', 'id': 'ab06c208-8ade-4ebb-b8da-f3d56282e404'}\n",
      "2025-09-04 17:15:13,785 - astrapy.data.cursors.cursor - INFO - cursor finished fetching a page: (empty page state) from memory_embeddings\n",
      "2025-09-04 17:15:13,786 - database.memory_store - INFO - Retrieved 5 memories for user test_user_123\n",
      "2025-09-04 17:15:13,788 - comp5.core.memory_manager - INFO - Filtered to 5 relevant memories\n",
      "2025-09-04 17:15:13,789 - astrapy.data.collection - INFO - updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:15:14,149 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db/memory_embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 17:15:14,150 - astrapy.data.collection - INFO - finished updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:15:14,150 - astrapy.data.collection - INFO - updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:15:14,511 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db/memory_embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 17:15:14,512 - astrapy.data.collection - INFO - finished updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:15:14,513 - astrapy.data.collection - INFO - updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:15:14,866 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db/memory_embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 17:15:14,871 - astrapy.data.collection - INFO - finished updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:15:14,873 - astrapy.data.collection - INFO - updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:15:15,167 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db/memory_embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 17:15:15,168 - astrapy.data.collection - INFO - finished updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:15:15,169 - astrapy.data.collection - INFO - updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:15:15,439 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db/memory_embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 17:15:15,441 - astrapy.data.collection - INFO - finished updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:15:15,441 - comp5.core.memory_manager - INFO - Assembled context with 5 memories\n",
      "2025-09-04 17:15:15,442 - gemini_engine.component5_bridge - INFO - Retrieved 5 memories for context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Memory context retrieved successfully\n",
      "üìä Memories Found: 5\n",
      "üìä Token Usage: 0\n",
      "üìä Assembly Metadata: {'source': 'component5_lstm', 'total_memories': 5, 'processing_time_ms': 0, 'gate_decisions': {}, 'query_tokens': 8, 'overhead_tokens': 200, 'available_tokens': 1792, 'memories_considered': 5, 'memories_selected': 5, 'token_utilization': 0.0235, 'diversity_stats': {'event': 1, 'insight': 1, 'emotion': 1, 'conversation': 2}, 'avg_relevance_score': 0.9495703595876692, 'total_tokens_used': 47, 'reason': 'success'}\n",
      "   Memory 1: Planning to attend a tech conference next month...\n",
      "   Importance: 0.900\n",
      "   Memory 2: Realized that taking breaks improves my coding productivity...\n",
      "   Importance: 0.700\n",
      "   Memory 3: I felt excited about starting a new AI project today...\n",
      "   Importance: 0.800\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüí≠ Testing Memory Context Retrieval...\")\n",
    "\n",
    "try:\n",
    "    # Test memory context retrieval\n",
    "    memory_context = await bridge.get_memory_context(\n",
    "        user_id=\"test_user_123\",\n",
    "        current_message=\"How am I feeling about work lately?\",\n",
    "        conversation_id=\"test_conv_001\",\n",
    "        max_memories=5\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Memory context retrieved successfully\")\n",
    "    print(f\"üìä Memories Found: {len(memory_context.selected_memories)}\")\n",
    "    print(f\"üìä Token Usage: {memory_context.token_usage}\")\n",
    "    print(f\"üìä Assembly Metadata: {memory_context.assembly_metadata}\")\n",
    "    \n",
    "    # Show sample memories\n",
    "    for i, memory in enumerate(memory_context.selected_memories[:3]):\n",
    "        print(f\"   Memory {i+1}: {memory.get('content_summary', 'No summary')[:60]}...\")\n",
    "        print(f\"   Importance: {memory.get('importance_score', 0):.3f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Memory context retrieval failed: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff0e72c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:15:15,550 - gemini_engine.memory_retriever - INFO - Memory Retriever initialized with real Component 5\n",
      "2025-09-04 17:15:15,550 - gemini_engine.context_assembler - INFO - Context Assembler initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéº Testing Orchestrator Creation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:15:15,754 - gemini_engine.gemini_client - INFO - Gemini Client initialized\n",
      "2025-09-04 17:15:15,754 - gemini_engine.personality_engine - INFO - Personality Engine initialized\n",
      "2025-09-04 17:15:15,755 - gemini_engine.proactive_engine - INFO - Proactive Engine initialized\n",
      "2025-09-04 17:15:15,755 - gemini_engine.conversation_manager - INFO - Conversation Manager initialized with real Component 5\n",
      "2025-09-04 17:15:15,755 - gemini_engine.memory_retriever - INFO - Memory Retriever initialized with real Component 5\n",
      "2025-09-04 17:15:15,756 - gemini_engine.context_assembler - INFO - Context Assembler initialized\n",
      "2025-09-04 17:15:15,757 - gemini_engine.personality_engine - INFO - Personality Engine initialized\n",
      "2025-09-04 17:15:15,960 - gemini_engine.gemini_client - INFO - Gemini Client initialized\n",
      "2025-09-04 17:15:15,960 - gemini_engine.proactive_engine - INFO - Proactive Engine initialized\n",
      "2025-09-04 17:15:15,961 - gemini_engine.quality_analyzer - INFO - Quality Analyzer initialized\n",
      "2025-09-04 17:15:15,961 - gemini_engine.satisfaction_tracker - INFO - Satisfaction Tracker initialized\n",
      "2025-09-04 17:15:15,962 - gemini_engine.feedback_engine - INFO - Feedback Engine initialized\n",
      "2025-09-04 17:15:15,962 - gemini_engine.metrics_collector - INFO - Metrics Collector initialized\n",
      "2025-09-04 17:15:15,963 - gemini_engine.gemini_engine_orchestrator - INFO - Gemini Engine Orchestrator initialized with real Component 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GeminiEngineOrchestrator created successfully\n",
      "üìä Component 5 Bridge: True\n",
      "üìä Conversation Manager: True\n",
      "üìä Memory Retriever: True\n",
      "üìä Gemini Client: True\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüéº Testing Orchestrator Creation...\")\n",
    "\n",
    "try:\n",
    "    from gemini_engine_orchestrator import GeminiEngineOrchestrator\n",
    "    \n",
    "    # Create orchestrator with Component 5 bridge\n",
    "    orchestrator = GeminiEngineOrchestrator()\n",
    "    print(\"‚úÖ GeminiEngineOrchestrator created successfully\")\n",
    "    \n",
    "    # Check components\n",
    "    print(f\"üìä Component 5 Bridge: {orchestrator.component5_bridge is not None}\")\n",
    "    print(f\"üìä Conversation Manager: {orchestrator.conversation_manager is not None}\")\n",
    "    print(f\"üìä Memory Retriever: {orchestrator.memory_retriever is not None}\")\n",
    "    print(f\"üìä Gemini Client: {orchestrator.gemini_client is not None}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Orchestrator creation failed: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9deca85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:15:15,969 - gemini_engine.gemini_engine_orchestrator - INFO - üöÄ Initializing Gemini Engine (Components 5, 6, 7)...\n",
      "2025-09-04 17:15:15,969 - gemini_engine.component5_bridge - INFO - üöÄ Initializing Component 5 LSTM Memory Gates...\n",
      "2025-09-04 17:15:15,971 - comp5.core.memory_manager - INFO - Initializing Memory Manager...\n",
      "2025-09-04 17:15:15,971 - database.astra_connector - INFO - Connecting to Astra DB: https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Initializing Orchestrator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:15:16,176 - astrapy.data.database - INFO - findCollections\n",
      "2025-09-04 17:15:16,447 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 17:15:16,447 - astrapy.data.database - INFO - finished findCollections\n",
      "2025-09-04 17:15:16,448 - database.astra_connector - INFO - Found collections: []\n",
      "2025-09-04 17:15:17,694 - database.astra_connector - INFO - Successfully connected to Astra DB\n",
      "2025-09-04 17:15:17,695 - comp5.core.memory_manager - INFO - No existing gate network found, using fresh model\n",
      "2025-09-04 17:15:17,695 - comp5.core.memory_manager - INFO - Memory Manager initialized successfully\n",
      "2025-09-04 17:15:17,695 - gemini_engine.component5_bridge - INFO - ‚úÖ Component 5 LSTM system initialized successfully\n",
      "2025-09-04 17:15:17,696 - gemini_engine.gemini_engine_orchestrator - INFO - ‚úÖ All components initialized successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Orchestrator initialized successfully\n",
      "üìä Performance Summary: {\n",
      "  \"conversation_metrics\": {\n",
      "    \"total_conversations\": 0,\n",
      "    \"avg_response_time_ms\": 0.0,\n",
      "    \"success_rate\": 0.0,\n",
      "    \"user_satisfaction_avg\": 0.0,\n",
      "    \"component5_health\": true,\n",
      "    \"component6_health\": true,\n",
      "    \"component7_health\": true\n",
      "  },\n",
      "  \"component5_stats\": {\n",
      "    \"bridge_stats\": {\n",
      "      \"memories_retrieved\": 0,\n",
      "      \"memories_processed\": 0,\n",
      "      \"gate_decisions\": 0,\n",
      "      \"context_assemblies\": 0,\n",
      "      \"errors\": 0\n",
      "    },\n",
      "    \"initialized\": true,\n",
      "    \"memory_manager_stats\": {\n",
      "      \"memory_cache_size\": 0,\n",
      "      \"gate_network_available\": true,\n",
      "      \"db_connector_available\": true,\n",
      "      \"memory_store_available\": true\n",
      "    },\n",
      "    \"memory_manager_available\": true,\n",
      "    \"gate_network_available\": true\n",
      "  },\n",
      "  \"component6_stats\": {\n",
      "    \"total_conversations\": 0,\n",
      "    \"active_conversations\": 0,\n",
      "    \"avg_response_time_ms\": 0.0,\n",
      "    \"success_rate\": 0.0,\n",
      "    \"component5_calls\": 0,\n",
      "    \"memory_context_successes\": 0,\n",
      "    \"successful_conversations\": 0,\n",
      "    \"component5_success_rate\": 0.0,\n",
      "    \"memory_retrieval_stats\": {\n",
      "      \"total_requests\": 0,\n",
      "      \"cache_hit_rate\": 0.0,\n",
      "      \"avg_retrieval_time_ms\": 0.0,\n",
      "      \"cache_size\": 0,\n",
      "      \"recent_retrieval_times\": []\n",
      "    }\n",
      "  },\n",
      "  \"component7_stats\": {\n",
      "    \"quality_analyzer\": {\n",
      "      \"total_analyses\": 0,\n",
      "      \"avg_processing_time_ms\": 0,\n",
      "      \"avg_quality_score\": 0\n",
      "    },\n",
      "    \"satisfaction_tracker\": {\n",
      "      \"avg_satisfaction_calculation_ms\": 0.0,\n",
      "      \"avg_signal_processing_ms\": 0.0,\n",
      "      \"total_satisfaction_tracked\": 0\n",
      "    },\n",
      "    \"feedback_engine\": {\n",
      "      \"avg_generation_time_ms\": 0.0,\n",
      "      \"avg_impact_score\": 0.0,\n",
      "      \"total_feedback_generated\": 0\n",
      "    },\n",
      "    \"metrics_collector\": {\n",
      "      \"avg_collection_time_ms\": 0.0,\n",
      "      \"avg_aggregation_time_ms\": 0.0,\n",
      "      \"total_metrics_collected\": 0\n",
      "    }\n",
      "  },\n",
      "  \"timestamp\": \"2025-09-04 11:45:17.697185\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüöÄ Initializing Orchestrator...\")\n",
    "\n",
    "try:\n",
    "    # Initialize orchestrator\n",
    "    init_success = await orchestrator.initialize()\n",
    "    \n",
    "    if init_success:\n",
    "        print(\"‚úÖ Orchestrator initialized successfully\")\n",
    "        \n",
    "        # Get performance summary\n",
    "        performance = orchestrator.get_performance_summary()\n",
    "        print(f\"üìä Performance Summary: {json.dumps(performance, indent=2, default=str)}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Orchestrator initialization failed\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Orchestrator initialization error: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e016950",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:15:17,705 - gemini_engine.component5_bridge - WARNING - Health check encountered error: MemoryManager.get_relevant_context() missing 1 required positional argument: 'query_features'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üè• Testing Orchestrator Health Check...\n",
      "‚úÖ Orchestrator health check completed\n",
      "üìä Overall Healthy: True\n",
      "üîß component5: {'initialized': True, 'config_valid': True, 'memory_manager_healthy': False, 'gate_network_healthy': False, 'database_connection': False}\n",
      "üîß component6: {'conversation_manager': True, 'gemini_client': True, 'context_assembler': True}\n",
      "üîß component7: {'orchestrator': True, 'quality_analyzer': True}\n",
      "üìä System Metrics: {\n",
      "  \"total_conversations\": 0,\n",
      "  \"avg_response_time_ms\": 0.0,\n",
      "  \"success_rate\": 0.0,\n",
      "  \"user_satisfaction_avg\": 0.0,\n",
      "  \"component5_health\": true,\n",
      "  \"component6_health\": true,\n",
      "  \"component7_health\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüè• Testing Orchestrator Health Check...\")\n",
    "\n",
    "try:\n",
    "    health = await orchestrator.health_check()\n",
    "    print(\"‚úÖ Orchestrator health check completed\")\n",
    "    \n",
    "    print(f\"üìä Overall Healthy: {health.get('overall_healthy', False)}\")\n",
    "    \n",
    "    # Component health details\n",
    "    comp_health = health.get('component_health', {})\n",
    "    for component, status in comp_health.items():\n",
    "        print(f\"üîß {component}: {status}\")\n",
    "    \n",
    "    # System metrics\n",
    "    sys_metrics = health.get('system_metrics', {})\n",
    "    print(f\"üìä System Metrics: {json.dumps(sys_metrics, indent=2, default=str)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Orchestrator health check failed: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e100690d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:27:41,983 - gemini_engine.gemini_engine_orchestrator - INFO - Processing conversation\n",
      "2025-09-04 17:27:41,985 - gemini_engine.gemini_engine_orchestrator - INFO - üß† Step 1: Retrieving memory context from Component 5...\n",
      "2025-09-04 17:27:41,986 - gemini_engine.component5_bridge - INFO - Getting memory context for user test_user_123\n",
      "2025-09-04 17:27:41,987 - comp5.core.memory_manager - INFO - Assembling context for user test_user_123\n",
      "2025-09-04 17:27:41,991 - comp5.core.memory_manager - INFO - Filtered to 2 relevant memories\n",
      "2025-09-04 17:27:41,992 - astrapy.data.collection - INFO - updateOne on 'memory_embeddings'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí¨ Testing Single Conversation...\n",
      "User: I'm feeling excited about my new AI project!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:27:42,828 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db/memory_embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 17:27:42,829 - astrapy.data.collection - INFO - finished updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:27:42,830 - astrapy.data.collection - INFO - updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:27:43,093 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db/memory_embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 17:27:43,094 - astrapy.data.collection - INFO - finished updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:27:43,095 - comp5.core.memory_manager - INFO - Assembled context with 2 memories\n",
      "2025-09-04 17:27:43,095 - gemini_engine.component5_bridge - INFO - Retrieved 2 memories for context\n",
      "2025-09-04 17:27:43,096 - gemini_engine.gemini_engine_orchestrator - INFO - Retrieved 2 memories from Component 5\n",
      "2025-09-04 17:27:43,096 - gemini_engine.gemini_engine_orchestrator - INFO - üë§ Step 2: Retrieving user profile...\n",
      "2025-09-04 17:27:43,097 - gemini_engine.gemini_engine_orchestrator - INFO - ü§ñ Step 3: Processing through Component 6...\n",
      "2025-09-04 17:27:43,097 - gemini_engine.conversation_manager - INFO - Processing conversation for user test_user_123\n",
      "2025-09-04 17:27:43,098 - gemini_engine.component5_bridge - INFO - Getting memory context for user test_user_123\n",
      "2025-09-04 17:27:43,098 - comp5.core.memory_manager - INFO - Assembling context for user test_user_123\n",
      "2025-09-04 17:27:43,100 - comp5.core.memory_manager - INFO - Filtered to 1 relevant memories\n",
      "2025-09-04 17:27:43,100 - astrapy.data.collection - INFO - updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:27:43,370 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db/memory_embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 17:27:43,371 - astrapy.data.collection - INFO - finished updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:27:43,372 - comp5.core.memory_manager - INFO - Assembled context with 1 memories\n",
      "2025-09-04 17:27:43,372 - gemini_engine.component5_bridge - INFO - Retrieved 1 memories for context\n",
      "2025-09-04 17:27:43,373 - gemini_engine.conversation_manager - INFO - Retrieved 1 memories from Component 5\n",
      "2025-09-04 17:27:43,373 - gemini_engine.context_assembler - INFO - Assembling context for conversation notebook_test_conv\n",
      "2025-09-04 17:27:43,375 - gemini_engine.context_assembler - INFO - Context assembled successfully\n",
      "2025-09-04 17:27:43,375 - gemini_engine.component6.context_assembler - INFO - assemble_context executed in 1.63ms\n",
      "2025-09-04 17:27:43,375 - gemini_engine.gemini_client - INFO - Generating Gemini response for conversation notebook_test_conv\n",
      "2025-09-04 17:27:55,167 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent \"HTTP/1.1 503 Service Unavailable\"\n",
      "2025-09-04 17:27:55,167 - gemini_engine.gemini_client - INFO - API RAW RESPONSE STATUS: 503\n",
      "2025-09-04 17:27:55,168 - gemini_engine.gemini_client - ERROR - HTTP error from Gemini API: 503\n",
      "2025-09-04 17:27:55,168 - gemini_engine.gemini_client - ERROR - Failed to generate Gemini response: Gemini API server error: 503\n",
      "2025-09-04 17:27:55,168 - gemini_engine.component6.gemini_client - ERROR - generate_response failed after 11793.27ms: Gemini API server error: 503\n",
      "2025-09-04 17:27:55,169 - gemini_engine.conversation_manager - ERROR - Error generating AI response: Gemini API server error: 503\n",
      "2025-09-04 17:27:55,169 - gemini_engine.conversation_manager - INFO - Conversation processed successfully\n",
      "2025-09-04 17:27:55,170 - gemini_engine.component6.conversation_manager - INFO - process_conversation executed in 12073.63ms\n",
      "2025-09-04 17:27:55,171 - gemini_engine.gemini_engine_orchestrator - INFO - üìä Step 4: Analyzing response through Component 7...\n",
      "2025-09-04 17:27:55,172 - gemini_engine.quality_analyzer - INFO - Analyzing response quality for resp_67bb2109\n",
      "2025-09-04 17:27:55,172 - gemini_engine.quality_analyzer - INFO - Quality analysis completed\n",
      "2025-09-04 17:27:55,173 - gemini_engine.component7.quality_analyzer - INFO - analyze_response executed in 1.01ms\n",
      "2025-09-04 17:27:55,173 - gemini_engine.satisfaction_tracker - INFO - Tracking satisfaction for user test_user_123\n",
      "2025-09-04 17:27:55,173 - gemini_engine.satisfaction_tracker - INFO - Satisfaction tracked for user test_user_123: 0.623\n",
      "2025-09-04 17:27:55,174 - gemini_engine.component7.satisfaction_tracker - INFO - track_user_satisfaction executed in 1.05ms\n",
      "2025-09-04 17:27:55,174 - gemini_engine.component7.metrics_collector - INFO - collect_component_metrics executed in 0.00ms\n",
      "2025-09-04 17:27:55,175 - gemini_engine.gemini_engine_orchestrator - INFO - üîÑ Step 5: Updating memory access in Component 5...\n",
      "2025-09-04 17:27:55,175 - gemini_engine.gemini_engine_orchestrator - WARNING - Memory access update failed: Component5Bridge.update_memory_access() got an unexpected keyword argument 'memories_used'\n",
      "2025-09-04 17:27:55,176 - gemini_engine.gemini_engine_orchestrator - INFO - ‚úÖ Conversation processed successfully\n",
      "2025-09-04 17:27:55,176 - gemini_engine.gemini_engine_orchestrator - INFO - process_conversation executed in 13193.07ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: EnhancedResponse(response_id='resp_67bb2109', conversation_id='notebook_test_conv', user_id='test_user_123', original_response='I apologize for the technical difficulty.', enhanced_response=\"I apologize, but I'm having trouble generating a response right now. Could you please try again?\", enhancement_metadata={'error': 'Gemini API server error: 503', 'fallback_used': True, 'timestamp': '2025-09-04T11:57:55.169850'}, processing_timestamp=datetime.datetime(2025, 9, 4, 11, 57, 55, 169850), quality_metrics={'overall_quality': 0.5}, safety_checks={'passed': True}, context_usage={'utilized': False}, response_metadata={'fallback_used': True, 'error': 'Gemini API server error: 503', 'timestamp': '2025-09-04T11:57:55.169850'}, follow_up_suggestions=['Could you rephrase your question?', 'Is there something specific I can help you with?'], proactive_suggestions=[], memory_context_metadata={'memories_used': 0}, response_analysis=ResponseAnalysis(analysis_id='c1e0a92d-7436-4359-968f-110a1c86ce5e', response_id='resp_67bb2109', conversation_id='notebook_test_conv', user_id='test_user_123', quality_scores={'coherence_score': 0.5, 'relevance_score': 0.5, 'context_usage_score': 0.5, 'safety_score': 1.0, 'overall_quality': 0.6000000000000001}, context_usage={'memories_referenced': 0, 'context_integration_score': 0.5, 'missing_context_opportunities': [], 'effective_usage': []}, user_satisfaction=0.5, improvement_suggestions=['Improve response coherence with better transitions', 'Better incorporate context keywords and themes', 'Make better use of provided memory context', 'Reference relevant memories when available'], analysis_timestamp=datetime.datetime(2025, 9, 4, 11, 57, 55, 172881)))\n",
      "‚úÖ Conversation processed successfully\n",
      "ü§ñ AI Response: I apologize, but I'm having trouble generating a response right now. Could you please try again?\n",
      "‚è±Ô∏è  Processing Time: 13193.07ms\n",
      "‚ùå Conversation processing failed: 'ResponseAnalysis' object has no attribute 'overall_quality'\n",
      "Traceback: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bhushan\\AppData\\Local\\Temp\\ipykernel_50808\\4064099772.py\", line 30, in <module>\n",
      "    print(f\"üìä Quality Score: {analysis.overall_quality:.3f}\")\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'ResponseAnalysis' object has no attribute 'overall_quality'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüí¨ Testing Single Conversation...\")\n",
    "\n",
    "try:\n",
    "    # Process a test conversation\n",
    "    test_message = \"I'm feeling excited about my new AI project!\"\n",
    "    print(f\"User: {test_message}\")\n",
    "    \n",
    "    start_time = datetime.utcnow()\n",
    "    \n",
    "    response = await orchestrator.process_conversation(\n",
    "        user_id=\"test_user_123\",\n",
    "        user_message=test_message,\n",
    "        conversation_id=\"notebook_test_conv\",\n",
    "        emotional_state={\n",
    "            \"primary_emotion\": \"excited\",\n",
    "            \"intensity\": 0.8,\n",
    "            \"confidence\": 0.9\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    processing_time = (datetime.utcnow() - start_time).total_seconds() * 1000\n",
    "    \n",
    "    print(\"‚úÖ Conversation processed successfully\")\n",
    "    print(f\"ü§ñ AI Response: {response.enhanced_response}\")\n",
    "    print(f\"‚è±Ô∏è  Processing Time: {processing_time:.2f}ms\")\n",
    "    \n",
    "    # Show enhanced response details\n",
    "    print(f\"\\nüìã Response Details:\")\n",
    "    print(f\"   Response ID: {response.response_id}\")\n",
    "    print(f\"   Conversation ID: {response.conversation_id}\")\n",
    "    print(f\"   User ID: {response.user_id}\")\n",
    "    \n",
    "    # Show analysis if available - FIXED VERSION\n",
    "    if hasattr(response, 'response_analysis') and response.response_analysis:\n",
    "        analysis = response.response_analysis\n",
    "        print(f\"\\nüìä Response Analysis:\")\n",
    "        \n",
    "        # Safe access to quality_scores\n",
    "        if hasattr(analysis, 'quality_scores'):\n",
    "            quality_scores = analysis.quality_scores\n",
    "            if isinstance(quality_scores, dict):\n",
    "                print(f\"   Overall Quality: {quality_scores.get('overall_quality', 0.0):.3f}\")\n",
    "                print(f\"   Coherence Score: {quality_scores.get('coherence_score', 0.0):.3f}\")\n",
    "                print(f\"   Relevance Score: {quality_scores.get('relevance_score', 0.0):.3f}\")\n",
    "                print(f\"   Context Usage: {quality_scores.get('context_usage_score', 0.0):.3f}\")\n",
    "                print(f\"   Safety Score: {quality_scores.get('safety_score', 1.0):.3f}\")\n",
    "            else:\n",
    "                print(f\"   Quality scores not accessible as dict: {type(quality_scores)}\")\n",
    "        \n",
    "        # Show user satisfaction if available\n",
    "        if hasattr(analysis, 'user_satisfaction'):\n",
    "            print(f\"   User Satisfaction: {analysis.user_satisfaction:.3f}\")\n",
    "        \n",
    "        # Show improvement suggestions\n",
    "        if hasattr(analysis, 'improvement_suggestions') and analysis.improvement_suggestions:\n",
    "            print(f\"   üí° Suggestions: {', '.join(analysis.improvement_suggestions[:2])}\")\n",
    "        \n",
    "        # Show context usage details\n",
    "        if hasattr(analysis, 'context_usage') and analysis.context_usage:\n",
    "            context_usage = analysis.context_usage\n",
    "            if isinstance(context_usage, dict):\n",
    "                memories_ref = context_usage.get('memories_referenced', 0)\n",
    "                integration_score = context_usage.get('context_integration_score', 0.0)\n",
    "                print(f\"   Memories Referenced: {memories_ref}\")\n",
    "                print(f\"   Context Integration: {integration_score:.3f}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"\\nüìä No detailed analysis available\")\n",
    "        print(f\"   response.response_analysis exists: {hasattr(response, 'response_analysis')}\")\n",
    "        if hasattr(response, 'response_analysis'):\n",
    "            print(f\"   response.response_analysis value: {response.response_analysis}\")\n",
    "    \n",
    "    # Show memory context metadata\n",
    "    if hasattr(response, 'memory_context_metadata') and response.memory_context_metadata:\n",
    "        memories_used = response.memory_context_metadata.get('memories_used', 0)\n",
    "        print(f\"\\nüß† Memory Context:\")\n",
    "        print(f\"   Memories Used: {memories_used}\")\n",
    "        print(f\"   Metadata: {response.memory_context_metadata}\")\n",
    "    \n",
    "    # Show enhancement metadata\n",
    "    if hasattr(response, 'enhancement_metadata') and response.enhancement_metadata:\n",
    "        metadata = response.enhancement_metadata\n",
    "        print(f\"\\n‚ö° Enhancement Metadata:\")\n",
    "        if isinstance(metadata, dict):\n",
    "            print(f\"   Fallback Used: {metadata.get('fallback_used', False)}\")\n",
    "            if 'error' in metadata:\n",
    "                print(f\"   Error: {metadata['error']}\")\n",
    "            print(f\"   Processing Time: {metadata.get('processing_time_ms', 'N/A')}ms\")\n",
    "    \n",
    "    # Show follow-up suggestions\n",
    "    if hasattr(response, 'follow_up_suggestions') and response.follow_up_suggestions:\n",
    "        print(f\"\\n‚ùì Follow-up Suggestions:\")\n",
    "        for i, suggestion in enumerate(response.follow_up_suggestions[:3], 1):\n",
    "            print(f\"   {i}. {suggestion}\")\n",
    "    \n",
    "    print(f\"\\nüîß Integration Status: SUCCESS! All components working together.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Conversation processing failed: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")\n",
    "    \n",
    "    # Additional debugging if needed\n",
    "    print(f\"\\nüîç Debug Information:\")\n",
    "    print(f\"   Error type: {type(e).__name__}\")\n",
    "    if 'response' in locals():\n",
    "        print(f\"   Response exists: True\")\n",
    "        print(f\"   Response type: {type(response)}\")\n",
    "    else:\n",
    "        print(f\"   Response exists: False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff12f0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 00:42:16,364 - gemini_engine.component5_bridge - INFO - Getting memory context for user flow_test_user\n",
      "2025-09-04 00:42:16,364 - comp5.core.memory_manager - INFO - Assembling context for user flow_test_user\n",
      "2025-09-04 00:42:16,365 - astrapy.data.cursors.cursor - INFO - cursor fetching a page: (empty page state) from memory_embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí≠ü§ñ Testing LSTM Memory Retrieval ‚Üí Conversation Engine Flow...\n",
      "\n",
      "--- Conversation 1 ---\n",
      "üë§ User Query: I just finished a big presentation at work\n",
      "üß† Step 1: Retrieving LSTM memory context...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 00:42:16,691 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db/memory_embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 00:42:16,692 - astrapy.utils.api_commander - WARNING - The Data API returned a warning: {'errorCode': 'IN_MEMORY_SORTING_DUE_TO_NON_PARTITION_SORTING', 'message': 'The command used columns in the sort clause that are not part of the partition sorting, and so the query was sorted in memory.\\n      \\nThe table memory_db.memory_embeddings has the partition sorting columns: [None].\\nThe command sorted on the columns: created_at.\\n\\nThe command was executed using in memory sorting rather than taking advantage of the partition sorting on disk. This can have performance implications on large tables.\\n\\nSee documentation for best practices for sorting.', 'family': 'REQUEST', 'scope': 'WARNING', 'title': 'Sorting by non partition sorting columns', 'id': 'bdbe157e-da99-4f8d-9bf2-235adeb923af'}\n",
      "2025-09-04 00:42:16,692 - astrapy.data.cursors.cursor - INFO - cursor finished fetching a page: (empty page state) from memory_embeddings\n",
      "2025-09-04 00:42:16,693 - database.memory_store - INFO - Retrieved 0 memories for user flow_test_user\n",
      "2025-09-04 00:42:16,693 - comp5.core.memory_manager - INFO - No memories found for user flow_test_user\n",
      "2025-09-04 00:42:16,694 - gemini_engine.component5_bridge - INFO - Retrieved 0 memories for context\n",
      "2025-09-04 00:42:16,694 - gemini_engine.conversation_manager - INFO - Processing conversation for user flow_test_user\n",
      "2025-09-04 00:42:16,695 - gemini_engine.component5_bridge - INFO - Getting memory context for user flow_test_user\n",
      "2025-09-04 00:42:16,695 - comp5.core.memory_manager - INFO - Assembling context for user flow_test_user\n",
      "2025-09-04 00:42:16,696 - astrapy.data.cursors.cursor - INFO - cursor fetching a page: (empty page state) from memory_embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìä Retrieved 0 memories in 329.77ms\n",
      "üîß Step 2: Assembling context + query for conversation engine...\n",
      "   üìä Context assembled with 0 memories\n",
      "   üìä Total context tokens: 0\n",
      "ü§ñ Step 3: Processing through conversation engine...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 00:42:16,967 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db/memory_embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 00:42:16,968 - astrapy.utils.api_commander - WARNING - The Data API returned a warning: {'errorCode': 'IN_MEMORY_SORTING_DUE_TO_NON_PARTITION_SORTING', 'message': 'The command used columns in the sort clause that are not part of the partition sorting, and so the query was sorted in memory.\\n      \\nThe table memory_db.memory_embeddings has the partition sorting columns: [None].\\nThe command sorted on the columns: created_at.\\n\\nThe command was executed using in memory sorting rather than taking advantage of the partition sorting on disk. This can have performance implications on large tables.\\n\\nSee documentation for best practices for sorting.', 'family': 'REQUEST', 'scope': 'WARNING', 'title': 'Sorting by non partition sorting columns', 'id': 'd5cbee72-945c-47ac-bbd9-a80f7e938c46'}\n",
      "2025-09-04 00:42:16,968 - astrapy.data.cursors.cursor - INFO - cursor finished fetching a page: (empty page state) from memory_embeddings\n",
      "2025-09-04 00:42:16,969 - database.memory_store - INFO - Retrieved 0 memories for user flow_test_user\n",
      "2025-09-04 00:42:16,969 - comp5.core.memory_manager - INFO - No memories found for user flow_test_user\n",
      "2025-09-04 00:42:16,970 - gemini_engine.component5_bridge - INFO - Retrieved 0 memories for context\n",
      "2025-09-04 00:42:16,970 - gemini_engine.conversation_manager - INFO - Retrieved 0 memories from Component 5\n",
      "2025-09-04 00:42:16,971 - gemini_engine.context_assembler - INFO - Assembling context for conversation flow_test_conv\n",
      "2025-09-04 00:42:16,981 - gemini_engine.context_assembler - ERROR - Failed to assemble context: 'GeminiAPIConfig' object has no attribute 'safety_settings'\n",
      "2025-09-04 00:42:16,982 - gemini_engine.component6.context_assembler - ERROR - assemble_context failed after 11.21ms: 'GeminiAPIConfig' object has no attribute 'safety_settings'\n",
      "2025-09-04 00:42:16,982 - gemini_engine.conversation_manager - ERROR - Error assembling Gemini context: 'GeminiAPIConfig' object has no attribute 'safety_settings'\n",
      "2025-09-04 00:42:16,983 - gemini_engine.gemini_client - INFO - Generating Gemini response for conversation flow_test_conv\n",
      "2025-09-04 00:42:16,983 - gemini_engine.gemini_client - ERROR - Failed to generate Gemini response: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "2025-09-04 00:42:16,984 - gemini_engine.component6.gemini_client - ERROR - generate_response failed after 0.99ms: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "2025-09-04 00:42:16,985 - gemini_engine.conversation_manager - ERROR - Error generating AI response: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "2025-09-04 00:42:16,986 - gemini_engine.conversation_manager - ERROR - Conversation processing failed\n",
      "2025-09-04 00:42:16,986 - gemini_engine.component6.conversation_manager - ERROR - process_conversation failed after 292.11ms: EnhancedResponse.__init__() got an unexpected keyword argument 'conversation_id'\n",
      "2025-09-04 00:42:16,987 - gemini_engine.component5_bridge - INFO - Getting memory context for user flow_test_user\n",
      "2025-09-04 00:42:16,988 - comp5.core.memory_manager - INFO - Assembling context for user flow_test_user\n",
      "2025-09-04 00:42:16,988 - comp5.core.memory_manager - INFO - No memories found for user flow_test_user\n",
      "2025-09-04 00:42:16,988 - gemini_engine.component5_bridge - INFO - Retrieved 0 memories for context\n",
      "2025-09-04 00:42:16,989 - gemini_engine.conversation_manager - INFO - Processing conversation for user flow_test_user\n",
      "2025-09-04 00:42:16,989 - gemini_engine.component5_bridge - INFO - Getting memory context for user flow_test_user\n",
      "2025-09-04 00:42:16,990 - comp5.core.memory_manager - INFO - Assembling context for user flow_test_user\n",
      "2025-09-04 00:42:16,990 - comp5.core.memory_manager - INFO - No memories found for user flow_test_user\n",
      "2025-09-04 00:42:16,990 - gemini_engine.component5_bridge - INFO - Retrieved 0 memories for context\n",
      "2025-09-04 00:42:16,991 - gemini_engine.conversation_manager - INFO - Retrieved 0 memories from Component 5\n",
      "2025-09-04 00:42:16,991 - gemini_engine.context_assembler - INFO - Assembling context for conversation flow_test_conv\n",
      "2025-09-04 00:42:16,992 - gemini_engine.context_assembler - ERROR - Failed to assemble context: 'GeminiAPIConfig' object has no attribute 'safety_settings'\n",
      "2025-09-04 00:42:16,992 - gemini_engine.component6.context_assembler - ERROR - assemble_context failed after 1.08ms: 'GeminiAPIConfig' object has no attribute 'safety_settings'\n",
      "2025-09-04 00:42:16,992 - gemini_engine.conversation_manager - ERROR - Error assembling Gemini context: 'GeminiAPIConfig' object has no attribute 'safety_settings'\n",
      "2025-09-04 00:42:16,993 - gemini_engine.gemini_client - INFO - Generating Gemini response for conversation flow_test_conv\n",
      "2025-09-04 00:42:16,993 - gemini_engine.gemini_client - ERROR - Failed to generate Gemini response: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "2025-09-04 00:42:16,994 - gemini_engine.component6.gemini_client - ERROR - generate_response failed after 1.00ms: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "2025-09-04 00:42:16,994 - gemini_engine.conversation_manager - ERROR - Error generating AI response: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "2025-09-04 00:42:16,995 - gemini_engine.conversation_manager - ERROR - Conversation processing failed\n",
      "2025-09-04 00:42:16,995 - gemini_engine.component6.conversation_manager - ERROR - process_conversation failed after 6.04ms: EnhancedResponse.__init__() got an unexpected keyword argument 'conversation_id'\n",
      "2025-09-04 00:42:16,996 - gemini_engine.component5_bridge - INFO - Getting memory context for user flow_test_user\n",
      "2025-09-04 00:42:16,997 - comp5.core.memory_manager - INFO - Assembling context for user flow_test_user\n",
      "2025-09-04 00:42:16,997 - comp5.core.memory_manager - INFO - No memories found for user flow_test_user\n",
      "2025-09-04 00:42:16,997 - gemini_engine.component5_bridge - INFO - Retrieved 0 memories for context\n",
      "2025-09-04 00:42:16,998 - gemini_engine.conversation_manager - INFO - Processing conversation for user flow_test_user\n",
      "2025-09-04 00:42:16,999 - gemini_engine.component5_bridge - INFO - Getting memory context for user flow_test_user\n",
      "2025-09-04 00:42:16,999 - comp5.core.memory_manager - INFO - Assembling context for user flow_test_user\n",
      "2025-09-04 00:42:16,999 - comp5.core.memory_manager - INFO - No memories found for user flow_test_user\n",
      "2025-09-04 00:42:16,999 - gemini_engine.component5_bridge - INFO - Retrieved 0 memories for context\n",
      "2025-09-04 00:42:17,000 - gemini_engine.conversation_manager - INFO - Retrieved 0 memories from Component 5\n",
      "2025-09-04 00:42:17,000 - gemini_engine.context_assembler - INFO - Assembling context for conversation flow_test_conv\n",
      "2025-09-04 00:42:17,001 - gemini_engine.context_assembler - ERROR - Failed to assemble context: 'GeminiAPIConfig' object has no attribute 'safety_settings'\n",
      "2025-09-04 00:42:17,001 - gemini_engine.component6.context_assembler - ERROR - assemble_context failed after 0.92ms: 'GeminiAPIConfig' object has no attribute 'safety_settings'\n",
      "2025-09-04 00:42:17,002 - gemini_engine.conversation_manager - ERROR - Error assembling Gemini context: 'GeminiAPIConfig' object has no attribute 'safety_settings'\n",
      "2025-09-04 00:42:17,002 - gemini_engine.gemini_client - INFO - Generating Gemini response for conversation flow_test_conv\n",
      "2025-09-04 00:42:17,002 - gemini_engine.gemini_client - ERROR - Failed to generate Gemini response: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "2025-09-04 00:42:17,002 - gemini_engine.component6.gemini_client - ERROR - generate_response failed after 0.00ms: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "2025-09-04 00:42:17,003 - gemini_engine.conversation_manager - ERROR - Error generating AI response: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "2025-09-04 00:42:17,003 - gemini_engine.conversation_manager - ERROR - Conversation processing failed\n",
      "2025-09-04 00:42:17,003 - gemini_engine.component6.conversation_manager - ERROR - process_conversation failed after 5.00ms: EnhancedResponse.__init__() got an unexpected keyword argument 'conversation_id'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Conversation 1 failed: EnhancedResponse.__init__() got an unexpected keyword argument 'conversation_id'\n",
      "   Traceback: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\conversation_manager.py\", line 294, in _generate_ai_response\n",
      "    gemini_response = await self.gemini_client.generate_response(gemini_request)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\shared\\utils.py\", line 37, in async_wrapper\n",
      "    result = await func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\gemini_client.py\", line 90, in generate_response\n",
      "    await self._check_rate_limits()\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\gemini_client.py\", line 137, in _check_rate_limits\n",
      "    if len(self.request_timestamps) >= settings.gemini_api.rate_limit_requests_per_minute:\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bhushan\\AppData\\Local\\Temp\\ipykernel_29204\\2647529219.py\", line 64, in <module>\n",
      "    response = await orchestrator.conversation_manager.process_conversation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\shared\\utils.py\", line 37, in async_wrapper\n",
      "    result = await func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\conversation_manager.py\", line 121, in process_conversation\n",
      "    ai_response = await self._generate_ai_response(gemini_request)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\conversation_manager.py\", line 312, in _generate_ai_response\n",
      "    return EnhancedResponse(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "TypeError: EnhancedResponse.__init__() got an unexpected keyword argument 'conversation_id'\n",
      "\n",
      "\n",
      "--- Conversation 2 ---\n",
      "üë§ User Query: Can you remind me what we discussed about presentations?\n",
      "üß† Step 1: Retrieving LSTM memory context...\n",
      "   üìä Retrieved 0 memories in 2.01ms\n",
      "üîß Step 2: Assembling context + query for conversation engine...\n",
      "   üìä Context assembled with 0 memories\n",
      "   üìä Total context tokens: 0\n",
      "ü§ñ Step 3: Processing through conversation engine...\n",
      "‚ùå Conversation 2 failed: EnhancedResponse.__init__() got an unexpected keyword argument 'conversation_id'\n",
      "   Traceback: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\conversation_manager.py\", line 294, in _generate_ai_response\n",
      "    gemini_response = await self.gemini_client.generate_response(gemini_request)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\shared\\utils.py\", line 37, in async_wrapper\n",
      "    result = await func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\gemini_client.py\", line 90, in generate_response\n",
      "    await self._check_rate_limits()\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\gemini_client.py\", line 137, in _check_rate_limits\n",
      "    if len(self.request_timestamps) >= settings.gemini_api.rate_limit_requests_per_minute:\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bhushan\\AppData\\Local\\Temp\\ipykernel_29204\\2647529219.py\", line 64, in <module>\n",
      "    response = await orchestrator.conversation_manager.process_conversation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\shared\\utils.py\", line 37, in async_wrapper\n",
      "    result = await func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\conversation_manager.py\", line 121, in process_conversation\n",
      "    ai_response = await self._generate_ai_response(gemini_request)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\conversation_manager.py\", line 312, in _generate_ai_response\n",
      "    return EnhancedResponse(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "TypeError: EnhancedResponse.__init__() got an unexpected keyword argument 'conversation_id'\n",
      "\n",
      "\n",
      "--- Conversation 3 ---\n",
      "üë§ User Query: I think I want to improve my public speaking skills\n",
      "üß† Step 1: Retrieving LSTM memory context...\n",
      "   üìä Retrieved 0 memories in 2.00ms\n",
      "üîß Step 2: Assembling context + query for conversation engine...\n",
      "   üìä Context assembled with 0 memories\n",
      "   üìä Total context tokens: 0\n",
      "ü§ñ Step 3: Processing through conversation engine...\n",
      "‚ùå Conversation 3 failed: EnhancedResponse.__init__() got an unexpected keyword argument 'conversation_id'\n",
      "   Traceback: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\conversation_manager.py\", line 294, in _generate_ai_response\n",
      "    gemini_response = await self.gemini_client.generate_response(gemini_request)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\shared\\utils.py\", line 37, in async_wrapper\n",
      "    result = await func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\gemini_client.py\", line 90, in generate_response\n",
      "    await self._check_rate_limits()\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\gemini_client.py\", line 137, in _check_rate_limits\n",
      "    if len(self.request_timestamps) >= settings.gemini_api.rate_limit_requests_per_minute:\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bhushan\\AppData\\Local\\Temp\\ipykernel_29204\\2647529219.py\", line 64, in <module>\n",
      "    response = await orchestrator.conversation_manager.process_conversation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\shared\\utils.py\", line 37, in async_wrapper\n",
      "    result = await func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\conversation_manager.py\", line 121, in process_conversation\n",
      "    ai_response = await self._generate_ai_response(gemini_request)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\conversation_manager.py\", line 312, in _generate_ai_response\n",
      "    return EnhancedResponse(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "TypeError: EnhancedResponse.__init__() got an unexpected keyword argument 'conversation_id'\n",
      "\n",
      "\n",
      "üìä LSTM ‚Üí Conversation Engine Flow Analysis:\n",
      "============================================================\n",
      "Total Conversations: 3\n",
      "Successful Conversations: 0\n",
      "LSTM Context Successes: 0\n",
      "Overall Success Rate: 0.0%\n",
      "LSTM Integration Rate: 0.0%\n",
      "\n",
      "Detailed Results:\n",
      "  ‚ùå üö´ Conv 1: I just finished a big presenta...\n",
      "  ‚ùå üö´ Conv 2: Can you remind me what we disc...\n",
      "  ‚ùå üö´ Conv 3: I think I want to improve my p...\n",
      "\n",
      "‚ùå ISSUES! LSTM Memory ‚Üí Conversation Engine integration needs debugging.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüí≠ü§ñ Testing LSTM Memory Retrieval ‚Üí Conversation Engine Flow...\")\n",
    "\n",
    "conversation_tests = [\n",
    "    {\n",
    "        \"message\": \"I just finished a big presentation at work\",\n",
    "        \"emotion\": {\"primary_emotion\": \"relieved\", \"intensity\": 0.7}\n",
    "    },\n",
    "    {\n",
    "        \"message\": \"Can you remind me what we discussed about presentations?\", \n",
    "        \"emotion\": {\"primary_emotion\": \"curious\", \"intensity\": 0.6}\n",
    "    },\n",
    "    {\n",
    "        \"message\": \"I think I want to improve my public speaking skills\",\n",
    "        \"emotion\": {\"primary_emotion\": \"motivated\", \"intensity\": 0.8}\n",
    "    }\n",
    "]\n",
    "\n",
    "conversation_results = []\n",
    "\n",
    "for i, test in enumerate(conversation_tests, 1):\n",
    "    try:\n",
    "        print(f\"\\n--- Conversation {i} ---\")\n",
    "        print(f\"üë§ User Query: {test['message']}\")\n",
    "        \n",
    "        # STEP 1: Get LSTM Memory Context\n",
    "        print(f\"üß† Step 1: Retrieving LSTM memory context...\")\n",
    "        start_retrieval = datetime.utcnow()\n",
    "        \n",
    "        memory_context = await bridge.get_memory_context(\n",
    "            user_id=\"flow_test_user\",\n",
    "            current_message=test['message'],\n",
    "            conversation_id=\"flow_test_conv\",\n",
    "            max_memories=10\n",
    "        )\n",
    "        \n",
    "        retrieval_time = (datetime.utcnow() - start_retrieval).total_seconds() * 1000\n",
    "        print(f\"   üìä Retrieved {len(memory_context.selected_memories)} memories in {retrieval_time:.2f}ms\")\n",
    "        \n",
    "        # Show retrieved memories\n",
    "        for j, memory in enumerate(memory_context.selected_memories[:3]):\n",
    "            relevance = memory_context.relevance_scores[j] if j < len(memory_context.relevance_scores) else 0\n",
    "            print(f\"   üí≠ Memory {j+1}: {memory.get('content_summary', 'No summary')[:50]}... (relevance: {relevance:.3f})\")\n",
    "        \n",
    "        # STEP 2: Assemble Context + Query\n",
    "        print(f\"üîß Step 2: Assembling context + query for conversation engine...\")\n",
    "        \n",
    "        # Create enhanced context with LSTM memories\n",
    "        context_with_memories = {\n",
    "            \"user_query\": test['message'],\n",
    "            \"emotional_state\": test['emotion'],\n",
    "            \"lstm_memories\": memory_context.selected_memories,\n",
    "            \"memory_metadata\": memory_context.assembly_metadata,\n",
    "            \"token_usage\": memory_context.token_usage\n",
    "        }\n",
    "        \n",
    "        print(f\"   üìä Context assembled with {len(memory_context.selected_memories)} memories\")\n",
    "        print(f\"   üìä Total context tokens: {memory_context.token_usage}\")\n",
    "        \n",
    "        # STEP 3: Process through Conversation Engine\n",
    "        print(f\"ü§ñ Step 3: Processing through conversation engine...\")\n",
    "        start_conversation = datetime.utcnow()\n",
    "        \n",
    "        # Use orchestrator's conversation manager with the LSTM context\n",
    "        response = await orchestrator.conversation_manager.process_conversation(\n",
    "            user_id=\"flow_test_user\",\n",
    "            user_message=test['message'],\n",
    "            conversation_id=\"flow_test_conv\",\n",
    "            emotional_state=test['emotion']\n",
    "        )\n",
    "        \n",
    "        conversation_time = (datetime.utcnow() - start_conversation).total_seconds() * 1000\n",
    "        total_time = retrieval_time + conversation_time\n",
    "        \n",
    "        print(f\"   ü§ñ AI Response: {response.enhanced_response[:100]}...\")\n",
    "        print(f\"   ‚è±Ô∏è  Conversation time: {conversation_time:.2f}ms\")\n",
    "        print(f\"   ‚è±Ô∏è  Total time (retrieval + conversation): {total_time:.2f}ms\")\n",
    "        \n",
    "        # STEP 4: Show Memory Usage in Response\n",
    "        print(f\"üîç Step 4: Memory usage analysis...\")\n",
    "        \n",
    "        # Check if memories influenced the response\n",
    "        memory_usage_analysis = {\n",
    "            \"memories_retrieved\": len(memory_context.selected_memories),\n",
    "            \"avg_memory_relevance\": sum(memory_context.relevance_scores) / len(memory_context.relevance_scores) if memory_context.relevance_scores else 0,\n",
    "            \"context_tokens_used\": memory_context.token_usage,\n",
    "            \"lstm_source\": memory_context.assembly_metadata.get('source', 'unknown')\n",
    "        }\n",
    "        \n",
    "        print(f\"   üìä Memory Usage: {json.dumps(memory_usage_analysis, indent=6)}\")\n",
    "        \n",
    "        # Store detailed results\n",
    "        conversation_results.append({\n",
    "            \"conversation\": i,\n",
    "            \"message\": test['message'],\n",
    "            \"memory_retrieval_time_ms\": retrieval_time,\n",
    "            \"conversation_processing_time_ms\": conversation_time,\n",
    "            \"total_processing_time_ms\": total_time,\n",
    "            \"memories_used\": len(memory_context.selected_memories),\n",
    "            \"memory_relevance_avg\": memory_usage_analysis[\"avg_memory_relevance\"],\n",
    "            \"response_length\": len(response.enhanced_response),\n",
    "            \"success\": True,\n",
    "            \"lstm_context_success\": True\n",
    "        })\n",
    "        \n",
    "        # Small delay between conversations to see the memory buildup\n",
    "        await asyncio.sleep(1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Conversation {i} failed: {e}\")\n",
    "        print(f\"   Traceback: {traceback.format_exc()}\")\n",
    "        \n",
    "        conversation_results.append({\n",
    "            \"conversation\": i,\n",
    "            \"message\": test['message'],\n",
    "            \"error\": str(e),\n",
    "            \"success\": False,\n",
    "            \"lstm_context_success\": False\n",
    "        })\n",
    "\n",
    "# STEP 5: Analyze the Complete Flow Results\n",
    "print(f\"\\nüìä LSTM ‚Üí Conversation Engine Flow Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total_conversations = len(conversation_results)\n",
    "successful_conversations = len([r for r in conversation_results if r.get(\"success\", False)])\n",
    "lstm_context_successes = len([r for r in conversation_results if r.get(\"lstm_context_success\", False)])\n",
    "\n",
    "print(f\"Total Conversations: {total_conversations}\")\n",
    "print(f\"Successful Conversations: {successful_conversations}\")\n",
    "print(f\"LSTM Context Successes: {lstm_context_successes}\")\n",
    "print(f\"Overall Success Rate: {successful_conversations/total_conversations*100:.1f}%\")\n",
    "print(f\"LSTM Integration Rate: {lstm_context_successes/total_conversations*100:.1f}%\")\n",
    "\n",
    "if successful_conversations > 0:\n",
    "    # Calculate averages for successful conversations\n",
    "    successful_results = [r for r in conversation_results if r.get(\"success\", False)]\n",
    "    \n",
    "    avg_memory_retrieval = sum(r.get(\"memory_retrieval_time_ms\", 0) for r in successful_results) / len(successful_results)\n",
    "    avg_conversation_time = sum(r.get(\"conversation_processing_time_ms\", 0) for r in successful_results) / len(successful_results)\n",
    "    avg_total_time = sum(r.get(\"total_processing_time_ms\", 0) for r in successful_results) / len(successful_results)\n",
    "    avg_memories_used = sum(r.get(\"memories_used\", 0) for r in successful_results) / len(successful_results)\n",
    "    avg_relevance = sum(r.get(\"memory_relevance_avg\", 0) for r in successful_results) / len(successful_results)\n",
    "    \n",
    "    print(f\"\\nPerformance Metrics (Successful Conversations):\")\n",
    "    print(f\"  üìä Avg Memory Retrieval Time: {avg_memory_retrieval:.2f}ms\")\n",
    "    print(f\"  üìä Avg Conversation Processing: {avg_conversation_time:.2f}ms\")\n",
    "    print(f\"  üìä Avg Total Processing Time: {avg_total_time:.2f}ms\")\n",
    "    print(f\"  üìä Avg Memories Used: {avg_memories_used:.1f}\")\n",
    "    print(f\"  üìä Avg Memory Relevance: {avg_relevance:.3f}\")\n",
    "\n",
    "# Show individual conversation results\n",
    "print(f\"\\nDetailed Results:\")\n",
    "for result in conversation_results:\n",
    "    status = \"‚úÖ\" if result.get(\"success\", False) else \"‚ùå\"\n",
    "    lstm_status = \"üß†\" if result.get(\"lstm_context_success\", False) else \"üö´\"\n",
    "    print(f\"  {status} {lstm_status} Conv {result['conversation']}: {result.get('message', '')[:30]}...\")\n",
    "    if result.get(\"success\", False):\n",
    "        print(f\"      Time: {result.get('total_processing_time_ms', 0):.1f}ms, Memories: {result.get('memories_used', 0)}\")\n",
    "\n",
    "# Assessment\n",
    "if lstm_context_successes == total_conversations and successful_conversations == total_conversations:\n",
    "    print(f\"\\nüéâ PERFECT! LSTM Memory ‚Üí Conversation Engine integration working flawlessly!\")\n",
    "elif lstm_context_successes > 0 and successful_conversations > 0:\n",
    "    print(f\"\\nüëç GOOD! LSTM Memory ‚Üí Conversation Engine integration mostly working.\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå ISSUES! LSTM Memory ‚Üí Conversation Engine integration needs debugging.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cae910",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüö® Testing Error Handling...\")\n",
    "\n",
    "error_tests = [\n",
    "    {\n",
    "        \"name\": \"Empty Message\",\n",
    "        \"user_id\": \"error_test_user\",\n",
    "        \"message\": \"\",\n",
    "        \"expected\": \"Should handle empty message gracefully\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Very Long Message\", \n",
    "        \"user_id\": \"error_test_user\",\n",
    "        \"message\": \"This is a very long message. \" * 200,  # ~1000+ words\n",
    "        \"expected\": \"Should handle long messages\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Special Characters\",\n",
    "        \"user_id\": \"error_test_user\", \n",
    "        \"message\": \"Hello! @#$%^&*()_+ üöÄü§ñüí≠ ‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‰Ω†Â•Ω\",\n",
    "        \"expected\": \"Should handle unicode and special chars\"\n",
    "    }\n",
    "]\n",
    "\n",
    "error_results = []\n",
    "\n",
    "for test in error_tests:\n",
    "    try:\n",
    "        print(f\"\\nüß™ Testing: {test['name']}\")\n",
    "        print(f\"Message: {test['message'][:50]}...\")\n",
    "        \n",
    "        response = await orchestrator.process_conversation(\n",
    "            user_id=test['user_id'],\n",
    "            user_message=test['message'],\n",
    "            conversation_id=f\"error_test_{test['name'].lower().replace(' ', '_')}\"\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ {test['name']}: Handled successfully\")\n",
    "        print(f\"Response: {response.enhanced_response[:100]}...\")\n",
    "        \n",
    "        error_results.append({\n",
    "            \"test\": test['name'],\n",
    "            \"status\": \"success\",\n",
    "            \"handled\": True\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  {test['name']}: {e}\")\n",
    "        error_results.append({\n",
    "            \"test\": test['name'],\n",
    "            \"status\": \"error\", \n",
    "            \"error\": str(e),\n",
    "            \"handled\": False\n",
    "        })\n",
    "\n",
    "print(f\"\\nüìä Error Handling Results:\")\n",
    "for result in error_results:\n",
    "    status = \"‚úÖ\" if result[\"status\"] == \"success\" else \"‚ö†Ô∏è\"\n",
    "    print(f\"   {status} {result['test']}: {result['status']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eba5bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n‚ö° Performance Analysis...\")\n",
    "\n",
    "try:\n",
    "    # Get comprehensive performance data\n",
    "    performance_summary = orchestrator.get_performance_summary()\n",
    "    \n",
    "    print(\"üìä PERFORMANCE SUMMARY:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Conversation metrics\n",
    "    conv_metrics = performance_summary.get('conversation_metrics', {})\n",
    "    print(f\"Total Conversations: {conv_metrics.get('total_conversations', 0)}\")\n",
    "    print(f\"Average Response Time: {conv_metrics.get('avg_response_time_ms', 0):.2f}ms\")\n",
    "    print(f\"Success Rate: {conv_metrics.get('success_rate', 0)*100:.1f}%\")\n",
    "    \n",
    "    # Component 5 stats\n",
    "    comp5_stats = performance_summary.get('component5_stats', {})\n",
    "    bridge_stats = comp5_stats.get('bridge_stats', {})\n",
    "    print(f\"\\nComponent 5 Performance:\")\n",
    "    print(f\"  Memories Retrieved: {bridge_stats.get('memories_retrieved', 0)}\")\n",
    "    print(f\"  Context Assemblies: {bridge_stats.get('context_assemblies', 0)}\")\n",
    "    print(f\"  Gate Decisions: {bridge_stats.get('gate_decisions', 0)}\")\n",
    "    print(f\"  Errors: {bridge_stats.get('errors', 0)}\")\n",
    "    \n",
    "    # Component 6 stats\n",
    "    comp6_stats = performance_summary.get('component6_stats', {})\n",
    "    print(f\"\\nComponent 6 Performance:\")\n",
    "    print(f\"  Active Conversations: {comp6_stats.get('active_conversations', 0)}\")\n",
    "    print(f\"  Memory Cache Size: {comp6_stats.get('memory_cache_size', 0)}\")\n",
    "    \n",
    "    # Calculate performance assessment\n",
    "    avg_time = conv_metrics.get('avg_response_time_ms', 0)\n",
    "    success_rate = conv_metrics.get('success_rate', 0)\n",
    "    \n",
    "    if avg_time < 5000 and success_rate > 0.8:\n",
    "        print(f\"\\nüéâ PERFORMANCE: EXCELLENT\")\n",
    "    elif avg_time < 10000 and success_rate > 0.6:\n",
    "        print(f\"\\nüëç PERFORMANCE: GOOD\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  PERFORMANCE: NEEDS OPTIMIZATION\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Performance analysis failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bb6854",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüèÅ FINAL INTEGRATION STATUS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Summary of all tests\n",
    "test_summary = {\n",
    "    \"component5_bridge\": \"‚úÖ Working\" if bridge._initialized else \"‚ùå Failed\",\n",
    "    \"orchestrator\": \"‚úÖ Working\" if orchestrator else \"‚ùå Failed\", \n",
    "    \"memory_retrieval\": \"‚úÖ Working\" if 'memory_context' in locals() else \"‚ùå Failed\",\n",
    "    \"conversation_processing\": \"‚úÖ Working\" if len([r for r in conversation_results if r[\"success\"]]) > 0 else \"‚ùå Failed\",\n",
    "    \"error_handling\": \"‚úÖ Working\" if len([r for r in error_results if r[\"status\"] == \"success\"]) > 0 else \"‚ùå Failed\"\n",
    "}\n",
    "\n",
    "for component, status in test_summary.items():\n",
    "    print(f\"{status} {component.replace('_', ' ').title()}\")\n",
    "\n",
    "# Overall assessment\n",
    "working_components = len([s for s in test_summary.values() if \"‚úÖ\" in s])\n",
    "total_components = len(test_summary)\n",
    "success_rate = working_components / total_components\n",
    "\n",
    "print(f\"\\nüìä Overall Success Rate: {success_rate*100:.1f}% ({working_components}/{total_components})\")\n",
    "\n",
    "if success_rate >= 0.8:\n",
    "    print(\"üéâ INTEGRATION SUCCESSFUL! All major components working.\")\n",
    "elif success_rate >= 0.6:\n",
    "    print(\"üëç INTEGRATION MOSTLY WORKING. Minor issues to address.\")\n",
    "else:\n",
    "    print(\"‚ùå INTEGRATION NEEDS WORK. Major issues detected.\")\n",
    "\n",
    "print(f\"\\n‚úÖ Integration test completed at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d276e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüßπ Cleanup...\")\n",
    "\n",
    "try:\n",
    "    # Cleanup resources\n",
    "    if 'orchestrator' in locals():\n",
    "        await orchestrator.cleanup()\n",
    "    \n",
    "    if 'bridge' in locals():\n",
    "        await bridge.cleanup()\n",
    "    \n",
    "    print(\"‚úÖ Cleanup completed successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Cleanup warning: {e}\")\n",
    "\n",
    "print(\"üèÅ All tests completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cbf4f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Environment Setup Complete\n",
      "Project Root: c:\\Users\\Bhushan\\Desktop\n",
      "Component 5 Path: c:\\Users\\Bhushan\\Desktop\\comp5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any, Optional\n",
    "import traceback\n",
    "\n",
    "# Add project paths\n",
    "project_root = os.path.dirname(os.path.abspath(\"\"))\n",
    "sys.path.insert(0, project_root)\n",
    "comp5_path = os.path.join(project_root, 'comp5')\n",
    "#sys.path.insert(0, comp5_path)\n",
    "\n",
    "print(\"ğŸ”§ Environment Setup Complete\")\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(f\"Component 5 Path: {comp5_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ddebbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing Basic Imports...\n",
      "âœ… configu.settings imported successfully\n",
      "âœ… shared modules imported successfully\n",
      "âœ… Component 5 modules imported successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ§ª Testing Basic Imports...\")\n",
    "\n",
    "try:\n",
    "    # Test configu import\n",
    "    from configu.settings import settings\n",
    "    print(\"âœ… configu.settings imported successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ configu.settings import failed: {e}\")\n",
    "\n",
    "try:\n",
    "    # Test shared imports\n",
    "    from shared.schemas import MemoryContext, UserProfile, EnhancedResponse\n",
    "    from shared.utils import get_logger, generate_correlation_id\n",
    "    print(\"âœ… shared modules imported successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ shared modules import failed: {e}\")\n",
    "\n",
    "try:\n",
    "    # Test Component 5 imports\n",
    "    from comp5.config.settings import LSTMConfig\n",
    "    from comp5.core.memory_manager import MemoryManager\n",
    "    print(\"âœ… Component 5 modules imported successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Component 5 modules import failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddf60bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§  Testing Component 5 Bridge...\n",
      "âœ… Component5Bridge created successfully\n",
      "ğŸ“Š Bridge initialized: False\n",
      "ğŸ“Š Bridge stats: {'memories_retrieved': 0, 'memories_processed': 0, 'gate_decisions': 0, 'context_assemblies': 0, 'errors': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nğŸ§  Testing Component 5 Bridge...\")\n",
    "\n",
    "try:\n",
    "    from component6.comp5_interface import Component5Bridge\n",
    "    \n",
    "    # Create bridge instance\n",
    "    bridge = Component5Bridge()\n",
    "    print(\"âœ… Component5Bridge created successfully\")\n",
    "    \n",
    "    # Check initial state\n",
    "    print(f\"ğŸ“Š Bridge initialized: {bridge._initialized}\")\n",
    "    print(f\"ğŸ“Š Bridge stats: {bridge.stats}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Component5Bridge creation failed: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b220124f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” DEBUG: Component 5 Astra Configuration...\n",
      "ğŸ§ª Testing manual AstraDBConfig creation...\n",
      "ğŸ“Š Raw env vars:\n",
      "   ASTRA_DB_API_ENDPOINT: 'https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com'\n",
      "   ASTRA_DB_TOKEN: 'AstraCS:zwwrMyRbmlev...'\n",
      "   KEYSPACE: 'memory_db'\n",
      "\n",
      "ğŸ§ª Testing AstraDBConfig.from_env()...\n",
      "âœ… AstraDBConfig.from_env() successful:\n",
      "   endpoint: 'https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com'\n",
      "   token: 'AstraCS:zwwrMyRbmlev...'\n",
      "   keyspace: 'memory_db'\n",
      "\n",
      "ğŸ§ª Testing manual AstraDBConfig creation...\n",
      "âœ… Manual AstraDBConfig successful:\n",
      "   endpoint: 'https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com'\n",
      "   token: 'AstraCS:zwwrMyRbmlev...'\n",
      "   keyspace: 'memory_db'\n",
      "\n",
      "ğŸ§ª Testing LSTMConfig creation...\n",
      "âœ… LSTMConfig created successfully:\n",
      "   astra endpoint: 'https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com'\n",
      "   astra token: 'AstraCS:zwwrMyRbmlev...'\n",
      "   astra keyspace: 'memory_db'\n",
      "\n",
      "ğŸ› ï¸ MANUAL FIX: Creating working Astra config...\n",
      "âœ… Working Astra config created:\n",
      "   endpoint: https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com\n",
      "   keyspace: memory_db\n",
      "\n",
      "ğŸ§ª Testing bridge with fixed config...\n",
      "\n",
      "ğŸ” Component 5 configuration debug completed!\n"
     ]
    }
   ],
   "source": [
    "# DEBUG CELL: Check Astra Configuration in Component 5\n",
    "import os\n",
    "print(\"ğŸ” DEBUG: Component 5 Astra Configuration...\")\n",
    "\n",
    "# Check how Component 5 is creating the Astra config\n",
    "try:\n",
    "    from comp5.config.settings import LSTMConfig, AstraDBConfig\n",
    "    \n",
    "    # Test manual config creation\n",
    "    print(\"ğŸ§ª Testing manual AstraDBConfig creation...\")\n",
    "    \n",
    "    # Get environment variables directly\n",
    "    endpoint = os.getenv(\"ASTRA_DB_API_ENDPOINT\")\n",
    "    token = os.getenv(\"ASTRA_DB_TOKEN\")\n",
    "    keyspace = os.getenv(\"KEYSPACE\")\n",
    "    \n",
    "    print(f\"ğŸ“Š Raw env vars:\")\n",
    "    print(f\"   ASTRA_DB_API_ENDPOINT: '{endpoint}'\")\n",
    "    print(f\"   ASTRA_DB_TOKEN: '{token[:20] if token else None}...'\")\n",
    "    print(f\"   KEYSPACE: '{keyspace}'\")\n",
    "    \n",
    "    # Test AstraDBConfig creation methods\n",
    "    print(\"\\nğŸ§ª Testing AstraDBConfig.from_env()...\")\n",
    "    try:\n",
    "        astra_config = AstraDBConfig.from_env()\n",
    "        print(f\"âœ… AstraDBConfig.from_env() successful:\")\n",
    "        print(f\"   endpoint: '{astra_config.endpoint}'\")\n",
    "        print(f\"   token: '{astra_config.token[:20] if astra_config.token else None}...'\")\n",
    "        print(f\"   keyspace: '{astra_config.keyspace}'\")\n",
    "    except Exception as config_error:\n",
    "        print(f\"âŒ AstraDBConfig.from_env() failed: {config_error}\")\n",
    "    \n",
    "    # Test manual AstraDBConfig creation\n",
    "    print(\"\\nğŸ§ª Testing manual AstraDBConfig creation...\")\n",
    "    try:\n",
    "        manual_astra_config = AstraDBConfig(\n",
    "            endpoint=endpoint,\n",
    "            token=token,\n",
    "            keyspace=keyspace or \"default_keyspace\"\n",
    "        )\n",
    "        print(f\"âœ… Manual AstraDBConfig successful:\")\n",
    "        print(f\"   endpoint: '{manual_astra_config.endpoint}'\")\n",
    "        print(f\"   token: '{manual_astra_config.token[:20] if manual_astra_config.token else None}...'\")\n",
    "        print(f\"   keyspace: '{manual_astra_config.keyspace}'\")\n",
    "    except Exception as manual_error:\n",
    "        print(f\"âŒ Manual AstraDBConfig failed: {manual_error}\")\n",
    "    \n",
    "    # Test full LSTMConfig creation\n",
    "    print(\"\\nğŸ§ª Testing LSTMConfig creation...\")\n",
    "    try:\n",
    "        lstm_config = LSTMConfig()\n",
    "        print(f\"âœ… LSTMConfig created successfully:\")\n",
    "        print(f\"   astra endpoint: '{lstm_config.astra_db.endpoint}'\")\n",
    "        print(f\"   astra token: '{lstm_config.astra_db.token[:20] if lstm_config.astra_db.token else None}...'\")\n",
    "        print(f\"   astra keyspace: '{lstm_config.astra_db.keyspace}'\")\n",
    "    except Exception as lstm_error:\n",
    "        print(f\"âŒ LSTMConfig creation failed: {lstm_error}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Configuration debug failed: {e}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FIX: Create Working Astra Config for Component 5 Bridge\n",
    "# ============================================================================\n",
    "print(\"\\nğŸ› ï¸ MANUAL FIX: Creating working Astra config...\")\n",
    "\n",
    "try:\n",
    "    # Create a working configuration manually\n",
    "    from comp5.config.settings import AstraDBConfig, LSTMConfig\n",
    "    \n",
    "    # Force correct values\n",
    "    working_astra_config = AstraDBConfig(\n",
    "        endpoint=\"https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com\",\n",
    "        token=os.getenv(\"ASTRA_DB_TOKEN\"),\n",
    "        keyspace=\"memory_db\"\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Working Astra config created:\")\n",
    "    print(f\"   endpoint: {working_astra_config.endpoint}\")\n",
    "    print(f\"   keyspace: {working_astra_config.keyspace}\")\n",
    "    \n",
    "    # Test if we can create a new bridge with this config\n",
    "    print(\"\\nğŸ§ª Testing bridge with fixed config...\")\n",
    "    \n",
    "    # Modify the bridge's config\n",
    "    if 'bridge' in locals() and bridge.config:\n",
    "        bridge.config.astra_db = working_astra_config\n",
    "        print(\"âœ… Bridge config updated with working Astra settings\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Manual fix failed: {e}\")\n",
    "\n",
    "print(\"\\nğŸ” Component 5 configuration debug completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c2054a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:15:10,339 - gemini_engine.component5_bridge - INFO - ğŸš€ Initializing Component 5 LSTM Memory Gates...\n",
      "2025-09-04 17:15:10,342 - comp5.core.memory_manager - INFO - Initializing Memory Manager...\n",
      "2025-09-04 17:15:10,342 - database.astra_connector - INFO - Connecting to Astra DB: https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Initializing Component 5 Bridge...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:15:10,545 - astrapy.data.database - INFO - findCollections\n",
      "2025-09-04 17:15:11,848 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 17:15:11,849 - astrapy.data.database - INFO - finished findCollections\n",
      "2025-09-04 17:15:11,849 - database.astra_connector - INFO - Found collections: []\n",
      "2025-09-04 17:15:13,110 - database.astra_connector - INFO - Successfully connected to Astra DB\n",
      "2025-09-04 17:15:13,112 - comp5.core.memory_manager - INFO - No existing gate network found, using fresh model\n",
      "2025-09-04 17:15:13,113 - comp5.core.memory_manager - INFO - Memory Manager initialized successfully\n",
      "2025-09-04 17:15:13,113 - gemini_engine.component5_bridge - INFO - âœ… Component 5 LSTM system initialized successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Component 5 Bridge initialized successfully\n",
      "ğŸ“Š Memory Manager: True\n",
      "ğŸ“Š Gate Network: True\n",
      "ğŸ“Š Bridge Statistics: {\n",
      "  \"bridge_stats\": {\n",
      "    \"memories_retrieved\": 0,\n",
      "    \"memories_processed\": 0,\n",
      "    \"gate_decisions\": 0,\n",
      "    \"context_assemblies\": 0,\n",
      "    \"errors\": 0\n",
      "  },\n",
      "  \"initialized\": true,\n",
      "  \"memory_manager_stats\": {\n",
      "    \"memory_cache_size\": 0,\n",
      "    \"gate_network_available\": true,\n",
      "    \"db_connector_available\": true,\n",
      "    \"memory_store_available\": true\n",
      "  },\n",
      "  \"memory_manager_available\": true,\n",
      "  \"gate_network_available\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nğŸš€ Initializing Component 5 Bridge...\")\n",
    "\n",
    "try:\n",
    "    # Initialize the bridge (async call)\n",
    "    init_success = await bridge.initialize()\n",
    "    \n",
    "    if init_success:\n",
    "        print(\"âœ… Component 5 Bridge initialized successfully\")\n",
    "        print(f\"ğŸ“Š Memory Manager: {bridge.memory_manager is not None}\")\n",
    "        print(f\"ğŸ“Š Gate Network: {bridge.gate_network is not None}\")\n",
    "        \n",
    "        # Get statistics safely\n",
    "        try:\n",
    "            stats = bridge.get_statistics()\n",
    "            print(f\"ğŸ“Š Bridge Statistics: {json.dumps(stats, indent=2, default=str)}\")\n",
    "        except Exception as stats_error:\n",
    "            print(f\"âš ï¸  Could not get full statistics: {stats_error}\")\n",
    "            print(f\"ğŸ“Š Basic Status: Initialized={bridge._initialized}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ Component 5 Bridge initialization failed\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Component 5 Bridge initialization error: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")\n",
    "    \n",
    "    # Check if it's just a database connection issue\n",
    "    if \"Astra DB\" in str(e) or \"Request URL\" in str(e):\n",
    "        print(\"â„¹ï¸  This appears to be an Astra DB connection issue.\")\n",
    "        print(\"â„¹ï¸  The LSTM gates may still work for testing with mock data.\")\n",
    "        print(\"â„¹ï¸  Check your ASTRA_DB_API_ENDPOINT and ASTRA_DB_TOKEN in .env file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3721e206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ASTRA_DB_API_ENDPOINT: 'https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com'\n",
      "ğŸ“Š ASTRA_DB_TOKEN: 'AstraCS:zwwrMyRbmlev...' (truncated)\n",
      "ğŸ“Š KEYSPACE: 'memory_db'\n",
      "ğŸ“Š .env file exists: True\n",
      "ğŸ“Š .env file path: c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\.env\n",
      "ğŸ“Š First 10 lines of .env file:\n",
      "\n",
      "ğŸ” All environment variables containing 'ASTRA':\n",
      "   ASTRA_COLLECTION: memory_embeddings...\n",
      "   ASTRA_DB_API_ENDPOINT: https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-ea...\n",
      "   ASTRA_DB_TOKEN: AstraCS:zwwrMyRbmlevzBlrKlCkxrDR:c561c306f3a1806fc...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Reload environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Check what's actually being read\n",
    "astra_endpoint = os.getenv(\"ASTRA_DB_API_ENDPOINT\")\n",
    "astra_token = os.getenv(\"ASTRA_DB_TOKEN\") \n",
    "keyspace = os.getenv(\"KEYSPACE\")\n",
    "\n",
    "print(f\"ğŸ“Š ASTRA_DB_API_ENDPOINT: '{astra_endpoint}'\")\n",
    "print(f\"ğŸ“Š ASTRA_DB_TOKEN: '{astra_token[:20] if astra_token else None}...' (truncated)\")\n",
    "print(f\"ğŸ“Š KEYSPACE: '{keyspace}'\")\n",
    "\n",
    "# Check if .env file exists and is readable\n",
    "env_file_path = os.path.join(os.getcwd(), \".env\")\n",
    "print(f\"ğŸ“Š .env file exists: {os.path.exists(env_file_path)}\")\n",
    "\n",
    "if os.path.exists(env_file_path):\n",
    "    print(f\"ğŸ“Š .env file path: {env_file_path}\")\n",
    "    # Read first few lines to verify content\n",
    "    with open(env_file_path, 'r') as f:\n",
    "        lines = f.readlines()[:10]\n",
    "        print(\"ğŸ“Š First 10 lines of .env file:\")\n",
    "        for i, line in enumerate(lines, 1):\n",
    "            if \"ASTRA\" in line or \"KEYSPACE\" in line:\n",
    "                print(f\"   {i}: {line.strip()}\")\n",
    "\n",
    "# Check environment variables from all sources\n",
    "print(f\"\\nğŸ” All environment variables containing 'ASTRA':\")\n",
    "for key, value in os.environ.items():\n",
    "    if 'ASTRA' in key:\n",
    "        print(f\"   {key}: {value[:50] if value else 'None'}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35a1d69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:15:13,135 - gemini_engine.component5_bridge - WARNING - Health check encountered error: MemoryManager.get_relevant_context() missing 1 required positional argument: 'query_features'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” DEBUG: Checking Bridge Components...\n",
      "ğŸ“Š Bridge initialized: True\n",
      "ğŸ“Š Bridge has memory_manager: True\n",
      "ğŸ“Š Memory manager is not None: True\n",
      "ğŸ“Š Bridge has gate_network: True\n",
      "ğŸ“Š Gate network is not None: True\n",
      "ğŸ“Š Memory Manager type: <class 'comp5.core.memory_manager.MemoryManager'>\n",
      "ğŸ“Š Memory Manager has gate_network: True\n",
      "ğŸ“Š Memory Manager gate_network is not None: True\n",
      "ğŸ“Š Gate Network type: <class 'core.gate_networks.LSTMGateNetwork'>\n",
      "ğŸ“Š Gate Network methods: ['T_destination', 'add_module', 'apply', 'bfloat16', 'buffers', 'call_super_init', 'children', 'compile', 'context_size', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forget_gate', 'forget_threshold', 'forward', 'get_buffer', 'get_extra_state', 'get_gate_decisions', 'get_parameter', 'get_submodule', 'get_thresholds', 'half', 'hidden_size', 'input_gate', 'input_size', 'input_threshold', 'ipu', 'load_model', 'load_state_dict', 'modules', 'mtia', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'output_gate', 'output_threshold', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_load_state_dict_pre_hook', 'register_module', 'register_parameter', 'register_state_dict_post_hook', 'register_state_dict_pre_hook', 'requires_grad_', 'save_model', 'set_extra_state', 'set_submodule', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'update_thresholds', 'xpu', 'zero_grad']\n",
      "ğŸ“Š Bridge health_check method exists: True\n",
      "\n",
      "ğŸ¥ Testing Component 5 Health Check...\n",
      "âœ… Health check completed\n",
      "ğŸ“Š Health Status: {\n",
      "  \"initialized\": true,\n",
      "  \"config_valid\": true,\n",
      "  \"memory_manager_healthy\": false,\n",
      "  \"gate_network_healthy\": false,\n",
      "  \"database_connection\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Add this debug cell BEFORE running the health check:\n",
    "\n",
    "print(\"\\nğŸ” DEBUG: Checking Bridge Components...\")\n",
    "\n",
    "# Check what's actually in the bridge\n",
    "print(f\"ğŸ“Š Bridge initialized: {bridge._initialized}\")\n",
    "print(f\"ğŸ“Š Bridge has memory_manager: {hasattr(bridge, 'memory_manager')}\")\n",
    "print(f\"ğŸ“Š Memory manager is not None: {bridge.memory_manager is not None}\")\n",
    "print(f\"ğŸ“Š Bridge has gate_network: {hasattr(bridge, 'gate_network')}\")\n",
    "print(f\"ğŸ“Š Gate network is not None: {bridge.gate_network is not None}\")\n",
    "\n",
    "if bridge.memory_manager:\n",
    "    print(f\"ğŸ“Š Memory Manager type: {type(bridge.memory_manager)}\")\n",
    "    print(f\"ğŸ“Š Memory Manager has gate_network: {hasattr(bridge.memory_manager, 'gate_network')}\")\n",
    "    print(f\"ğŸ“Š Memory Manager gate_network is not None: {bridge.memory_manager.gate_network is not None}\")\n",
    "\n",
    "if bridge.gate_network:\n",
    "    print(f\"ğŸ“Š Gate Network type: {type(bridge.gate_network)}\")\n",
    "    print(f\"ğŸ“Š Gate Network methods: {[method for method in dir(bridge.gate_network) if not method.startswith('_')]}\")\n",
    "\n",
    "# Check what methods the health check is trying to call\n",
    "print(f\"ğŸ“Š Bridge health_check method exists: {hasattr(bridge, 'health_check')}\")\n",
    "\n",
    "# Now run the health check\n",
    "print(\"\\nğŸ¥ Testing Component 5 Health Check...\")\n",
    "try:\n",
    "    health = await bridge.health_check()\n",
    "    print(\"âœ… Health check completed\")\n",
    "    print(f\"ğŸ“Š Health Status: {json.dumps(health, indent=2, default=str)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Health check failed: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38416744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:15:13,142 - gemini_engine.component5_bridge - WARNING - Health check encountered error: MemoryManager.get_relevant_context() missing 1 required positional argument: 'query_features'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¥ Testing Component 5 Health Check...\n",
      "âœ… Health check completed\n",
      "ğŸ“Š Health Status: {\n",
      "  \"initialized\": true,\n",
      "  \"config_valid\": true,\n",
      "  \"memory_manager_healthy\": false,\n",
      "  \"gate_network_healthy\": false,\n",
      "  \"database_connection\": false\n",
      "}\n",
      "ğŸ”§ Initialized: True\n",
      "ğŸ”§ Config Valid: True\n",
      "ğŸ”§ Memory Manager: False\n",
      "ğŸ”§ Gate Network: False\n",
      "ğŸ”§ Database: False\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nğŸ¥ Testing Component 5 Health Check...\")\n",
    "\n",
    "try:\n",
    "    health = await bridge.health_check()\n",
    "    print(\"âœ… Health check completed\")\n",
    "    print(f\"ğŸ“Š Health Status: {json.dumps(health, indent=2, default=str)}\")\n",
    "    \n",
    "    # Check individual components\n",
    "    print(f\"ğŸ”§ Initialized: {health.get('initialized', False)}\")\n",
    "    print(f\"ğŸ”§ Config Valid: {health.get('config_valid', False)}\")\n",
    "    print(f\"ğŸ”§ Memory Manager: {health.get('memory_manager_healthy', False)}\")\n",
    "    print(f\"ğŸ”§ Gate Network: {health.get('gate_network_healthy', False)}\")\n",
    "    print(f\"ğŸ”§ Database: {health.get('database_connection', False)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Health check failed: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfef375f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:15:13,151 - gemini_engine.component5_bridge - INFO - Getting memory context for user test_user_123\n",
      "2025-09-04 17:15:13,152 - comp5.core.memory_manager - INFO - Assembling context for user test_user_123\n",
      "2025-09-04 17:15:13,157 - astrapy.data.cursors.cursor - INFO - cursor fetching a page: (empty page state) from memory_embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’­ Testing Memory Context Retrieval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:15:13,784 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db/memory_embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 17:15:13,785 - astrapy.utils.api_commander - WARNING - The Data API returned a warning: {'errorCode': 'IN_MEMORY_SORTING_DUE_TO_NON_PARTITION_SORTING', 'message': 'The command used columns in the sort clause that are not part of the partition sorting, and so the query was sorted in memory.\\n      \\nThe table memory_db.memory_embeddings has the partition sorting columns: [None].\\nThe command sorted on the columns: created_at.\\n\\nThe command was executed using in memory sorting rather than taking advantage of the partition sorting on disk. This can have performance implications on large tables.\\n\\nSee documentation for best practices for sorting.', 'family': 'REQUEST', 'scope': 'WARNING', 'title': 'Sorting by non partition sorting columns', 'id': 'ab06c208-8ade-4ebb-b8da-f3d56282e404'}\n",
      "2025-09-04 17:15:13,785 - astrapy.data.cursors.cursor - INFO - cursor finished fetching a page: (empty page state) from memory_embeddings\n",
      "2025-09-04 17:15:13,786 - database.memory_store - INFO - Retrieved 5 memories for user test_user_123\n",
      "2025-09-04 17:15:13,788 - comp5.core.memory_manager - INFO - Filtered to 5 relevant memories\n",
      "2025-09-04 17:15:13,789 - astrapy.data.collection - INFO - updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:15:14,149 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db/memory_embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 17:15:14,150 - astrapy.data.collection - INFO - finished updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:15:14,150 - astrapy.data.collection - INFO - updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:15:14,511 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db/memory_embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 17:15:14,512 - astrapy.data.collection - INFO - finished updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:15:14,513 - astrapy.data.collection - INFO - updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:15:14,866 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db/memory_embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 17:15:14,871 - astrapy.data.collection - INFO - finished updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:15:14,873 - astrapy.data.collection - INFO - updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:15:15,167 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db/memory_embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 17:15:15,168 - astrapy.data.collection - INFO - finished updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:15:15,169 - astrapy.data.collection - INFO - updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:15:15,439 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db/memory_embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 17:15:15,441 - astrapy.data.collection - INFO - finished updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:15:15,441 - comp5.core.memory_manager - INFO - Assembled context with 5 memories\n",
      "2025-09-04 17:15:15,442 - gemini_engine.component5_bridge - INFO - Retrieved 5 memories for context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Memory context retrieved successfully\n",
      "ğŸ“Š Memories Found: 5\n",
      "ğŸ“Š Token Usage: 0\n",
      "ğŸ“Š Assembly Metadata: {'source': 'component5_lstm', 'total_memories': 5, 'processing_time_ms': 0, 'gate_decisions': {}, 'query_tokens': 8, 'overhead_tokens': 200, 'available_tokens': 1792, 'memories_considered': 5, 'memories_selected': 5, 'token_utilization': 0.0235, 'diversity_stats': {'event': 1, 'insight': 1, 'emotion': 1, 'conversation': 2}, 'avg_relevance_score': 0.9495703595876692, 'total_tokens_used': 47, 'reason': 'success'}\n",
      "   Memory 1: Planning to attend a tech conference next month...\n",
      "   Importance: 0.900\n",
      "   Memory 2: Realized that taking breaks improves my coding productivity...\n",
      "   Importance: 0.700\n",
      "   Memory 3: I felt excited about starting a new AI project today...\n",
      "   Importance: 0.800\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nğŸ’­ Testing Memory Context Retrieval...\")\n",
    "\n",
    "try:\n",
    "    # Test memory context retrieval\n",
    "    memory_context = await bridge.get_memory_context(\n",
    "        user_id=\"test_user_123\",\n",
    "        current_message=\"How am I feeling about work lately?\",\n",
    "        conversation_id=\"test_conv_001\",\n",
    "        max_memories=5\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… Memory context retrieved successfully\")\n",
    "    print(f\"ğŸ“Š Memories Found: {len(memory_context.selected_memories)}\")\n",
    "    print(f\"ğŸ“Š Token Usage: {memory_context.token_usage}\")\n",
    "    print(f\"ğŸ“Š Assembly Metadata: {memory_context.assembly_metadata}\")\n",
    "    \n",
    "    # Show sample memories\n",
    "    for i, memory in enumerate(memory_context.selected_memories[:3]):\n",
    "        print(f\"   Memory {i+1}: {memory.get('content_summary', 'No summary')[:60]}...\")\n",
    "        print(f\"   Importance: {memory.get('importance_score', 0):.3f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Memory context retrieval failed: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff0e72c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:15:15,550 - gemini_engine.memory_retriever - INFO - Memory Retriever initialized with real Component 5\n",
      "2025-09-04 17:15:15,550 - gemini_engine.context_assembler - INFO - Context Assembler initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¼ Testing Orchestrator Creation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:15:15,754 - gemini_engine.gemini_client - INFO - Gemini Client initialized\n",
      "2025-09-04 17:15:15,754 - gemini_engine.personality_engine - INFO - Personality Engine initialized\n",
      "2025-09-04 17:15:15,755 - gemini_engine.proactive_engine - INFO - Proactive Engine initialized\n",
      "2025-09-04 17:15:15,755 - gemini_engine.conversation_manager - INFO - Conversation Manager initialized with real Component 5\n",
      "2025-09-04 17:15:15,755 - gemini_engine.memory_retriever - INFO - Memory Retriever initialized with real Component 5\n",
      "2025-09-04 17:15:15,756 - gemini_engine.context_assembler - INFO - Context Assembler initialized\n",
      "2025-09-04 17:15:15,757 - gemini_engine.personality_engine - INFO - Personality Engine initialized\n",
      "2025-09-04 17:15:15,960 - gemini_engine.gemini_client - INFO - Gemini Client initialized\n",
      "2025-09-04 17:15:15,960 - gemini_engine.proactive_engine - INFO - Proactive Engine initialized\n",
      "2025-09-04 17:15:15,961 - gemini_engine.quality_analyzer - INFO - Quality Analyzer initialized\n",
      "2025-09-04 17:15:15,961 - gemini_engine.satisfaction_tracker - INFO - Satisfaction Tracker initialized\n",
      "2025-09-04 17:15:15,962 - gemini_engine.feedback_engine - INFO - Feedback Engine initialized\n",
      "2025-09-04 17:15:15,962 - gemini_engine.metrics_collector - INFO - Metrics Collector initialized\n",
      "2025-09-04 17:15:15,963 - gemini_engine.gemini_engine_orchestrator - INFO - Gemini Engine Orchestrator initialized with real Component 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GeminiEngineOrchestrator created successfully\n",
      "ğŸ“Š Component 5 Bridge: True\n",
      "ğŸ“Š Conversation Manager: True\n",
      "ğŸ“Š Memory Retriever: True\n",
      "ğŸ“Š Gemini Client: True\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nğŸ¼ Testing Orchestrator Creation...\")\n",
    "\n",
    "try:\n",
    "    from gemini_engine_orchestrator import GeminiEngineOrchestrator\n",
    "    \n",
    "    # Create orchestrator with Component 5 bridge\n",
    "    orchestrator = GeminiEngineOrchestrator()\n",
    "    print(\"âœ… GeminiEngineOrchestrator created successfully\")\n",
    "    \n",
    "    # Check components\n",
    "    print(f\"ğŸ“Š Component 5 Bridge: {orchestrator.component5_bridge is not None}\")\n",
    "    print(f\"ğŸ“Š Conversation Manager: {orchestrator.conversation_manager is not None}\")\n",
    "    print(f\"ğŸ“Š Memory Retriever: {orchestrator.memory_retriever is not None}\")\n",
    "    print(f\"ğŸ“Š Gemini Client: {orchestrator.gemini_client is not None}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Orchestrator creation failed: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9deca85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:15:15,969 - gemini_engine.gemini_engine_orchestrator - INFO - ğŸš€ Initializing Gemini Engine (Components 5, 6, 7)...\n",
      "2025-09-04 17:15:15,969 - gemini_engine.component5_bridge - INFO - ğŸš€ Initializing Component 5 LSTM Memory Gates...\n",
      "2025-09-04 17:15:15,971 - comp5.core.memory_manager - INFO - Initializing Memory Manager...\n",
      "2025-09-04 17:15:15,971 - database.astra_connector - INFO - Connecting to Astra DB: https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Initializing Orchestrator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:15:16,176 - astrapy.data.database - INFO - findCollections\n",
      "2025-09-04 17:15:16,447 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 17:15:16,447 - astrapy.data.database - INFO - finished findCollections\n",
      "2025-09-04 17:15:16,448 - database.astra_connector - INFO - Found collections: []\n",
      "2025-09-04 17:15:17,694 - database.astra_connector - INFO - Successfully connected to Astra DB\n",
      "2025-09-04 17:15:17,695 - comp5.core.memory_manager - INFO - No existing gate network found, using fresh model\n",
      "2025-09-04 17:15:17,695 - comp5.core.memory_manager - INFO - Memory Manager initialized successfully\n",
      "2025-09-04 17:15:17,695 - gemini_engine.component5_bridge - INFO - âœ… Component 5 LSTM system initialized successfully\n",
      "2025-09-04 17:15:17,696 - gemini_engine.gemini_engine_orchestrator - INFO - âœ… All components initialized successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Orchestrator initialized successfully\n",
      "ğŸ“Š Performance Summary: {\n",
      "  \"conversation_metrics\": {\n",
      "    \"total_conversations\": 0,\n",
      "    \"avg_response_time_ms\": 0.0,\n",
      "    \"success_rate\": 0.0,\n",
      "    \"user_satisfaction_avg\": 0.0,\n",
      "    \"component5_health\": true,\n",
      "    \"component6_health\": true,\n",
      "    \"component7_health\": true\n",
      "  },\n",
      "  \"component5_stats\": {\n",
      "    \"bridge_stats\": {\n",
      "      \"memories_retrieved\": 0,\n",
      "      \"memories_processed\": 0,\n",
      "      \"gate_decisions\": 0,\n",
      "      \"context_assemblies\": 0,\n",
      "      \"errors\": 0\n",
      "    },\n",
      "    \"initialized\": true,\n",
      "    \"memory_manager_stats\": {\n",
      "      \"memory_cache_size\": 0,\n",
      "      \"gate_network_available\": true,\n",
      "      \"db_connector_available\": true,\n",
      "      \"memory_store_available\": true\n",
      "    },\n",
      "    \"memory_manager_available\": true,\n",
      "    \"gate_network_available\": true\n",
      "  },\n",
      "  \"component6_stats\": {\n",
      "    \"total_conversations\": 0,\n",
      "    \"active_conversations\": 0,\n",
      "    \"avg_response_time_ms\": 0.0,\n",
      "    \"success_rate\": 0.0,\n",
      "    \"component5_calls\": 0,\n",
      "    \"memory_context_successes\": 0,\n",
      "    \"successful_conversations\": 0,\n",
      "    \"component5_success_rate\": 0.0,\n",
      "    \"memory_retrieval_stats\": {\n",
      "      \"total_requests\": 0,\n",
      "      \"cache_hit_rate\": 0.0,\n",
      "      \"avg_retrieval_time_ms\": 0.0,\n",
      "      \"cache_size\": 0,\n",
      "      \"recent_retrieval_times\": []\n",
      "    }\n",
      "  },\n",
      "  \"component7_stats\": {\n",
      "    \"quality_analyzer\": {\n",
      "      \"total_analyses\": 0,\n",
      "      \"avg_processing_time_ms\": 0,\n",
      "      \"avg_quality_score\": 0\n",
      "    },\n",
      "    \"satisfaction_tracker\": {\n",
      "      \"avg_satisfaction_calculation_ms\": 0.0,\n",
      "      \"avg_signal_processing_ms\": 0.0,\n",
      "      \"total_satisfaction_tracked\": 0\n",
      "    },\n",
      "    \"feedback_engine\": {\n",
      "      \"avg_generation_time_ms\": 0.0,\n",
      "      \"avg_impact_score\": 0.0,\n",
      "      \"total_feedback_generated\": 0\n",
      "    },\n",
      "    \"metrics_collector\": {\n",
      "      \"avg_collection_time_ms\": 0.0,\n",
      "      \"avg_aggregation_time_ms\": 0.0,\n",
      "      \"total_metrics_collected\": 0\n",
      "    }\n",
      "  },\n",
      "  \"timestamp\": \"2025-09-04 11:45:17.697185\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nğŸš€ Initializing Orchestrator...\")\n",
    "\n",
    "try:\n",
    "    # Initialize orchestrator\n",
    "    init_success = await orchestrator.initialize()\n",
    "    \n",
    "    if init_success:\n",
    "        print(\"âœ… Orchestrator initialized successfully\")\n",
    "        \n",
    "        # Get performance summary\n",
    "        performance = orchestrator.get_performance_summary()\n",
    "        print(f\"ğŸ“Š Performance Summary: {json.dumps(performance, indent=2, default=str)}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ Orchestrator initialization failed\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Orchestrator initialization error: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e016950",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:15:17,705 - gemini_engine.component5_bridge - WARNING - Health check encountered error: MemoryManager.get_relevant_context() missing 1 required positional argument: 'query_features'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¥ Testing Orchestrator Health Check...\n",
      "âœ… Orchestrator health check completed\n",
      "ğŸ“Š Overall Healthy: True\n",
      "ğŸ”§ component5: {'initialized': True, 'config_valid': True, 'memory_manager_healthy': False, 'gate_network_healthy': False, 'database_connection': False}\n",
      "ğŸ”§ component6: {'conversation_manager': True, 'gemini_client': True, 'context_assembler': True}\n",
      "ğŸ”§ component7: {'orchestrator': True, 'quality_analyzer': True}\n",
      "ğŸ“Š System Metrics: {\n",
      "  \"total_conversations\": 0,\n",
      "  \"avg_response_time_ms\": 0.0,\n",
      "  \"success_rate\": 0.0,\n",
      "  \"user_satisfaction_avg\": 0.0,\n",
      "  \"component5_health\": true,\n",
      "  \"component6_health\": true,\n",
      "  \"component7_health\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nğŸ¥ Testing Orchestrator Health Check...\")\n",
    "\n",
    "try:\n",
    "    health = await orchestrator.health_check()\n",
    "    print(\"âœ… Orchestrator health check completed\")\n",
    "    \n",
    "    print(f\"ğŸ“Š Overall Healthy: {health.get('overall_healthy', False)}\")\n",
    "    \n",
    "    # Component health details\n",
    "    comp_health = health.get('component_health', {})\n",
    "    for component, status in comp_health.items():\n",
    "        print(f\"ğŸ”§ {component}: {status}\")\n",
    "    \n",
    "    # System metrics\n",
    "    sys_metrics = health.get('system_metrics', {})\n",
    "    print(f\"ğŸ“Š System Metrics: {json.dumps(sys_metrics, indent=2, default=str)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Orchestrator health check failed: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e100690d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:27:41,983 - gemini_engine.gemini_engine_orchestrator - INFO - Processing conversation\n",
      "2025-09-04 17:27:41,985 - gemini_engine.gemini_engine_orchestrator - INFO - ğŸ§  Step 1: Retrieving memory context from Component 5...\n",
      "2025-09-04 17:27:41,986 - gemini_engine.component5_bridge - INFO - Getting memory context for user test_user_123\n",
      "2025-09-04 17:27:41,987 - comp5.core.memory_manager - INFO - Assembling context for user test_user_123\n",
      "2025-09-04 17:27:41,991 - comp5.core.memory_manager - INFO - Filtered to 2 relevant memories\n",
      "2025-09-04 17:27:41,992 - astrapy.data.collection - INFO - updateOne on 'memory_embeddings'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¬ Testing Single Conversation...\n",
      "User: I'm feeling excited about my new AI project!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:27:42,828 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db/memory_embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 17:27:42,829 - astrapy.data.collection - INFO - finished updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:27:42,830 - astrapy.data.collection - INFO - updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:27:43,093 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db/memory_embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 17:27:43,094 - astrapy.data.collection - INFO - finished updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:27:43,095 - comp5.core.memory_manager - INFO - Assembled context with 2 memories\n",
      "2025-09-04 17:27:43,095 - gemini_engine.component5_bridge - INFO - Retrieved 2 memories for context\n",
      "2025-09-04 17:27:43,096 - gemini_engine.gemini_engine_orchestrator - INFO - Retrieved 2 memories from Component 5\n",
      "2025-09-04 17:27:43,096 - gemini_engine.gemini_engine_orchestrator - INFO - ğŸ‘¤ Step 2: Retrieving user profile...\n",
      "2025-09-04 17:27:43,097 - gemini_engine.gemini_engine_orchestrator - INFO - ğŸ¤– Step 3: Processing through Component 6...\n",
      "2025-09-04 17:27:43,097 - gemini_engine.conversation_manager - INFO - Processing conversation for user test_user_123\n",
      "2025-09-04 17:27:43,098 - gemini_engine.component5_bridge - INFO - Getting memory context for user test_user_123\n",
      "2025-09-04 17:27:43,098 - comp5.core.memory_manager - INFO - Assembling context for user test_user_123\n",
      "2025-09-04 17:27:43,100 - comp5.core.memory_manager - INFO - Filtered to 1 relevant memories\n",
      "2025-09-04 17:27:43,100 - astrapy.data.collection - INFO - updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:27:43,370 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db/memory_embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 17:27:43,371 - astrapy.data.collection - INFO - finished updateOne on 'memory_embeddings'\n",
      "2025-09-04 17:27:43,372 - comp5.core.memory_manager - INFO - Assembled context with 1 memories\n",
      "2025-09-04 17:27:43,372 - gemini_engine.component5_bridge - INFO - Retrieved 1 memories for context\n",
      "2025-09-04 17:27:43,373 - gemini_engine.conversation_manager - INFO - Retrieved 1 memories from Component 5\n",
      "2025-09-04 17:27:43,373 - gemini_engine.context_assembler - INFO - Assembling context for conversation notebook_test_conv\n",
      "2025-09-04 17:27:43,375 - gemini_engine.context_assembler - INFO - Context assembled successfully\n",
      "2025-09-04 17:27:43,375 - gemini_engine.component6.context_assembler - INFO - assemble_context executed in 1.63ms\n",
      "2025-09-04 17:27:43,375 - gemini_engine.gemini_client - INFO - Generating Gemini response for conversation notebook_test_conv\n",
      "2025-09-04 17:27:55,167 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent \"HTTP/1.1 503 Service Unavailable\"\n",
      "2025-09-04 17:27:55,167 - gemini_engine.gemini_client - INFO - API RAW RESPONSE STATUS: 503\n",
      "2025-09-04 17:27:55,168 - gemini_engine.gemini_client - ERROR - HTTP error from Gemini API: 503\n",
      "2025-09-04 17:27:55,168 - gemini_engine.gemini_client - ERROR - Failed to generate Gemini response: Gemini API server error: 503\n",
      "2025-09-04 17:27:55,168 - gemini_engine.component6.gemini_client - ERROR - generate_response failed after 11793.27ms: Gemini API server error: 503\n",
      "2025-09-04 17:27:55,169 - gemini_engine.conversation_manager - ERROR - Error generating AI response: Gemini API server error: 503\n",
      "2025-09-04 17:27:55,169 - gemini_engine.conversation_manager - INFO - Conversation processed successfully\n",
      "2025-09-04 17:27:55,170 - gemini_engine.component6.conversation_manager - INFO - process_conversation executed in 12073.63ms\n",
      "2025-09-04 17:27:55,171 - gemini_engine.gemini_engine_orchestrator - INFO - ğŸ“Š Step 4: Analyzing response through Component 7...\n",
      "2025-09-04 17:27:55,172 - gemini_engine.quality_analyzer - INFO - Analyzing response quality for resp_67bb2109\n",
      "2025-09-04 17:27:55,172 - gemini_engine.quality_analyzer - INFO - Quality analysis completed\n",
      "2025-09-04 17:27:55,173 - gemini_engine.component7.quality_analyzer - INFO - analyze_response executed in 1.01ms\n",
      "2025-09-04 17:27:55,173 - gemini_engine.satisfaction_tracker - INFO - Tracking satisfaction for user test_user_123\n",
      "2025-09-04 17:27:55,173 - gemini_engine.satisfaction_tracker - INFO - Satisfaction tracked for user test_user_123: 0.623\n",
      "2025-09-04 17:27:55,174 - gemini_engine.component7.satisfaction_tracker - INFO - track_user_satisfaction executed in 1.05ms\n",
      "2025-09-04 17:27:55,174 - gemini_engine.component7.metrics_collector - INFO - collect_component_metrics executed in 0.00ms\n",
      "2025-09-04 17:27:55,175 - gemini_engine.gemini_engine_orchestrator - INFO - ğŸ”„ Step 5: Updating memory access in Component 5...\n",
      "2025-09-04 17:27:55,175 - gemini_engine.gemini_engine_orchestrator - WARNING - Memory access update failed: Component5Bridge.update_memory_access() got an unexpected keyword argument 'memories_used'\n",
      "2025-09-04 17:27:55,176 - gemini_engine.gemini_engine_orchestrator - INFO - âœ… Conversation processed successfully\n",
      "2025-09-04 17:27:55,176 - gemini_engine.gemini_engine_orchestrator - INFO - process_conversation executed in 13193.07ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: EnhancedResponse(response_id='resp_67bb2109', conversation_id='notebook_test_conv', user_id='test_user_123', original_response='I apologize for the technical difficulty.', enhanced_response=\"I apologize, but I'm having trouble generating a response right now. Could you please try again?\", enhancement_metadata={'error': 'Gemini API server error: 503', 'fallback_used': True, 'timestamp': '2025-09-04T11:57:55.169850'}, processing_timestamp=datetime.datetime(2025, 9, 4, 11, 57, 55, 169850), quality_metrics={'overall_quality': 0.5}, safety_checks={'passed': True}, context_usage={'utilized': False}, response_metadata={'fallback_used': True, 'error': 'Gemini API server error: 503', 'timestamp': '2025-09-04T11:57:55.169850'}, follow_up_suggestions=['Could you rephrase your question?', 'Is there something specific I can help you with?'], proactive_suggestions=[], memory_context_metadata={'memories_used': 0}, response_analysis=ResponseAnalysis(analysis_id='c1e0a92d-7436-4359-968f-110a1c86ce5e', response_id='resp_67bb2109', conversation_id='notebook_test_conv', user_id='test_user_123', quality_scores={'coherence_score': 0.5, 'relevance_score': 0.5, 'context_usage_score': 0.5, 'safety_score': 1.0, 'overall_quality': 0.6000000000000001}, context_usage={'memories_referenced': 0, 'context_integration_score': 0.5, 'missing_context_opportunities': [], 'effective_usage': []}, user_satisfaction=0.5, improvement_suggestions=['Improve response coherence with better transitions', 'Better incorporate context keywords and themes', 'Make better use of provided memory context', 'Reference relevant memories when available'], analysis_timestamp=datetime.datetime(2025, 9, 4, 11, 57, 55, 172881)))\n",
      "âœ… Conversation processed successfully\n",
      "ğŸ¤– AI Response: I apologize, but I'm having trouble generating a response right now. Could you please try again?\n",
      "â±ï¸  Processing Time: 13193.07ms\n",
      "âŒ Conversation processing failed: 'ResponseAnalysis' object has no attribute 'overall_quality'\n",
      "Traceback: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bhushan\\AppData\\Local\\Temp\\ipykernel_50808\\4064099772.py\", line 30, in <module>\n",
      "    print(f\"ğŸ“Š Quality Score: {analysis.overall_quality:.3f}\")\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'ResponseAnalysis' object has no attribute 'overall_quality'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nğŸ’¬ Testing Single Conversation...\")\n",
    "\n",
    "try:\n",
    "    # Process a test conversation\n",
    "    test_message = \"I'm feeling excited about my new AI project!\"\n",
    "    print(f\"User: {test_message}\")\n",
    "    \n",
    "    start_time = datetime.utcnow()\n",
    "    \n",
    "    response = await orchestrator.process_conversation(\n",
    "        user_id=\"test_user_123\",\n",
    "        user_message=test_message,\n",
    "        conversation_id=\"notebook_test_conv\",\n",
    "        emotional_state={\n",
    "            \"primary_emotion\": \"excited\",\n",
    "            \"intensity\": 0.8,\n",
    "            \"confidence\": 0.9\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    processing_time = (datetime.utcnow() - start_time).total_seconds() * 1000\n",
    "    \n",
    "    print(\"âœ… Conversation processed successfully\")\n",
    "    print(f\"ğŸ¤– AI Response: {response.enhanced_response}\")\n",
    "    print(f\"â±ï¸  Processing Time: {processing_time:.2f}ms\")\n",
    "    \n",
    "    # Show enhanced response details\n",
    "    print(f\"\\nğŸ“‹ Response Details:\")\n",
    "    print(f\"   Response ID: {response.response_id}\")\n",
    "    print(f\"   Conversation ID: {response.conversation_id}\")\n",
    "    print(f\"   User ID: {response.user_id}\")\n",
    "    \n",
    "    # Show analysis if available - FIXED VERSION\n",
    "    if hasattr(response, 'response_analysis') and response.response_analysis:\n",
    "        analysis = response.response_analysis\n",
    "        print(f\"\\nğŸ“Š Response Analysis:\")\n",
    "        \n",
    "        # Safe access to quality_scores\n",
    "        if hasattr(analysis, 'quality_scores'):\n",
    "            quality_scores = analysis.quality_scores\n",
    "            if isinstance(quality_scores, dict):\n",
    "                print(f\"   Overall Quality: {quality_scores.get('overall_quality', 0.0):.3f}\")\n",
    "                print(f\"   Coherence Score: {quality_scores.get('coherence_score', 0.0):.3f}\")\n",
    "                print(f\"   Relevance Score: {quality_scores.get('relevance_score', 0.0):.3f}\")\n",
    "                print(f\"   Context Usage: {quality_scores.get('context_usage_score', 0.0):.3f}\")\n",
    "                print(f\"   Safety Score: {quality_scores.get('safety_score', 1.0):.3f}\")\n",
    "            else:\n",
    "                print(f\"   Quality scores not accessible as dict: {type(quality_scores)}\")\n",
    "        \n",
    "        # Show user satisfaction if available\n",
    "        if hasattr(analysis, 'user_satisfaction'):\n",
    "            print(f\"   User Satisfaction: {analysis.user_satisfaction:.3f}\")\n",
    "        \n",
    "        # Show improvement suggestions\n",
    "        if hasattr(analysis, 'improvement_suggestions') and analysis.improvement_suggestions:\n",
    "            print(f\"   ğŸ’¡ Suggestions: {', '.join(analysis.improvement_suggestions[:2])}\")\n",
    "        \n",
    "        # Show context usage details\n",
    "        if hasattr(analysis, 'context_usage') and analysis.context_usage:\n",
    "            context_usage = analysis.context_usage\n",
    "            if isinstance(context_usage, dict):\n",
    "                memories_ref = context_usage.get('memories_referenced', 0)\n",
    "                integration_score = context_usage.get('context_integration_score', 0.0)\n",
    "                print(f\"   Memories Referenced: {memories_ref}\")\n",
    "                print(f\"   Context Integration: {integration_score:.3f}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"\\nğŸ“Š No detailed analysis available\")\n",
    "        print(f\"   response.response_analysis exists: {hasattr(response, 'response_analysis')}\")\n",
    "        if hasattr(response, 'response_analysis'):\n",
    "            print(f\"   response.response_analysis value: {response.response_analysis}\")\n",
    "    \n",
    "    # Show memory context metadata\n",
    "    if hasattr(response, 'memory_context_metadata') and response.memory_context_metadata:\n",
    "        memories_used = response.memory_context_metadata.get('memories_used', 0)\n",
    "        print(f\"\\nğŸ§  Memory Context:\")\n",
    "        print(f\"   Memories Used: {memories_used}\")\n",
    "        print(f\"   Metadata: {response.memory_context_metadata}\")\n",
    "    \n",
    "    # Show enhancement metadata\n",
    "    if hasattr(response, 'enhancement_metadata') and response.enhancement_metadata:\n",
    "        metadata = response.enhancement_metadata\n",
    "        print(f\"\\nâš¡ Enhancement Metadata:\")\n",
    "        if isinstance(metadata, dict):\n",
    "            print(f\"   Fallback Used: {metadata.get('fallback_used', False)}\")\n",
    "            if 'error' in metadata:\n",
    "                print(f\"   Error: {metadata['error']}\")\n",
    "            print(f\"   Processing Time: {metadata.get('processing_time_ms', 'N/A')}ms\")\n",
    "    \n",
    "    # Show follow-up suggestions\n",
    "    if hasattr(response, 'follow_up_suggestions') and response.follow_up_suggestions:\n",
    "        print(f\"\\nâ“ Follow-up Suggestions:\")\n",
    "        for i, suggestion in enumerate(response.follow_up_suggestions[:3], 1):\n",
    "            print(f\"   {i}. {suggestion}\")\n",
    "    \n",
    "    print(f\"\\nğŸ”§ Integration Status: SUCCESS! All components working together.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Conversation processing failed: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")\n",
    "    \n",
    "    # Additional debugging if needed\n",
    "    print(f\"\\nğŸ” Debug Information:\")\n",
    "    print(f\"   Error type: {type(e).__name__}\")\n",
    "    if 'response' in locals():\n",
    "        print(f\"   Response exists: True\")\n",
    "        print(f\"   Response type: {type(response)}\")\n",
    "    else:\n",
    "        print(f\"   Response exists: False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff12f0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 00:42:16,364 - gemini_engine.component5_bridge - INFO - Getting memory context for user flow_test_user\n",
      "2025-09-04 00:42:16,364 - comp5.core.memory_manager - INFO - Assembling context for user flow_test_user\n",
      "2025-09-04 00:42:16,365 - astrapy.data.cursors.cursor - INFO - cursor fetching a page: (empty page state) from memory_embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’­ğŸ¤– Testing LSTM Memory Retrieval â†’ Conversation Engine Flow...\n",
      "\n",
      "--- Conversation 1 ---\n",
      "ğŸ‘¤ User Query: I just finished a big presentation at work\n",
      "ğŸ§  Step 1: Retrieving LSTM memory context...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 00:42:16,691 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db/memory_embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 00:42:16,692 - astrapy.utils.api_commander - WARNING - The Data API returned a warning: {'errorCode': 'IN_MEMORY_SORTING_DUE_TO_NON_PARTITION_SORTING', 'message': 'The command used columns in the sort clause that are not part of the partition sorting, and so the query was sorted in memory.\\n      \\nThe table memory_db.memory_embeddings has the partition sorting columns: [None].\\nThe command sorted on the columns: created_at.\\n\\nThe command was executed using in memory sorting rather than taking advantage of the partition sorting on disk. This can have performance implications on large tables.\\n\\nSee documentation for best practices for sorting.', 'family': 'REQUEST', 'scope': 'WARNING', 'title': 'Sorting by non partition sorting columns', 'id': 'bdbe157e-da99-4f8d-9bf2-235adeb923af'}\n",
      "2025-09-04 00:42:16,692 - astrapy.data.cursors.cursor - INFO - cursor finished fetching a page: (empty page state) from memory_embeddings\n",
      "2025-09-04 00:42:16,693 - database.memory_store - INFO - Retrieved 0 memories for user flow_test_user\n",
      "2025-09-04 00:42:16,693 - comp5.core.memory_manager - INFO - No memories found for user flow_test_user\n",
      "2025-09-04 00:42:16,694 - gemini_engine.component5_bridge - INFO - Retrieved 0 memories for context\n",
      "2025-09-04 00:42:16,694 - gemini_engine.conversation_manager - INFO - Processing conversation for user flow_test_user\n",
      "2025-09-04 00:42:16,695 - gemini_engine.component5_bridge - INFO - Getting memory context for user flow_test_user\n",
      "2025-09-04 00:42:16,695 - comp5.core.memory_manager - INFO - Assembling context for user flow_test_user\n",
      "2025-09-04 00:42:16,696 - astrapy.data.cursors.cursor - INFO - cursor fetching a page: (empty page state) from memory_embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ğŸ“Š Retrieved 0 memories in 329.77ms\n",
      "ğŸ”§ Step 2: Assembling context + query for conversation engine...\n",
      "   ğŸ“Š Context assembled with 0 memories\n",
      "   ğŸ“Š Total context tokens: 0\n",
      "ğŸ¤– Step 3: Processing through conversation engine...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 00:42:16,967 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db/memory_embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-09-04 00:42:16,968 - astrapy.utils.api_commander - WARNING - The Data API returned a warning: {'errorCode': 'IN_MEMORY_SORTING_DUE_TO_NON_PARTITION_SORTING', 'message': 'The command used columns in the sort clause that are not part of the partition sorting, and so the query was sorted in memory.\\n      \\nThe table memory_db.memory_embeddings has the partition sorting columns: [None].\\nThe command sorted on the columns: created_at.\\n\\nThe command was executed using in memory sorting rather than taking advantage of the partition sorting on disk. This can have performance implications on large tables.\\n\\nSee documentation for best practices for sorting.', 'family': 'REQUEST', 'scope': 'WARNING', 'title': 'Sorting by non partition sorting columns', 'id': 'd5cbee72-945c-47ac-bbd9-a80f7e938c46'}\n",
      "2025-09-04 00:42:16,968 - astrapy.data.cursors.cursor - INFO - cursor finished fetching a page: (empty page state) from memory_embeddings\n",
      "2025-09-04 00:42:16,969 - database.memory_store - INFO - Retrieved 0 memories for user flow_test_user\n",
      "2025-09-04 00:42:16,969 - comp5.core.memory_manager - INFO - No memories found for user flow_test_user\n",
      "2025-09-04 00:42:16,970 - gemini_engine.component5_bridge - INFO - Retrieved 0 memories for context\n",
      "2025-09-04 00:42:16,970 - gemini_engine.conversation_manager - INFO - Retrieved 0 memories from Component 5\n",
      "2025-09-04 00:42:16,971 - gemini_engine.context_assembler - INFO - Assembling context for conversation flow_test_conv\n",
      "2025-09-04 00:42:16,981 - gemini_engine.context_assembler - ERROR - Failed to assemble context: 'GeminiAPIConfig' object has no attribute 'safety_settings'\n",
      "2025-09-04 00:42:16,982 - gemini_engine.component6.context_assembler - ERROR - assemble_context failed after 11.21ms: 'GeminiAPIConfig' object has no attribute 'safety_settings'\n",
      "2025-09-04 00:42:16,982 - gemini_engine.conversation_manager - ERROR - Error assembling Gemini context: 'GeminiAPIConfig' object has no attribute 'safety_settings'\n",
      "2025-09-04 00:42:16,983 - gemini_engine.gemini_client - INFO - Generating Gemini response for conversation flow_test_conv\n",
      "2025-09-04 00:42:16,983 - gemini_engine.gemini_client - ERROR - Failed to generate Gemini response: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "2025-09-04 00:42:16,984 - gemini_engine.component6.gemini_client - ERROR - generate_response failed after 0.99ms: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "2025-09-04 00:42:16,985 - gemini_engine.conversation_manager - ERROR - Error generating AI response: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "2025-09-04 00:42:16,986 - gemini_engine.conversation_manager - ERROR - Conversation processing failed\n",
      "2025-09-04 00:42:16,986 - gemini_engine.component6.conversation_manager - ERROR - process_conversation failed after 292.11ms: EnhancedResponse.__init__() got an unexpected keyword argument 'conversation_id'\n",
      "2025-09-04 00:42:16,987 - gemini_engine.component5_bridge - INFO - Getting memory context for user flow_test_user\n",
      "2025-09-04 00:42:16,988 - comp5.core.memory_manager - INFO - Assembling context for user flow_test_user\n",
      "2025-09-04 00:42:16,988 - comp5.core.memory_manager - INFO - No memories found for user flow_test_user\n",
      "2025-09-04 00:42:16,988 - gemini_engine.component5_bridge - INFO - Retrieved 0 memories for context\n",
      "2025-09-04 00:42:16,989 - gemini_engine.conversation_manager - INFO - Processing conversation for user flow_test_user\n",
      "2025-09-04 00:42:16,989 - gemini_engine.component5_bridge - INFO - Getting memory context for user flow_test_user\n",
      "2025-09-04 00:42:16,990 - comp5.core.memory_manager - INFO - Assembling context for user flow_test_user\n",
      "2025-09-04 00:42:16,990 - comp5.core.memory_manager - INFO - No memories found for user flow_test_user\n",
      "2025-09-04 00:42:16,990 - gemini_engine.component5_bridge - INFO - Retrieved 0 memories for context\n",
      "2025-09-04 00:42:16,991 - gemini_engine.conversation_manager - INFO - Retrieved 0 memories from Component 5\n",
      "2025-09-04 00:42:16,991 - gemini_engine.context_assembler - INFO - Assembling context for conversation flow_test_conv\n",
      "2025-09-04 00:42:16,992 - gemini_engine.context_assembler - ERROR - Failed to assemble context: 'GeminiAPIConfig' object has no attribute 'safety_settings'\n",
      "2025-09-04 00:42:16,992 - gemini_engine.component6.context_assembler - ERROR - assemble_context failed after 1.08ms: 'GeminiAPIConfig' object has no attribute 'safety_settings'\n",
      "2025-09-04 00:42:16,992 - gemini_engine.conversation_manager - ERROR - Error assembling Gemini context: 'GeminiAPIConfig' object has no attribute 'safety_settings'\n",
      "2025-09-04 00:42:16,993 - gemini_engine.gemini_client - INFO - Generating Gemini response for conversation flow_test_conv\n",
      "2025-09-04 00:42:16,993 - gemini_engine.gemini_client - ERROR - Failed to generate Gemini response: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "2025-09-04 00:42:16,994 - gemini_engine.component6.gemini_client - ERROR - generate_response failed after 1.00ms: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "2025-09-04 00:42:16,994 - gemini_engine.conversation_manager - ERROR - Error generating AI response: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "2025-09-04 00:42:16,995 - gemini_engine.conversation_manager - ERROR - Conversation processing failed\n",
      "2025-09-04 00:42:16,995 - gemini_engine.component6.conversation_manager - ERROR - process_conversation failed after 6.04ms: EnhancedResponse.__init__() got an unexpected keyword argument 'conversation_id'\n",
      "2025-09-04 00:42:16,996 - gemini_engine.component5_bridge - INFO - Getting memory context for user flow_test_user\n",
      "2025-09-04 00:42:16,997 - comp5.core.memory_manager - INFO - Assembling context for user flow_test_user\n",
      "2025-09-04 00:42:16,997 - comp5.core.memory_manager - INFO - No memories found for user flow_test_user\n",
      "2025-09-04 00:42:16,997 - gemini_engine.component5_bridge - INFO - Retrieved 0 memories for context\n",
      "2025-09-04 00:42:16,998 - gemini_engine.conversation_manager - INFO - Processing conversation for user flow_test_user\n",
      "2025-09-04 00:42:16,999 - gemini_engine.component5_bridge - INFO - Getting memory context for user flow_test_user\n",
      "2025-09-04 00:42:16,999 - comp5.core.memory_manager - INFO - Assembling context for user flow_test_user\n",
      "2025-09-04 00:42:16,999 - comp5.core.memory_manager - INFO - No memories found for user flow_test_user\n",
      "2025-09-04 00:42:16,999 - gemini_engine.component5_bridge - INFO - Retrieved 0 memories for context\n",
      "2025-09-04 00:42:17,000 - gemini_engine.conversation_manager - INFO - Retrieved 0 memories from Component 5\n",
      "2025-09-04 00:42:17,000 - gemini_engine.context_assembler - INFO - Assembling context for conversation flow_test_conv\n",
      "2025-09-04 00:42:17,001 - gemini_engine.context_assembler - ERROR - Failed to assemble context: 'GeminiAPIConfig' object has no attribute 'safety_settings'\n",
      "2025-09-04 00:42:17,001 - gemini_engine.component6.context_assembler - ERROR - assemble_context failed after 0.92ms: 'GeminiAPIConfig' object has no attribute 'safety_settings'\n",
      "2025-09-04 00:42:17,002 - gemini_engine.conversation_manager - ERROR - Error assembling Gemini context: 'GeminiAPIConfig' object has no attribute 'safety_settings'\n",
      "2025-09-04 00:42:17,002 - gemini_engine.gemini_client - INFO - Generating Gemini response for conversation flow_test_conv\n",
      "2025-09-04 00:42:17,002 - gemini_engine.gemini_client - ERROR - Failed to generate Gemini response: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "2025-09-04 00:42:17,002 - gemini_engine.component6.gemini_client - ERROR - generate_response failed after 0.00ms: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "2025-09-04 00:42:17,003 - gemini_engine.conversation_manager - ERROR - Error generating AI response: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "2025-09-04 00:42:17,003 - gemini_engine.conversation_manager - ERROR - Conversation processing failed\n",
      "2025-09-04 00:42:17,003 - gemini_engine.component6.conversation_manager - ERROR - process_conversation failed after 5.00ms: EnhancedResponse.__init__() got an unexpected keyword argument 'conversation_id'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Conversation 1 failed: EnhancedResponse.__init__() got an unexpected keyword argument 'conversation_id'\n",
      "   Traceback: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\conversation_manager.py\", line 294, in _generate_ai_response\n",
      "    gemini_response = await self.gemini_client.generate_response(gemini_request)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\shared\\utils.py\", line 37, in async_wrapper\n",
      "    result = await func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\gemini_client.py\", line 90, in generate_response\n",
      "    await self._check_rate_limits()\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\gemini_client.py\", line 137, in _check_rate_limits\n",
      "    if len(self.request_timestamps) >= settings.gemini_api.rate_limit_requests_per_minute:\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bhushan\\AppData\\Local\\Temp\\ipykernel_29204\\2647529219.py\", line 64, in <module>\n",
      "    response = await orchestrator.conversation_manager.process_conversation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\shared\\utils.py\", line 37, in async_wrapper\n",
      "    result = await func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\conversation_manager.py\", line 121, in process_conversation\n",
      "    ai_response = await self._generate_ai_response(gemini_request)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\conversation_manager.py\", line 312, in _generate_ai_response\n",
      "    return EnhancedResponse(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "TypeError: EnhancedResponse.__init__() got an unexpected keyword argument 'conversation_id'\n",
      "\n",
      "\n",
      "--- Conversation 2 ---\n",
      "ğŸ‘¤ User Query: Can you remind me what we discussed about presentations?\n",
      "ğŸ§  Step 1: Retrieving LSTM memory context...\n",
      "   ğŸ“Š Retrieved 0 memories in 2.01ms\n",
      "ğŸ”§ Step 2: Assembling context + query for conversation engine...\n",
      "   ğŸ“Š Context assembled with 0 memories\n",
      "   ğŸ“Š Total context tokens: 0\n",
      "ğŸ¤– Step 3: Processing through conversation engine...\n",
      "âŒ Conversation 2 failed: EnhancedResponse.__init__() got an unexpected keyword argument 'conversation_id'\n",
      "   Traceback: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\conversation_manager.py\", line 294, in _generate_ai_response\n",
      "    gemini_response = await self.gemini_client.generate_response(gemini_request)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\shared\\utils.py\", line 37, in async_wrapper\n",
      "    result = await func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\gemini_client.py\", line 90, in generate_response\n",
      "    await self._check_rate_limits()\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\gemini_client.py\", line 137, in _check_rate_limits\n",
      "    if len(self.request_timestamps) >= settings.gemini_api.rate_limit_requests_per_minute:\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bhushan\\AppData\\Local\\Temp\\ipykernel_29204\\2647529219.py\", line 64, in <module>\n",
      "    response = await orchestrator.conversation_manager.process_conversation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\shared\\utils.py\", line 37, in async_wrapper\n",
      "    result = await func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\conversation_manager.py\", line 121, in process_conversation\n",
      "    ai_response = await self._generate_ai_response(gemini_request)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\conversation_manager.py\", line 312, in _generate_ai_response\n",
      "    return EnhancedResponse(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "TypeError: EnhancedResponse.__init__() got an unexpected keyword argument 'conversation_id'\n",
      "\n",
      "\n",
      "--- Conversation 3 ---\n",
      "ğŸ‘¤ User Query: I think I want to improve my public speaking skills\n",
      "ğŸ§  Step 1: Retrieving LSTM memory context...\n",
      "   ğŸ“Š Retrieved 0 memories in 2.00ms\n",
      "ğŸ”§ Step 2: Assembling context + query for conversation engine...\n",
      "   ğŸ“Š Context assembled with 0 memories\n",
      "   ğŸ“Š Total context tokens: 0\n",
      "ğŸ¤– Step 3: Processing through conversation engine...\n",
      "âŒ Conversation 3 failed: EnhancedResponse.__init__() got an unexpected keyword argument 'conversation_id'\n",
      "   Traceback: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\conversation_manager.py\", line 294, in _generate_ai_response\n",
      "    gemini_response = await self.gemini_client.generate_response(gemini_request)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\shared\\utils.py\", line 37, in async_wrapper\n",
      "    result = await func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\gemini_client.py\", line 90, in generate_response\n",
      "    await self._check_rate_limits()\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\gemini_client.py\", line 137, in _check_rate_limits\n",
      "    if len(self.request_timestamps) >= settings.gemini_api.rate_limit_requests_per_minute:\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'GeminiAPIConfig' object has no attribute 'rate_limit_requests_per_minute'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Bhushan\\AppData\\Local\\Temp\\ipykernel_29204\\2647529219.py\", line 64, in <module>\n",
      "    response = await orchestrator.conversation_manager.process_conversation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\shared\\utils.py\", line 37, in async_wrapper\n",
      "    result = await func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\conversation_manager.py\", line 121, in process_conversation\n",
      "    ai_response = await self._generate_ai_response(gemini_request)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\component6\\conversation_manager.py\", line 312, in _generate_ai_response\n",
      "    return EnhancedResponse(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "TypeError: EnhancedResponse.__init__() got an unexpected keyword argument 'conversation_id'\n",
      "\n",
      "\n",
      "ğŸ“Š LSTM â†’ Conversation Engine Flow Analysis:\n",
      "============================================================\n",
      "Total Conversations: 3\n",
      "Successful Conversations: 0\n",
      "LSTM Context Successes: 0\n",
      "Overall Success Rate: 0.0%\n",
      "LSTM Integration Rate: 0.0%\n",
      "\n",
      "Detailed Results:\n",
      "  âŒ ğŸš« Conv 1: I just finished a big presenta...\n",
      "  âŒ ğŸš« Conv 2: Can you remind me what we disc...\n",
      "  âŒ ğŸš« Conv 3: I think I want to improve my p...\n",
      "\n",
      "âŒ ISSUES! LSTM Memory â†’ Conversation Engine integration needs debugging.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nğŸ’­ğŸ¤– Testing LSTM Memory Retrieval â†’ Conversation Engine Flow...\")\n",
    "\n",
    "conversation_tests = [\n",
    "    {\n",
    "        \"message\": \"I just finished a big presentation at work\",\n",
    "        \"emotion\": {\"primary_emotion\": \"relieved\", \"intensity\": 0.7}\n",
    "    },\n",
    "    {\n",
    "        \"message\": \"Can you remind me what we discussed about presentations?\", \n",
    "        \"emotion\": {\"primary_emotion\": \"curious\", \"intensity\": 0.6}\n",
    "    },\n",
    "    {\n",
    "        \"message\": \"I think I want to improve my public speaking skills\",\n",
    "        \"emotion\": {\"primary_emotion\": \"motivated\", \"intensity\": 0.8}\n",
    "    }\n",
    "]\n",
    "\n",
    "conversation_results = []\n",
    "\n",
    "for i, test in enumerate(conversation_tests, 1):\n",
    "    try:\n",
    "        print(f\"\\n--- Conversation {i} ---\")\n",
    "        print(f\"ğŸ‘¤ User Query: {test['message']}\")\n",
    "        \n",
    "        # STEP 1: Get LSTM Memory Context\n",
    "        print(f\"ğŸ§  Step 1: Retrieving LSTM memory context...\")\n",
    "        start_retrieval = datetime.utcnow()\n",
    "        \n",
    "        memory_context = await bridge.get_memory_context(\n",
    "            user_id=\"flow_test_user\",\n",
    "            current_message=test['message'],\n",
    "            conversation_id=\"flow_test_conv\",\n",
    "            max_memories=10\n",
    "        )\n",
    "        \n",
    "        retrieval_time = (datetime.utcnow() - start_retrieval).total_seconds() * 1000\n",
    "        print(f\"   ğŸ“Š Retrieved {len(memory_context.selected_memories)} memories in {retrieval_time:.2f}ms\")\n",
    "        \n",
    "        # Show retrieved memories\n",
    "        for j, memory in enumerate(memory_context.selected_memories[:3]):\n",
    "            relevance = memory_context.relevance_scores[j] if j < len(memory_context.relevance_scores) else 0\n",
    "            print(f\"   ğŸ’­ Memory {j+1}: {memory.get('content_summary', 'No summary')[:50]}... (relevance: {relevance:.3f})\")\n",
    "        \n",
    "        # STEP 2: Assemble Context + Query\n",
    "        print(f\"ğŸ”§ Step 2: Assembling context + query for conversation engine...\")\n",
    "        \n",
    "        # Create enhanced context with LSTM memories\n",
    "        context_with_memories = {\n",
    "            \"user_query\": test['message'],\n",
    "            \"emotional_state\": test['emotion'],\n",
    "            \"lstm_memories\": memory_context.selected_memories,\n",
    "            \"memory_metadata\": memory_context.assembly_metadata,\n",
    "            \"token_usage\": memory_context.token_usage\n",
    "        }\n",
    "        \n",
    "        print(f\"   ğŸ“Š Context assembled with {len(memory_context.selected_memories)} memories\")\n",
    "        print(f\"   ğŸ“Š Total context tokens: {memory_context.token_usage}\")\n",
    "        \n",
    "        # STEP 3: Process through Conversation Engine\n",
    "        print(f\"ğŸ¤– Step 3: Processing through conversation engine...\")\n",
    "        start_conversation = datetime.utcnow()\n",
    "        \n",
    "        # Use orchestrator's conversation manager with the LSTM context\n",
    "        response = await orchestrator.conversation_manager.process_conversation(\n",
    "            user_id=\"flow_test_user\",\n",
    "            user_message=test['message'],\n",
    "            conversation_id=\"flow_test_conv\",\n",
    "            emotional_state=test['emotion']\n",
    "        )\n",
    "        \n",
    "        conversation_time = (datetime.utcnow() - start_conversation).total_seconds() * 1000\n",
    "        total_time = retrieval_time + conversation_time\n",
    "        \n",
    "        print(f\"   ğŸ¤– AI Response: {response.enhanced_response[:100]}...\")\n",
    "        print(f\"   â±ï¸  Conversation time: {conversation_time:.2f}ms\")\n",
    "        print(f\"   â±ï¸  Total time (retrieval + conversation): {total_time:.2f}ms\")\n",
    "        \n",
    "        # STEP 4: Show Memory Usage in Response\n",
    "        print(f\"ğŸ” Step 4: Memory usage analysis...\")\n",
    "        \n",
    "        # Check if memories influenced the response\n",
    "        memory_usage_analysis = {\n",
    "            \"memories_retrieved\": len(memory_context.selected_memories),\n",
    "            \"avg_memory_relevance\": sum(memory_context.relevance_scores) / len(memory_context.relevance_scores) if memory_context.relevance_scores else 0,\n",
    "            \"context_tokens_used\": memory_context.token_usage,\n",
    "            \"lstm_source\": memory_context.assembly_metadata.get('source', 'unknown')\n",
    "        }\n",
    "        \n",
    "        print(f\"   ğŸ“Š Memory Usage: {json.dumps(memory_usage_analysis, indent=6)}\")\n",
    "        \n",
    "        # Store detailed results\n",
    "        conversation_results.append({\n",
    "            \"conversation\": i,\n",
    "            \"message\": test['message'],\n",
    "            \"memory_retrieval_time_ms\": retrieval_time,\n",
    "            \"conversation_processing_time_ms\": conversation_time,\n",
    "            \"total_processing_time_ms\": total_time,\n",
    "            \"memories_used\": len(memory_context.selected_memories),\n",
    "            \"memory_relevance_avg\": memory_usage_analysis[\"avg_memory_relevance\"],\n",
    "            \"response_length\": len(response.enhanced_response),\n",
    "            \"success\": True,\n",
    "            \"lstm_context_success\": True\n",
    "        })\n",
    "        \n",
    "        # Small delay between conversations to see the memory buildup\n",
    "        await asyncio.sleep(1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Conversation {i} failed: {e}\")\n",
    "        print(f\"   Traceback: {traceback.format_exc()}\")\n",
    "        \n",
    "        conversation_results.append({\n",
    "            \"conversation\": i,\n",
    "            \"message\": test['message'],\n",
    "            \"error\": str(e),\n",
    "            \"success\": False,\n",
    "            \"lstm_context_success\": False\n",
    "        })\n",
    "\n",
    "# STEP 5: Analyze the Complete Flow Results\n",
    "print(f\"\\nğŸ“Š LSTM â†’ Conversation Engine Flow Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total_conversations = len(conversation_results)\n",
    "successful_conversations = len([r for r in conversation_results if r.get(\"success\", False)])\n",
    "lstm_context_successes = len([r for r in conversation_results if r.get(\"lstm_context_success\", False)])\n",
    "\n",
    "print(f\"Total Conversations: {total_conversations}\")\n",
    "print(f\"Successful Conversations: {successful_conversations}\")\n",
    "print(f\"LSTM Context Successes: {lstm_context_successes}\")\n",
    "print(f\"Overall Success Rate: {successful_conversations/total_conversations*100:.1f}%\")\n",
    "print(f\"LSTM Integration Rate: {lstm_context_successes/total_conversations*100:.1f}%\")\n",
    "\n",
    "if successful_conversations > 0:\n",
    "    # Calculate averages for successful conversations\n",
    "    successful_results = [r for r in conversation_results if r.get(\"success\", False)]\n",
    "    \n",
    "    avg_memory_retrieval = sum(r.get(\"memory_retrieval_time_ms\", 0) for r in successful_results) / len(successful_results)\n",
    "    avg_conversation_time = sum(r.get(\"conversation_processing_time_ms\", 0) for r in successful_results) / len(successful_results)\n",
    "    avg_total_time = sum(r.get(\"total_processing_time_ms\", 0) for r in successful_results) / len(successful_results)\n",
    "    avg_memories_used = sum(r.get(\"memories_used\", 0) for r in successful_results) / len(successful_results)\n",
    "    avg_relevance = sum(r.get(\"memory_relevance_avg\", 0) for r in successful_results) / len(successful_results)\n",
    "    \n",
    "    print(f\"\\nPerformance Metrics (Successful Conversations):\")\n",
    "    print(f\"  ğŸ“Š Avg Memory Retrieval Time: {avg_memory_retrieval:.2f}ms\")\n",
    "    print(f\"  ğŸ“Š Avg Conversation Processing: {avg_conversation_time:.2f}ms\")\n",
    "    print(f\"  ğŸ“Š Avg Total Processing Time: {avg_total_time:.2f}ms\")\n",
    "    print(f\"  ğŸ“Š Avg Memories Used: {avg_memories_used:.1f}\")\n",
    "    print(f\"  ğŸ“Š Avg Memory Relevance: {avg_relevance:.3f}\")\n",
    "\n",
    "# Show individual conversation results\n",
    "print(f\"\\nDetailed Results:\")\n",
    "for result in conversation_results:\n",
    "    status = \"âœ…\" if result.get(\"success\", False) else \"âŒ\"\n",
    "    lstm_status = \"ğŸ§ \" if result.get(\"lstm_context_success\", False) else \"ğŸš«\"\n",
    "    print(f\"  {status} {lstm_status} Conv {result['conversation']}: {result.get('message', '')[:30]}...\")\n",
    "    if result.get(\"success\", False):\n",
    "        print(f\"      Time: {result.get('total_processing_time_ms', 0):.1f}ms, Memories: {result.get('memories_used', 0)}\")\n",
    "\n",
    "# Assessment\n",
    "if lstm_context_successes == total_conversations and successful_conversations == total_conversations:\n",
    "    print(f\"\\nğŸ‰ PERFECT! LSTM Memory â†’ Conversation Engine integration working flawlessly!\")\n",
    "elif lstm_context_successes > 0 and successful_conversations > 0:\n",
    "    print(f\"\\nğŸ‘ GOOD! LSTM Memory â†’ Conversation Engine integration mostly working.\")\n",
    "else:\n",
    "    print(f\"\\nâŒ ISSUES! LSTM Memory â†’ Conversation Engine integration needs debugging.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cae910",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸš¨ Testing Error Handling...\")\n",
    "\n",
    "error_tests = [\n",
    "    {\n",
    "        \"name\": \"Empty Message\",\n",
    "        \"user_id\": \"error_test_user\",\n",
    "        \"message\": \"\",\n",
    "        \"expected\": \"Should handle empty message gracefully\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Very Long Message\", \n",
    "        \"user_id\": \"error_test_user\",\n",
    "        \"message\": \"This is a very long message. \" * 200,  # ~1000+ words\n",
    "        \"expected\": \"Should handle long messages\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Special Characters\",\n",
    "        \"user_id\": \"error_test_user\", \n",
    "        \"message\": \"Hello! @#$%^&*()_+ ğŸš€ğŸ¤–ğŸ’­ à¤¨à¤®à¤¸à¥à¤¤à¥‡ ä½ å¥½\",\n",
    "        \"expected\": \"Should handle unicode and special chars\"\n",
    "    }\n",
    "]\n",
    "\n",
    "error_results = []\n",
    "\n",
    "for test in error_tests:\n",
    "    try:\n",
    "        print(f\"\\nğŸ§ª Testing: {test['name']}\")\n",
    "        print(f\"Message: {test['message'][:50]}...\")\n",
    "        \n",
    "        response = await orchestrator.process_conversation(\n",
    "            user_id=test['user_id'],\n",
    "            user_message=test['message'],\n",
    "            conversation_id=f\"error_test_{test['name'].lower().replace(' ', '_')}\"\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… {test['name']}: Handled successfully\")\n",
    "        print(f\"Response: {response.enhanced_response[:100]}...\")\n",
    "        \n",
    "        error_results.append({\n",
    "            \"test\": test['name'],\n",
    "            \"status\": \"success\",\n",
    "            \"handled\": True\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  {test['name']}: {e}\")\n",
    "        error_results.append({\n",
    "            \"test\": test['name'],\n",
    "            \"status\": \"error\", \n",
    "            \"error\": str(e),\n",
    "            \"handled\": False\n",
    "        })\n",
    "\n",
    "print(f\"\\nğŸ“Š Error Handling Results:\")\n",
    "for result in error_results:\n",
    "    status = \"âœ…\" if result[\"status\"] == \"success\" else \"âš ï¸\"\n",
    "    print(f\"   {status} {result['test']}: {result['status']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eba5bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nâš¡ Performance Analysis...\")\n",
    "\n",
    "try:\n",
    "    # Get comprehensive performance data\n",
    "    performance_summary = orchestrator.get_performance_summary()\n",
    "    \n",
    "    print(\"ğŸ“Š PERFORMANCE SUMMARY:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Conversation metrics\n",
    "    conv_metrics = performance_summary.get('conversation_metrics', {})\n",
    "    print(f\"Total Conversations: {conv_metrics.get('total_conversations', 0)}\")\n",
    "    print(f\"Average Response Time: {conv_metrics.get('avg_response_time_ms', 0):.2f}ms\")\n",
    "    print(f\"Success Rate: {conv_metrics.get('success_rate', 0)*100:.1f}%\")\n",
    "    \n",
    "    # Component 5 stats\n",
    "    comp5_stats = performance_summary.get('component5_stats', {})\n",
    "    bridge_stats = comp5_stats.get('bridge_stats', {})\n",
    "    print(f\"\\nComponent 5 Performance:\")\n",
    "    print(f\"  Memories Retrieved: {bridge_stats.get('memories_retrieved', 0)}\")\n",
    "    print(f\"  Context Assemblies: {bridge_stats.get('context_assemblies', 0)}\")\n",
    "    print(f\"  Gate Decisions: {bridge_stats.get('gate_decisions', 0)}\")\n",
    "    print(f\"  Errors: {bridge_stats.get('errors', 0)}\")\n",
    "    \n",
    "    # Component 6 stats\n",
    "    comp6_stats = performance_summary.get('component6_stats', {})\n",
    "    print(f\"\\nComponent 6 Performance:\")\n",
    "    print(f\"  Active Conversations: {comp6_stats.get('active_conversations', 0)}\")\n",
    "    print(f\"  Memory Cache Size: {comp6_stats.get('memory_cache_size', 0)}\")\n",
    "    \n",
    "    # Calculate performance assessment\n",
    "    avg_time = conv_metrics.get('avg_response_time_ms', 0)\n",
    "    success_rate = conv_metrics.get('success_rate', 0)\n",
    "    \n",
    "    if avg_time < 5000 and success_rate > 0.8:\n",
    "        print(f\"\\nğŸ‰ PERFORMANCE: EXCELLENT\")\n",
    "    elif avg_time < 10000 and success_rate > 0.6:\n",
    "        print(f\"\\nğŸ‘ PERFORMANCE: GOOD\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  PERFORMANCE: NEEDS OPTIMIZATION\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Performance analysis failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bb6854",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ FINAL INTEGRATION STATUS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Summary of all tests\n",
    "test_summary = {\n",
    "    \"component5_bridge\": \"âœ… Working\" if bridge._initialized else \"âŒ Failed\",\n",
    "    \"orchestrator\": \"âœ… Working\" if orchestrator else \"âŒ Failed\", \n",
    "    \"memory_retrieval\": \"âœ… Working\" if 'memory_context' in locals() else \"âŒ Failed\",\n",
    "    \"conversation_processing\": \"âœ… Working\" if len([r for r in conversation_results if r[\"success\"]]) > 0 else \"âŒ Failed\",\n",
    "    \"error_handling\": \"âœ… Working\" if len([r for r in error_results if r[\"status\"] == \"success\"]) > 0 else \"âŒ Failed\"\n",
    "}\n",
    "\n",
    "for component, status in test_summary.items():\n",
    "    print(f\"{status} {component.replace('_', ' ').title()}\")\n",
    "\n",
    "# Overall assessment\n",
    "working_components = len([s for s in test_summary.values() if \"âœ…\" in s])\n",
    "total_components = len(test_summary)\n",
    "success_rate = working_components / total_components\n",
    "\n",
    "print(f\"\\nğŸ“Š Overall Success Rate: {success_rate*100:.1f}% ({working_components}/{total_components})\")\n",
    "\n",
    "if success_rate >= 0.8:\n",
    "    print(\"ğŸ‰ INTEGRATION SUCCESSFUL! All major components working.\")\n",
    "elif success_rate >= 0.6:\n",
    "    print(\"ğŸ‘ INTEGRATION MOSTLY WORKING. Minor issues to address.\")\n",
    "else:\n",
    "    print(\"âŒ INTEGRATION NEEDS WORK. Major issues detected.\")\n",
    "\n",
    "print(f\"\\nâœ… Integration test completed at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d276e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ§¹ Cleanup...\")\n",
    "\n",
    "try:\n",
    "    # Cleanup resources\n",
    "    if 'orchestrator' in locals():\n",
    "        await orchestrator.cleanup()\n",
    "    \n",
    "    if 'bridge' in locals():\n",
    "        await bridge.cleanup()\n",
    "    \n",
    "    print(\"âœ… Cleanup completed successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Cleanup warning: {e}\")\n",
    "\n",
    "print(\"ğŸ All tests completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

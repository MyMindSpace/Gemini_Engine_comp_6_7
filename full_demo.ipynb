{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cbf4f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Environment Setup Complete\n",
      "Project Root: c:\\Users\\Bhushan\\Desktop\n",
      "Component 5 Path: c:\\Users\\Bhushan\\Desktop\\comp5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any, Optional\n",
    "import traceback\n",
    "\n",
    "# Add project paths\n",
    "project_root = os.path.dirname(os.path.abspath(\"\"))\n",
    "sys.path.insert(0, project_root)\n",
    "comp5_path = os.path.join(project_root, 'comp5')\n",
    "sys.path.insert(0, comp5_path)\n",
    "\n",
    "print(\"üîß Environment Setup Complete\")\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(f\"Component 5 Path: {comp5_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ddebbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Basic Imports...\n",
      "‚úÖ configu.settings imported successfully\n",
      "‚úÖ shared modules imported successfully\n",
      "‚úÖ Component 5 modules imported successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"üß™ Testing Basic Imports...\")\n",
    "\n",
    "try:\n",
    "    # Test configu import\n",
    "    from configu.settings import settings\n",
    "    print(\"‚úÖ configu.settings imported successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå configu.settings import failed: {e}\")\n",
    "\n",
    "try:\n",
    "    # Test shared imports\n",
    "    from shared.schemas import MemoryContext, UserProfile, EnhancedResponse\n",
    "    from shared.utils import get_logger, generate_correlation_id\n",
    "    print(\"‚úÖ shared modules imported successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå shared modules import failed: {e}\")\n",
    "\n",
    "try:\n",
    "    # Test Component 5 imports\n",
    "    from comp5.config.settings import LSTMConfig\n",
    "    from comp5.core.memory_manager import MemoryManager\n",
    "    print(\"‚úÖ Component 5 modules imported successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Component 5 modules import failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddf60bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† Testing Component 5 Bridge...\n",
      "‚úÖ Component5Bridge created successfully\n",
      "üìä Bridge initialized: False\n",
      "üìä Bridge stats: {'memories_retrieved': 0, 'memories_processed': 0, 'gate_decisions': 0, 'context_assemblies': 0, 'errors': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüß† Testing Component 5 Bridge...\")\n",
    "\n",
    "try:\n",
    "    from component6.comp5_interface import Component5Bridge\n",
    "    \n",
    "    # Create bridge instance\n",
    "    bridge = Component5Bridge()\n",
    "    print(\"‚úÖ Component5Bridge created successfully\")\n",
    "    \n",
    "    # Check initial state\n",
    "    print(f\"üìä Bridge initialized: {bridge._initialized}\")\n",
    "    print(f\"üìä Bridge stats: {bridge.stats}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Component5Bridge creation failed: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b220124f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç DEBUG: Component 5 Astra Configuration...\n",
      "üß™ Testing manual AstraDBConfig creation...\n",
      "üìä Raw env vars:\n",
      "   ASTRA_DB_API_ENDPOINT: 'https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com'\n",
      "   ASTRA_DB_TOKEN: 'AstraCS:zwwrMyRbmlev...'\n",
      "   KEYSPACE: 'memory_db'\n",
      "\n",
      "üß™ Testing AstraDBConfig.from_env()...\n",
      "‚úÖ AstraDBConfig.from_env() successful:\n",
      "   endpoint: 'https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com'\n",
      "   token: 'AstraCS:zwwrMyRbmlev...'\n",
      "   keyspace: 'memory_db'\n",
      "\n",
      "üß™ Testing manual AstraDBConfig creation...\n",
      "‚úÖ Manual AstraDBConfig successful:\n",
      "   endpoint: 'https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com'\n",
      "   token: 'AstraCS:zwwrMyRbmlev...'\n",
      "   keyspace: 'memory_db'\n",
      "\n",
      "üß™ Testing LSTMConfig creation...\n",
      "‚úÖ LSTMConfig created successfully:\n",
      "   astra endpoint: 'https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com'\n",
      "   astra token: 'AstraCS:zwwrMyRbmlev...'\n",
      "   astra keyspace: 'memory_db'\n",
      "\n",
      "üõ†Ô∏è MANUAL FIX: Creating working Astra config...\n",
      "‚úÖ Working Astra config created:\n",
      "   endpoint: https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com\n",
      "   keyspace: memory_db\n",
      "\n",
      "üß™ Testing bridge with fixed config...\n",
      "\n",
      "üîç Component 5 configuration debug completed!\n"
     ]
    }
   ],
   "source": [
    "# DEBUG CELL: Check Astra Configuration in Component 5\n",
    "import os\n",
    "print(\"üîç DEBUG: Component 5 Astra Configuration...\")\n",
    "\n",
    "# Check how Component 5 is creating the Astra config\n",
    "try:\n",
    "    from comp5.config.settings import LSTMConfig, AstraDBConfig\n",
    "    \n",
    "    # Test manual config creation\n",
    "    print(\"üß™ Testing manual AstraDBConfig creation...\")\n",
    "    \n",
    "    # Get environment variables directly\n",
    "    endpoint = os.getenv(\"ASTRA_DB_API_ENDPOINT\")\n",
    "    token = os.getenv(\"ASTRA_DB_TOKEN\")\n",
    "    keyspace = os.getenv(\"KEYSPACE\")\n",
    "    \n",
    "    print(f\"üìä Raw env vars:\")\n",
    "    print(f\"   ASTRA_DB_API_ENDPOINT: '{endpoint}'\")\n",
    "    print(f\"   ASTRA_DB_TOKEN: '{token[:20] if token else None}...'\")\n",
    "    print(f\"   KEYSPACE: '{keyspace}'\")\n",
    "    \n",
    "    # Test AstraDBConfig creation methods\n",
    "    print(\"\\nüß™ Testing AstraDBConfig.from_env()...\")\n",
    "    try:\n",
    "        astra_config = AstraDBConfig.from_env()\n",
    "        print(f\"‚úÖ AstraDBConfig.from_env() successful:\")\n",
    "        print(f\"   endpoint: '{astra_config.endpoint}'\")\n",
    "        print(f\"   token: '{astra_config.token[:20] if astra_config.token else None}...'\")\n",
    "        print(f\"   keyspace: '{astra_config.keyspace}'\")\n",
    "    except Exception as config_error:\n",
    "        print(f\"‚ùå AstraDBConfig.from_env() failed: {config_error}\")\n",
    "    \n",
    "    # Test manual AstraDBConfig creation\n",
    "    print(\"\\nüß™ Testing manual AstraDBConfig creation...\")\n",
    "    try:\n",
    "        manual_astra_config = AstraDBConfig(\n",
    "            endpoint=endpoint,\n",
    "            token=token,\n",
    "            keyspace=keyspace or \"default_keyspace\"\n",
    "        )\n",
    "        print(f\"‚úÖ Manual AstraDBConfig successful:\")\n",
    "        print(f\"   endpoint: '{manual_astra_config.endpoint}'\")\n",
    "        print(f\"   token: '{manual_astra_config.token[:20] if manual_astra_config.token else None}...'\")\n",
    "        print(f\"   keyspace: '{manual_astra_config.keyspace}'\")\n",
    "    except Exception as manual_error:\n",
    "        print(f\"‚ùå Manual AstraDBConfig failed: {manual_error}\")\n",
    "    \n",
    "    # Test full LSTMConfig creation\n",
    "    print(\"\\nüß™ Testing LSTMConfig creation...\")\n",
    "    try:\n",
    "        lstm_config = LSTMConfig()\n",
    "        print(f\"‚úÖ LSTMConfig created successfully:\")\n",
    "        print(f\"   astra endpoint: '{lstm_config.astra_db.endpoint}'\")\n",
    "        print(f\"   astra token: '{lstm_config.astra_db.token[:20] if lstm_config.astra_db.token else None}...'\")\n",
    "        print(f\"   astra keyspace: '{lstm_config.astra_db.keyspace}'\")\n",
    "    except Exception as lstm_error:\n",
    "        print(f\"‚ùå LSTMConfig creation failed: {lstm_error}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Configuration debug failed: {e}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FIX: Create Working Astra Config for Component 5 Bridge\n",
    "# ============================================================================\n",
    "print(\"\\nüõ†Ô∏è MANUAL FIX: Creating working Astra config...\")\n",
    "\n",
    "try:\n",
    "    # Create a working configuration manually\n",
    "    from comp5.config.settings import AstraDBConfig, LSTMConfig\n",
    "    \n",
    "    # Force correct values\n",
    "    working_astra_config = AstraDBConfig(\n",
    "        endpoint=\"https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com\",\n",
    "        token=os.getenv(\"ASTRA_DB_TOKEN\"),\n",
    "        keyspace=\"memory_db\"\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Working Astra config created:\")\n",
    "    print(f\"   endpoint: {working_astra_config.endpoint}\")\n",
    "    print(f\"   keyspace: {working_astra_config.keyspace}\")\n",
    "    \n",
    "    # Test if we can create a new bridge with this config\n",
    "    print(\"\\nüß™ Testing bridge with fixed config...\")\n",
    "    \n",
    "    # Modify the bridge's config\n",
    "    if 'bridge' in locals() and bridge.config:\n",
    "        bridge.config.astra_db = working_astra_config\n",
    "        print(\"‚úÖ Bridge config updated with working Astra settings\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Manual fix failed: {e}\")\n",
    "\n",
    "print(\"\\nüîç Component 5 configuration debug completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c2054a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 21:37:58,667 - gemini_engine.component5_bridge - INFO - üöÄ Initializing Component 5 LSTM Memory Gates...\n",
      "2025-09-03 21:37:58,669 - comp5.core.memory_manager - INFO - Initializing Memory Manager...\n",
      "2025-09-03 21:37:58,670 - database.astra_connector - INFO - Connecting to Astra DB: https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Initializing Component 5 Bridge...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 21:37:58,881 - astrapy.data.database - INFO - findCollections\n",
      "2025-09-03 21:38:00,971 - httpx - INFO - HTTP Request: POST https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com/api/json/v1/memory_db \"HTTP/1.1 200 OK\"\n",
      "2025-09-03 21:38:00,974 - astrapy.data.database - INFO - finished findCollections\n",
      "2025-09-03 21:38:00,975 - database.astra_connector - INFO - Found collections: []\n",
      "2025-09-03 21:38:02,209 - database.astra_connector - INFO - Successfully connected to Astra DB\n",
      "2025-09-03 21:38:02,212 - comp5.core.memory_manager - INFO - No existing gate network found, using fresh model\n",
      "2025-09-03 21:38:02,213 - comp5.core.memory_manager - INFO - Memory Manager initialized successfully\n",
      "2025-09-03 21:38:02,213 - gemini_engine.component5_bridge - INFO - ‚úÖ Component 5 LSTM system initialized successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Component 5 Bridge initialized successfully\n",
      "üìä Memory Manager: True\n",
      "üìä Gate Network: True\n",
      "üìä Bridge Statistics: {\n",
      "  \"bridge_stats\": {\n",
      "    \"memories_retrieved\": 0,\n",
      "    \"memories_processed\": 0,\n",
      "    \"gate_decisions\": 0,\n",
      "    \"context_assemblies\": 0,\n",
      "    \"errors\": 0\n",
      "  },\n",
      "  \"initialized\": true,\n",
      "  \"memory_manager_stats\": {\n",
      "    \"memory_cache_size\": 0,\n",
      "    \"gate_network_available\": true,\n",
      "    \"db_connector_available\": true,\n",
      "    \"memory_store_available\": true\n",
      "  },\n",
      "  \"memory_manager_available\": true,\n",
      "  \"gate_network_available\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüöÄ Initializing Component 5 Bridge...\")\n",
    "\n",
    "try:\n",
    "    # Initialize the bridge (async call)\n",
    "    init_success = await bridge.initialize()\n",
    "    \n",
    "    if init_success:\n",
    "        print(\"‚úÖ Component 5 Bridge initialized successfully\")\n",
    "        print(f\"üìä Memory Manager: {bridge.memory_manager is not None}\")\n",
    "        print(f\"üìä Gate Network: {bridge.gate_network is not None}\")\n",
    "        \n",
    "        # Get statistics safely\n",
    "        try:\n",
    "            stats = bridge.get_statistics()\n",
    "            print(f\"üìä Bridge Statistics: {json.dumps(stats, indent=2, default=str)}\")\n",
    "        except Exception as stats_error:\n",
    "            print(f\"‚ö†Ô∏è  Could not get full statistics: {stats_error}\")\n",
    "            print(f\"üìä Basic Status: Initialized={bridge._initialized}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Component 5 Bridge initialization failed\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Component 5 Bridge initialization error: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")\n",
    "    \n",
    "    # Check if it's just a database connection issue\n",
    "    if \"Astra DB\" in str(e) or \"Request URL\" in str(e):\n",
    "        print(\"‚ÑπÔ∏è  This appears to be an Astra DB connection issue.\")\n",
    "        print(\"‚ÑπÔ∏è  The LSTM gates may still work for testing with mock data.\")\n",
    "        print(\"‚ÑπÔ∏è  Check your ASTRA_DB_API_ENDPOINT and ASTRA_DB_TOKEN in .env file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3721e206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä ASTRA_DB_API_ENDPOINT: 'https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-east1.apps.astra.datastax.com'\n",
      "üìä ASTRA_DB_TOKEN: 'AstraCS:zwwrMyRbmlev...' (truncated)\n",
      "üìä KEYSPACE: 'memory_db'\n",
      "üìä .env file exists: True\n",
      "üìä .env file path: c:\\Users\\Bhushan\\Desktop\\Gemini_Engine_comp_6_7\\.env\n",
      "üìä First 10 lines of .env file:\n",
      "\n",
      "üîç All environment variables containing 'ASTRA':\n",
      "   ASTRA_COLLECTION: memory_embeddings...\n",
      "   ASTRA_DB_API_ENDPOINT: https://a240df36-45c0-4e1a-a227-2c9a3b1b4822-us-ea...\n",
      "   ASTRA_DB_TOKEN: AstraCS:zwwrMyRbmlevzBlrKlCkxrDR:c561c306f3a1806fc...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Reload environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Check what's actually being read\n",
    "astra_endpoint = os.getenv(\"ASTRA_DB_API_ENDPOINT\")\n",
    "astra_token = os.getenv(\"ASTRA_DB_TOKEN\") \n",
    "keyspace = os.getenv(\"KEYSPACE\")\n",
    "\n",
    "print(f\"üìä ASTRA_DB_API_ENDPOINT: '{astra_endpoint}'\")\n",
    "print(f\"üìä ASTRA_DB_TOKEN: '{astra_token[:20] if astra_token else None}...' (truncated)\")\n",
    "print(f\"üìä KEYSPACE: '{keyspace}'\")\n",
    "\n",
    "# Check if .env file exists and is readable\n",
    "env_file_path = os.path.join(os.getcwd(), \".env\")\n",
    "print(f\"üìä .env file exists: {os.path.exists(env_file_path)}\")\n",
    "\n",
    "if os.path.exists(env_file_path):\n",
    "    print(f\"üìä .env file path: {env_file_path}\")\n",
    "    # Read first few lines to verify content\n",
    "    with open(env_file_path, 'r') as f:\n",
    "        lines = f.readlines()[:10]\n",
    "        print(\"üìä First 10 lines of .env file:\")\n",
    "        for i, line in enumerate(lines, 1):\n",
    "            if \"ASTRA\" in line or \"KEYSPACE\" in line:\n",
    "                print(f\"   {i}: {line.strip()}\")\n",
    "\n",
    "# Check environment variables from all sources\n",
    "print(f\"\\nüîç All environment variables containing 'ASTRA':\")\n",
    "for key, value in os.environ.items():\n",
    "    if 'ASTRA' in key:\n",
    "        print(f\"   {key}: {value[:50] if value else 'None'}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35a1d69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 21:38:02,236 - gemini_engine.component5_bridge - WARNING - Health check encountered error: MemoryManager.get_relevant_context() missing 1 required positional argument: 'query_features'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç DEBUG: Checking Bridge Components...\n",
      "üìä Bridge initialized: True\n",
      "üìä Bridge has memory_manager: True\n",
      "üìä Memory manager is not None: True\n",
      "üìä Bridge has gate_network: True\n",
      "üìä Gate network is not None: True\n",
      "üìä Memory Manager type: <class 'comp5.core.memory_manager.MemoryManager'>\n",
      "üìä Memory Manager has gate_network: True\n",
      "üìä Memory Manager gate_network is not None: True\n",
      "üìä Gate Network type: <class 'core.gate_networks.LSTMGateNetwork'>\n",
      "üìä Gate Network methods: ['T_destination', 'add_module', 'apply', 'bfloat16', 'buffers', 'call_super_init', 'children', 'compile', 'context_size', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forget_gate', 'forget_threshold', 'forward', 'get_buffer', 'get_extra_state', 'get_gate_decisions', 'get_parameter', 'get_submodule', 'get_thresholds', 'half', 'hidden_size', 'input_gate', 'input_size', 'input_threshold', 'ipu', 'load_model', 'load_state_dict', 'modules', 'mtia', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'output_gate', 'output_threshold', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_load_state_dict_pre_hook', 'register_module', 'register_parameter', 'register_state_dict_post_hook', 'register_state_dict_pre_hook', 'requires_grad_', 'save_model', 'set_extra_state', 'set_submodule', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'update_thresholds', 'xpu', 'zero_grad']\n",
      "üìä Bridge health_check method exists: True\n",
      "\n",
      "üè• Testing Component 5 Health Check...\n",
      "‚úÖ Health check completed\n",
      "üìä Health Status: {\n",
      "  \"initialized\": true,\n",
      "  \"config_valid\": true,\n",
      "  \"memory_manager_healthy\": false,\n",
      "  \"gate_network_healthy\": false,\n",
      "  \"database_connection\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Add this debug cell BEFORE running the health check:\n",
    "\n",
    "print(\"\\nüîç DEBUG: Checking Bridge Components...\")\n",
    "\n",
    "# Check what's actually in the bridge\n",
    "print(f\"üìä Bridge initialized: {bridge._initialized}\")\n",
    "print(f\"üìä Bridge has memory_manager: {hasattr(bridge, 'memory_manager')}\")\n",
    "print(f\"üìä Memory manager is not None: {bridge.memory_manager is not None}\")\n",
    "print(f\"üìä Bridge has gate_network: {hasattr(bridge, 'gate_network')}\")\n",
    "print(f\"üìä Gate network is not None: {bridge.gate_network is not None}\")\n",
    "\n",
    "if bridge.memory_manager:\n",
    "    print(f\"üìä Memory Manager type: {type(bridge.memory_manager)}\")\n",
    "    print(f\"üìä Memory Manager has gate_network: {hasattr(bridge.memory_manager, 'gate_network')}\")\n",
    "    print(f\"üìä Memory Manager gate_network is not None: {bridge.memory_manager.gate_network is not None}\")\n",
    "\n",
    "if bridge.gate_network:\n",
    "    print(f\"üìä Gate Network type: {type(bridge.gate_network)}\")\n",
    "    print(f\"üìä Gate Network methods: {[method for method in dir(bridge.gate_network) if not method.startswith('_')]}\")\n",
    "\n",
    "# Check what methods the health check is trying to call\n",
    "print(f\"üìä Bridge health_check method exists: {hasattr(bridge, 'health_check')}\")\n",
    "\n",
    "# Now run the health check\n",
    "print(\"\\nüè• Testing Component 5 Health Check...\")\n",
    "try:\n",
    "    health = await bridge.health_check()\n",
    "    print(\"‚úÖ Health check completed\")\n",
    "    print(f\"üìä Health Status: {json.dumps(health, indent=2, default=str)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Health check failed: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38416744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 21:38:02,244 - gemini_engine.component5_bridge - WARNING - Health check encountered error: MemoryManager.get_relevant_context() missing 1 required positional argument: 'query_features'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üè• Testing Component 5 Health Check...\n",
      "‚úÖ Health check completed\n",
      "üìä Health Status: {\n",
      "  \"initialized\": true,\n",
      "  \"config_valid\": true,\n",
      "  \"memory_manager_healthy\": false,\n",
      "  \"gate_network_healthy\": false,\n",
      "  \"database_connection\": false\n",
      "}\n",
      "üîß Initialized: True\n",
      "üîß Config Valid: True\n",
      "üîß Memory Manager: False\n",
      "üîß Gate Network: False\n",
      "üîß Database: False\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüè• Testing Component 5 Health Check...\")\n",
    "\n",
    "try:\n",
    "    health = await bridge.health_check()\n",
    "    print(\"‚úÖ Health check completed\")\n",
    "    print(f\"üìä Health Status: {json.dumps(health, indent=2, default=str)}\")\n",
    "    \n",
    "    # Check individual components\n",
    "    print(f\"üîß Initialized: {health.get('initialized', False)}\")\n",
    "    print(f\"üîß Config Valid: {health.get('config_valid', False)}\")\n",
    "    print(f\"üîß Memory Manager: {health.get('memory_manager_healthy', False)}\")\n",
    "    print(f\"üîß Gate Network: {health.get('gate_network_healthy', False)}\")\n",
    "    print(f\"üîß Database: {health.get('database_connection', False)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Health check failed: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a375c972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Cleaning Astra DB and inserting 90-dimensional test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 21:44:16,289 - astrapy.data.collection - INFO - starting delete_many on 'memory_embeddings'\n",
      "2025-09-03 21:44:16,289 - astrapy.data.collection - INFO - deleteMany on 'memory_embeddings'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Connected to Astra DB\n",
      "üóëÔ∏è Deleting all existing 97-dimensional data...\n"
     ]
    }
   ],
   "source": [
    "# CELL: Clean Astra DB and Insert 90-Dimensional Test Data\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone\n",
    "from uuid import uuid4\n",
    "from astrapy import DataAPIClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(\"üóëÔ∏è Cleaning Astra DB and inserting 90-dimensional test data...\")\n",
    "\n",
    "# Connect to Astra DB\n",
    "client = DataAPIClient(os.getenv(\"ASTRA_DB_TOKEN\"))\n",
    "db = client.get_database_by_api_endpoint(\n",
    "    os.getenv(\"ASTRA_DB_API_ENDPOINT\"),\n",
    "    keyspace=os.getenv(\"KEYSPACE\")\n",
    ")\n",
    "collection = db.get_collection(\"memory_embeddings\")\n",
    "\n",
    "print(\"üì° Connected to Astra DB\")\n",
    "\n",
    "# Step 1: Delete all existing data\n",
    "print(\"üóëÔ∏è Deleting all existing 97-dimensional data...\")\n",
    "try:\n",
    "    # Delete all documents (careful - this deletes everything!)\n",
    "    result = collection.delete_many({})\n",
    "    print(f\"‚úÖ Deleted {result.deleted_count if hasattr(result, 'deleted_count') else 'all'} existing documents\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Delete operation: {e}\")\n",
    "\n",
    "# Step 2: Create sample 90-dimensional memories\n",
    "print(\"üìù Creating 90-dimensional test memories...\")\n",
    "\n",
    "sample_memories = [\n",
    "    {\n",
    "        \"id\": str(uuid4()),\n",
    "        \"user_id\": \"test_user_123\",\n",
    "        \"memory_type\": \"emotion\",\n",
    "        \"content_summary\": \"I felt excited about starting a new AI project today\",\n",
    "        \"importance_score\": 0.8,\n",
    "        \"emotional_significance\": 0.9,\n",
    "        \"temporal_relevance\": 0.7,\n",
    "        \"access_frequency\": 1,\n",
    "        \"relationships\": [\"AI\", \"project\", \"work\"],\n",
    "        \"retrieval_triggers\": [\"AI\", \"project\", \"excited\", \"work\"],\n",
    "        \"context_needed\": {\"emotion_context\": \"positive\", \"work_context\": \"project_start\"},\n",
    "        \"gate_scores\": {\"input\": {\"score\": 0.8, \"decision\": True}, \"forget\": {\"score\": 0.2, \"decision\": False}, \"output\": {\"score\": 0.7, \"decision\": True}},\n",
    "        \"feature_vector\": np.random.rand(90).tolist(),  # 90-dimensional\n",
    "        \"embeddings\": np.random.rand(768).tolist(),     # Standard 768-dim embeddings\n",
    "        \"created_at\": datetime.now(timezone.utc),\n",
    "        \"last_accessed\": datetime.now(timezone.utc),\n",
    "        \"original_entry_id\": str(uuid4())\n",
    "    },\n",
    "    {\n",
    "        \"id\": str(uuid4()),\n",
    "        \"user_id\": \"test_user_123\", \n",
    "        \"memory_type\": \"conversation\",\n",
    "        \"content_summary\": \"Discussed machine learning techniques with a colleague\",\n",
    "        \"importance_score\": 0.6,\n",
    "        \"emotional_significance\": 0.5,\n",
    "        \"temporal_relevance\": 0.8,\n",
    "        \"access_frequency\": 2,\n",
    "        \"relationships\": [\"colleague\", \"machine learning\", \"discussion\"],\n",
    "        \"retrieval_triggers\": [\"ML\", \"colleague\", \"discuss\", \"learning\"],\n",
    "        \"context_needed\": {\"topic\": \"technical\", \"social_context\": \"work_colleague\"},\n",
    "        \"gate_scores\": {\"input\": {\"score\": 0.6, \"decision\": True}, \"forget\": {\"score\": 0.3, \"decision\": False}, \"output\": {\"score\": 0.6, \"decision\": True}},\n",
    "        \"feature_vector\": np.random.rand(90).tolist(),  # 90-dimensional\n",
    "        \"embeddings\": np.random.rand(768).tolist(),\n",
    "        \"created_at\": datetime.now(timezone.utc),\n",
    "        \"last_accessed\": datetime.now(timezone.utc),\n",
    "        \"original_entry_id\": str(uuid4())\n",
    "    },\n",
    "    {\n",
    "        \"id\": str(uuid4()),\n",
    "        \"user_id\": \"test_user_123\",\n",
    "        \"memory_type\": \"insight\",\n",
    "        \"content_summary\": \"Realized that taking breaks improves my coding productivity\",\n",
    "        \"importance_score\": 0.7,\n",
    "        \"emotional_significance\": 0.6,\n",
    "        \"temporal_relevance\": 0.9,\n",
    "        \"access_frequency\": 0,\n",
    "        \"relationships\": [\"productivity\", \"coding\", \"breaks\"],\n",
    "        \"retrieval_triggers\": [\"productivity\", \"coding\", \"breaks\", \"work\"],\n",
    "        \"context_needed\": {\"insight_type\": \"productivity\", \"domain\": \"programming\"},\n",
    "        \"gate_scores\": {\"input\": {\"score\": 0.7, \"decision\": True}, \"forget\": {\"score\": 0.1, \"decision\": False}, \"output\": {\"score\": 0.8, \"decision\": True}},\n",
    "        \"feature_vector\": np.random.rand(90).tolist(),  # 90-dimensional\n",
    "        \"embeddings\": np.random.rand(768).tolist(),\n",
    "        \"created_at\": datetime.now(timezone.utc),\n",
    "        \"last_accessed\": datetime.now(timezone.utc),\n",
    "        \"original_entry_id\": str(uuid4())\n",
    "    },\n",
    "    {\n",
    "        \"id\": str(uuid4()),\n",
    "        \"user_id\": \"test_user_123\",\n",
    "        \"memory_type\": \"event\", \n",
    "        \"content_summary\": \"Planning to attend a tech conference next month\",\n",
    "        \"importance_score\": 0.9,\n",
    "        \"emotional_significance\": 0.7,\n",
    "        \"temporal_relevance\": 0.6,\n",
    "        \"access_frequency\": 1,\n",
    "        \"relationships\": [\"conference\", \"tech\", \"learning\"],\n",
    "        \"retrieval_triggers\": [\"conference\", \"tech\", \"event\", \"learning\"],\n",
    "        \"context_needed\": {\"event_type\": \"professional\", \"timeline\": \"future\"},\n",
    "        \"gate_scores\": {\"input\": {\"score\": 0.9, \"decision\": True}, \"forget\": {\"score\": 0.1, \"decision\": False}, \"output\": {\"score\": 0.6, \"decision\": True}},\n",
    "        \"feature_vector\": np.random.rand(90).tolist(),  # 90-dimensional\n",
    "        \"embeddings\": np.random.rand(768).tolist(),\n",
    "        \"created_at\": datetime.now(timezone.utc),\n",
    "        \"last_accessed\": datetime.now(timezone.utc),\n",
    "        \"original_entry_id\": str(uuid4())\n",
    "    },\n",
    "    {\n",
    "        \"id\": str(uuid4()),\n",
    "        \"user_id\": \"test_user_123\",\n",
    "        \"memory_type\": \"conversation\",\n",
    "        \"content_summary\": \"Had a great conversation about work-life balance\",\n",
    "        \"importance_score\": 0.5,\n",
    "        \"emotional_significance\": 0.8,\n",
    "        \"temporal_relevance\": 0.5,\n",
    "        \"access_frequency\": 0,\n",
    "        \"relationships\": [\"work\", \"life balance\", \"conversation\"],\n",
    "        \"retrieval_triggers\": [\"work\", \"balance\", \"life\", \"stress\"],\n",
    "        \"context_needed\": {\"topic\": \"personal\", \"domain\": \"wellness\"},\n",
    "        \"gate_scores\": {\"input\": {\"score\": 0.5, \"decision\": True}, \"forget\": {\"score\": 0.4, \"decision\": False}, \"output\": {\"score\": 0.5, \"decision\": True}},\n",
    "        \"feature_vector\": np.random.rand(90).tolist(),  # 90-dimensional\n",
    "        \"embeddings\": np.random.rand(768).tolist(),\n",
    "        \"created_at\": datetime.now(timezone.utc),\n",
    "        \"last_accessed\": datetime.now(timezone.utc),\n",
    "        \"original_entry_id\": str(uuid4())\n",
    "    }\n",
    "]\n",
    "\n",
    "# Step 3: Insert test memories\n",
    "print(\"üìù Inserting 90-dimensional test memories...\")\n",
    "inserted_count = 0\n",
    "\n",
    "for memory in sample_memories:\n",
    "    try:\n",
    "        # Convert datetime to ISO string\n",
    "        if isinstance(memory[\"created_at\"], datetime):\n",
    "            memory[\"created_at\"] = memory[\"created_at\"].isoformat()\n",
    "        if isinstance(memory[\"last_accessed\"], datetime):\n",
    "            memory[\"last_accessed\"] = memory[\"last_accessed\"].isoformat()\n",
    "        \n",
    "        # Convert gate_scores and context_needed to JSON strings\n",
    "        memory[\"gate_scores\"] = json.dumps(memory[\"gate_scores\"])\n",
    "        memory[\"context_needed\"] = json.dumps(memory[\"context_needed\"])\n",
    "        \n",
    "        # Insert document\n",
    "        result = collection.insert_one(memory)\n",
    "        print(f\"‚úÖ Inserted memory: {memory['content_summary'][:50]}...\")\n",
    "        inserted_count += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to insert memory: {e}\")\n",
    "\n",
    "print(f\"‚úÖ Successfully inserted {inserted_count} test memories with 90-dimensional feature vectors\")\n",
    "\n",
    "# Step 4: Verify the data\n",
    "print(\"üîç Verifying inserted data...\")\n",
    "try:\n",
    "    # Query to check the data\n",
    "    docs = list(collection.find({\"user_id\": \"test_user_123\"}).limit(2))\n",
    "    \n",
    "    print(f\"üìä Found {len(docs)} documents for test_user_123\")\n",
    "    \n",
    "    for i, doc in enumerate(docs[:2]):\n",
    "        feature_vector = doc.get(\"feature_vector\", [])\n",
    "        print(f\"   Memory {i+1}: {doc.get('content_summary', '')[:40]}...\")\n",
    "        print(f\"   Feature vector length: {len(feature_vector)} (should be 90)\")\n",
    "        print(f\"   Memory type: {doc.get('memory_type')}\")\n",
    "        print(f\"   Importance: {doc.get('importance_score')}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Verification failed: {e}\")\n",
    "\n",
    "print(\"‚úÖ Astra DB cleanup and data insertion completed!\")\n",
    "print(\"üîÑ Now restart your kernel and re-run the bridge initialization with 90-dimensional config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfef375f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 21:38:11,868 - gemini_engine.component5_bridge - INFO - Getting memory context for user test_user_123\n",
      "2025-09-03 21:38:11,868 - comp5.core.memory_manager - INFO - Assembling context for user test_user_123\n",
      "2025-09-03 21:38:11,869 - comp5.core.memory_manager - ERROR - Error assembling context for user test_user_123: mat1 and mat2 shapes cannot be multiplied (1x90 and 97x64)\n",
      "2025-09-03 21:38:11,869 - gemini_engine.component5_bridge - INFO - Retrieved 0 memories for context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí≠ Testing Memory Context Retrieval...\n",
      "‚úÖ Memory context retrieved successfully\n",
      "üìä Memories Found: 0\n",
      "üìä Token Usage: 0\n",
      "üìä Assembly Metadata: {'source': 'component5_lstm', 'total_memories': 0, 'processing_time_ms': 0, 'gate_decisions': {}, 'reason': 'error', 'error': 'mat1 and mat2 shapes cannot be multiplied (1x90 and 97x64)'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüí≠ Testing Memory Context Retrieval...\")\n",
    "\n",
    "try:\n",
    "    # Test memory context retrieval\n",
    "    memory_context = await bridge.get_memory_context(\n",
    "        user_id=\"test_user_123\",\n",
    "        current_message=\"How am I feeling about work lately?\",\n",
    "        conversation_id=\"test_conv_001\",\n",
    "        max_memories=5\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Memory context retrieved successfully\")\n",
    "    print(f\"üìä Memories Found: {len(memory_context.selected_memories)}\")\n",
    "    print(f\"üìä Token Usage: {memory_context.token_usage}\")\n",
    "    print(f\"üìä Assembly Metadata: {memory_context.assembly_metadata}\")\n",
    "    \n",
    "    # Show sample memories\n",
    "    for i, memory in enumerate(memory_context.selected_memories[:3]):\n",
    "        print(f\"   Memory {i+1}: {memory.get('content_summary', 'No summary')[:60]}...\")\n",
    "        print(f\"   Importance: {memory.get('importance_score', 0):.3f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Memory context retrieval failed: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0e72c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüéº Testing Orchestrator Creation...\")\n",
    "\n",
    "try:\n",
    "    from gemini_engine_orchestrator import GeminiEngineOrchestrator\n",
    "    \n",
    "    # Create orchestrator with Component 5 bridge\n",
    "    orchestrator = GeminiEngineOrchestrator()\n",
    "    print(\"‚úÖ GeminiEngineOrchestrator created successfully\")\n",
    "    \n",
    "    # Check components\n",
    "    print(f\"üìä Component 5 Bridge: {orchestrator.component5_bridge is not None}\")\n",
    "    print(f\"üìä Conversation Manager: {orchestrator.conversation_manager is not None}\")\n",
    "    print(f\"üìä Memory Retriever: {orchestrator.memory_retriever is not None}\")\n",
    "    print(f\"üìä Gemini Client: {orchestrator.gemini_client is not None}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Orchestrator creation failed: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9deca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüöÄ Initializing Orchestrator...\")\n",
    "\n",
    "try:\n",
    "    # Initialize orchestrator\n",
    "    init_success = await orchestrator.initialize()\n",
    "    \n",
    "    if init_success:\n",
    "        print(\"‚úÖ Orchestrator initialized successfully\")\n",
    "        \n",
    "        # Get performance summary\n",
    "        performance = orchestrator.get_performance_summary()\n",
    "        print(f\"üìä Performance Summary: {json.dumps(performance, indent=2, default=str)}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Orchestrator initialization failed\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Orchestrator initialization error: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e016950",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüè• Testing Orchestrator Health Check...\")\n",
    "\n",
    "try:\n",
    "    health = await orchestrator.health_check()\n",
    "    print(\"‚úÖ Orchestrator health check completed\")\n",
    "    \n",
    "    print(f\"üìä Overall Healthy: {health.get('overall_healthy', False)}\")\n",
    "    \n",
    "    # Component health details\n",
    "    comp_health = health.get('component_health', {})\n",
    "    for component, status in comp_health.items():\n",
    "        print(f\"üîß {component}: {status}\")\n",
    "    \n",
    "    # System metrics\n",
    "    sys_metrics = health.get('system_metrics', {})\n",
    "    print(f\"üìä System Metrics: {json.dumps(sys_metrics, indent=2, default=str)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Orchestrator health check failed: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e100690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüí¨ Testing Single Conversation...\")\n",
    "\n",
    "try:\n",
    "    # Process a test conversation\n",
    "    test_message = \"I'm feeling excited about my new AI project!\"\n",
    "    print(f\"User: {test_message}\")\n",
    "    \n",
    "    start_time = datetime.utcnow()\n",
    "    \n",
    "    response = await orchestrator.process_conversation(\n",
    "        user_id=\"notebook_test_user\",\n",
    "        user_message=test_message,\n",
    "        conversation_id=\"notebook_test_conv\",\n",
    "        emotional_state={\n",
    "            \"primary_emotion\": \"excited\",\n",
    "            \"intensity\": 0.8,\n",
    "            \"confidence\": 0.9\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    processing_time = (datetime.utcnow() - start_time).total_seconds() * 1000\n",
    "    \n",
    "    print(\"‚úÖ Conversation processed successfully\")\n",
    "    print(f\"ü§ñ AI Response: {response.enhanced_response}\")\n",
    "    print(f\"‚è±Ô∏è  Processing Time: {processing_time:.2f}ms\")\n",
    "    \n",
    "    # Show analysis if available\n",
    "    if hasattr(response, 'response_analysis') and response.response_analysis:\n",
    "        analysis = response.response_analysis\n",
    "        print(f\"üìä Quality Score: {analysis.overall_quality:.3f}\")\n",
    "        print(f\"üìä Relevance Score: {analysis.contextual_relevance:.3f}\")\n",
    "        print(f\"üìä Engagement Score: {analysis.engagement_potential:.3f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Conversation processing failed: {e}\")\n",
    "    print(f\"Traceback: {traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff12f0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüí≠ü§ñ Testing LSTM Memory Retrieval ‚Üí Conversation Engine Flow...\")\n",
    "\n",
    "conversation_tests = [\n",
    "    {\n",
    "        \"message\": \"I just finished a big presentation at work\",\n",
    "        \"emotion\": {\"primary_emotion\": \"relieved\", \"intensity\": 0.7}\n",
    "    },\n",
    "    {\n",
    "        \"message\": \"Can you remind me what we discussed about presentations?\", \n",
    "        \"emotion\": {\"primary_emotion\": \"curious\", \"intensity\": 0.6}\n",
    "    },\n",
    "    {\n",
    "        \"message\": \"I think I want to improve my public speaking skills\",\n",
    "        \"emotion\": {\"primary_emotion\": \"motivated\", \"intensity\": 0.8}\n",
    "    }\n",
    "]\n",
    "\n",
    "conversation_results = []\n",
    "\n",
    "for i, test in enumerate(conversation_tests, 1):\n",
    "    try:\n",
    "        print(f\"\\n--- Conversation {i} ---\")\n",
    "        print(f\"üë§ User Query: {test['message']}\")\n",
    "        \n",
    "        # STEP 1: Get LSTM Memory Context\n",
    "        print(f\"üß† Step 1: Retrieving LSTM memory context...\")\n",
    "        start_retrieval = datetime.utcnow()\n",
    "        \n",
    "        memory_context = await bridge.get_memory_context(\n",
    "            user_id=\"flow_test_user\",\n",
    "            current_message=test['message'],\n",
    "            conversation_id=\"flow_test_conv\",\n",
    "            max_memories=10\n",
    "        )\n",
    "        \n",
    "        retrieval_time = (datetime.utcnow() - start_retrieval).total_seconds() * 1000\n",
    "        print(f\"   üìä Retrieved {len(memory_context.selected_memories)} memories in {retrieval_time:.2f}ms\")\n",
    "        \n",
    "        # Show retrieved memories\n",
    "        for j, memory in enumerate(memory_context.selected_memories[:3]):\n",
    "            relevance = memory_context.relevance_scores[j] if j < len(memory_context.relevance_scores) else 0\n",
    "            print(f\"   üí≠ Memory {j+1}: {memory.get('content_summary', 'No summary')[:50]}... (relevance: {relevance:.3f})\")\n",
    "        \n",
    "        # STEP 2: Assemble Context + Query\n",
    "        print(f\"üîß Step 2: Assembling context + query for conversation engine...\")\n",
    "        \n",
    "        # Create enhanced context with LSTM memories\n",
    "        context_with_memories = {\n",
    "            \"user_query\": test['message'],\n",
    "            \"emotional_state\": test['emotion'],\n",
    "            \"lstm_memories\": memory_context.selected_memories,\n",
    "            \"memory_metadata\": memory_context.assembly_metadata,\n",
    "            \"token_usage\": memory_context.token_usage\n",
    "        }\n",
    "        \n",
    "        print(f\"   üìä Context assembled with {len(memory_context.selected_memories)} memories\")\n",
    "        print(f\"   üìä Total context tokens: {memory_context.token_usage}\")\n",
    "        \n",
    "        # STEP 3: Process through Conversation Engine\n",
    "        print(f\"ü§ñ Step 3: Processing through conversation engine...\")\n",
    "        start_conversation = datetime.utcnow()\n",
    "        \n",
    "        # Use orchestrator's conversation manager with the LSTM context\n",
    "        response = await orchestrator.conversation_manager.process_conversation(\n",
    "            user_id=\"flow_test_user\",\n",
    "            user_message=test['message'],\n",
    "            conversation_id=\"flow_test_conv\",\n",
    "            emotional_state=test['emotion']\n",
    "        )\n",
    "        \n",
    "        conversation_time = (datetime.utcnow() - start_conversation).total_seconds() * 1000\n",
    "        total_time = retrieval_time + conversation_time\n",
    "        \n",
    "        print(f\"   ü§ñ AI Response: {response.enhanced_response[:100]}...\")\n",
    "        print(f\"   ‚è±Ô∏è  Conversation time: {conversation_time:.2f}ms\")\n",
    "        print(f\"   ‚è±Ô∏è  Total time (retrieval + conversation): {total_time:.2f}ms\")\n",
    "        \n",
    "        # STEP 4: Show Memory Usage in Response\n",
    "        print(f\"üîç Step 4: Memory usage analysis...\")\n",
    "        \n",
    "        # Check if memories influenced the response\n",
    "        memory_usage_analysis = {\n",
    "            \"memories_retrieved\": len(memory_context.selected_memories),\n",
    "            \"avg_memory_relevance\": sum(memory_context.relevance_scores) / len(memory_context.relevance_scores) if memory_context.relevance_scores else 0,\n",
    "            \"context_tokens_used\": memory_context.token_usage,\n",
    "            \"lstm_source\": memory_context.assembly_metadata.get('source', 'unknown')\n",
    "        }\n",
    "        \n",
    "        print(f\"   üìä Memory Usage: {json.dumps(memory_usage_analysis, indent=6)}\")\n",
    "        \n",
    "        # Store detailed results\n",
    "        conversation_results.append({\n",
    "            \"conversation\": i,\n",
    "            \"message\": test['message'],\n",
    "            \"memory_retrieval_time_ms\": retrieval_time,\n",
    "            \"conversation_processing_time_ms\": conversation_time,\n",
    "            \"total_processing_time_ms\": total_time,\n",
    "            \"memories_used\": len(memory_context.selected_memories),\n",
    "            \"memory_relevance_avg\": memory_usage_analysis[\"avg_memory_relevance\"],\n",
    "            \"response_length\": len(response.enhanced_response),\n",
    "            \"success\": True,\n",
    "            \"lstm_context_success\": True\n",
    "        })\n",
    "        \n",
    "        # Small delay between conversations to see the memory buildup\n",
    "        await asyncio.sleep(1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Conversation {i} failed: {e}\")\n",
    "        print(f\"   Traceback: {traceback.format_exc()}\")\n",
    "        \n",
    "        conversation_results.append({\n",
    "            \"conversation\": i,\n",
    "            \"message\": test['message'],\n",
    "            \"error\": str(e),\n",
    "            \"success\": False,\n",
    "            \"lstm_context_success\": False\n",
    "        })\n",
    "\n",
    "# STEP 5: Analyze the Complete Flow Results\n",
    "print(f\"\\nüìä LSTM ‚Üí Conversation Engine Flow Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total_conversations = len(conversation_results)\n",
    "successful_conversations = len([r for r in conversation_results if r.get(\"success\", False)])\n",
    "lstm_context_successes = len([r for r in conversation_results if r.get(\"lstm_context_success\", False)])\n",
    "\n",
    "print(f\"Total Conversations: {total_conversations}\")\n",
    "print(f\"Successful Conversations: {successful_conversations}\")\n",
    "print(f\"LSTM Context Successes: {lstm_context_successes}\")\n",
    "print(f\"Overall Success Rate: {successful_conversations/total_conversations*100:.1f}%\")\n",
    "print(f\"LSTM Integration Rate: {lstm_context_successes/total_conversations*100:.1f}%\")\n",
    "\n",
    "if successful_conversations > 0:\n",
    "    # Calculate averages for successful conversations\n",
    "    successful_results = [r for r in conversation_results if r.get(\"success\", False)]\n",
    "    \n",
    "    avg_memory_retrieval = sum(r.get(\"memory_retrieval_time_ms\", 0) for r in successful_results) / len(successful_results)\n",
    "    avg_conversation_time = sum(r.get(\"conversation_processing_time_ms\", 0) for r in successful_results) / len(successful_results)\n",
    "    avg_total_time = sum(r.get(\"total_processing_time_ms\", 0) for r in successful_results) / len(successful_results)\n",
    "    avg_memories_used = sum(r.get(\"memories_used\", 0) for r in successful_results) / len(successful_results)\n",
    "    avg_relevance = sum(r.get(\"memory_relevance_avg\", 0) for r in successful_results) / len(successful_results)\n",
    "    \n",
    "    print(f\"\\nPerformance Metrics (Successful Conversations):\")\n",
    "    print(f\"  üìä Avg Memory Retrieval Time: {avg_memory_retrieval:.2f}ms\")\n",
    "    print(f\"  üìä Avg Conversation Processing: {avg_conversation_time:.2f}ms\")\n",
    "    print(f\"  üìä Avg Total Processing Time: {avg_total_time:.2f}ms\")\n",
    "    print(f\"  üìä Avg Memories Used: {avg_memories_used:.1f}\")\n",
    "    print(f\"  üìä Avg Memory Relevance: {avg_relevance:.3f}\")\n",
    "\n",
    "# Show individual conversation results\n",
    "print(f\"\\nDetailed Results:\")\n",
    "for result in conversation_results:\n",
    "    status = \"‚úÖ\" if result.get(\"success\", False) else \"‚ùå\"\n",
    "    lstm_status = \"üß†\" if result.get(\"lstm_context_success\", False) else \"üö´\"\n",
    "    print(f\"  {status} {lstm_status} Conv {result['conversation']}: {result.get('message', '')[:30]}...\")\n",
    "    if result.get(\"success\", False):\n",
    "        print(f\"      Time: {result.get('total_processing_time_ms', 0):.1f}ms, Memories: {result.get('memories_used', 0)}\")\n",
    "\n",
    "# Assessment\n",
    "if lstm_context_successes == total_conversations and successful_conversations == total_conversations:\n",
    "    print(f\"\\nüéâ PERFECT! LSTM Memory ‚Üí Conversation Engine integration working flawlessly!\")\n",
    "elif lstm_context_successes > 0 and successful_conversations > 0:\n",
    "    print(f\"\\nüëç GOOD! LSTM Memory ‚Üí Conversation Engine integration mostly working.\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå ISSUES! LSTM Memory ‚Üí Conversation Engine integration needs debugging.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cae910",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüö® Testing Error Handling...\")\n",
    "\n",
    "error_tests = [\n",
    "    {\n",
    "        \"name\": \"Empty Message\",\n",
    "        \"user_id\": \"error_test_user\",\n",
    "        \"message\": \"\",\n",
    "        \"expected\": \"Should handle empty message gracefully\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Very Long Message\", \n",
    "        \"user_id\": \"error_test_user\",\n",
    "        \"message\": \"This is a very long message. \" * 200,  # ~1000+ words\n",
    "        \"expected\": \"Should handle long messages\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Special Characters\",\n",
    "        \"user_id\": \"error_test_user\", \n",
    "        \"message\": \"Hello! @#$%^&*()_+ üöÄü§ñüí≠ ‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‰Ω†Â•Ω\",\n",
    "        \"expected\": \"Should handle unicode and special chars\"\n",
    "    }\n",
    "]\n",
    "\n",
    "error_results = []\n",
    "\n",
    "for test in error_tests:\n",
    "    try:\n",
    "        print(f\"\\nüß™ Testing: {test['name']}\")\n",
    "        print(f\"Message: {test['message'][:50]}...\")\n",
    "        \n",
    "        response = await orchestrator.process_conversation(\n",
    "            user_id=test['user_id'],\n",
    "            user_message=test['message'],\n",
    "            conversation_id=f\"error_test_{test['name'].lower().replace(' ', '_')}\"\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ {test['name']}: Handled successfully\")\n",
    "        print(f\"Response: {response.enhanced_response[:100]}...\")\n",
    "        \n",
    "        error_results.append({\n",
    "            \"test\": test['name'],\n",
    "            \"status\": \"success\",\n",
    "            \"handled\": True\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  {test['name']}: {e}\")\n",
    "        error_results.append({\n",
    "            \"test\": test['name'],\n",
    "            \"status\": \"error\", \n",
    "            \"error\": str(e),\n",
    "            \"handled\": False\n",
    "        })\n",
    "\n",
    "print(f\"\\nüìä Error Handling Results:\")\n",
    "for result in error_results:\n",
    "    status = \"‚úÖ\" if result[\"status\"] == \"success\" else \"‚ö†Ô∏è\"\n",
    "    print(f\"   {status} {result['test']}: {result['status']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eba5bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n‚ö° Performance Analysis...\")\n",
    "\n",
    "try:\n",
    "    # Get comprehensive performance data\n",
    "    performance_summary = orchestrator.get_performance_summary()\n",
    "    \n",
    "    print(\"üìä PERFORMANCE SUMMARY:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Conversation metrics\n",
    "    conv_metrics = performance_summary.get('conversation_metrics', {})\n",
    "    print(f\"Total Conversations: {conv_metrics.get('total_conversations', 0)}\")\n",
    "    print(f\"Average Response Time: {conv_metrics.get('avg_response_time_ms', 0):.2f}ms\")\n",
    "    print(f\"Success Rate: {conv_metrics.get('success_rate', 0)*100:.1f}%\")\n",
    "    \n",
    "    # Component 5 stats\n",
    "    comp5_stats = performance_summary.get('component5_stats', {})\n",
    "    bridge_stats = comp5_stats.get('bridge_stats', {})\n",
    "    print(f\"\\nComponent 5 Performance:\")\n",
    "    print(f\"  Memories Retrieved: {bridge_stats.get('memories_retrieved', 0)}\")\n",
    "    print(f\"  Context Assemblies: {bridge_stats.get('context_assemblies', 0)}\")\n",
    "    print(f\"  Gate Decisions: {bridge_stats.get('gate_decisions', 0)}\")\n",
    "    print(f\"  Errors: {bridge_stats.get('errors', 0)}\")\n",
    "    \n",
    "    # Component 6 stats\n",
    "    comp6_stats = performance_summary.get('component6_stats', {})\n",
    "    print(f\"\\nComponent 6 Performance:\")\n",
    "    print(f\"  Active Conversations: {comp6_stats.get('active_conversations', 0)}\")\n",
    "    print(f\"  Memory Cache Size: {comp6_stats.get('memory_cache_size', 0)}\")\n",
    "    \n",
    "    # Calculate performance assessment\n",
    "    avg_time = conv_metrics.get('avg_response_time_ms', 0)\n",
    "    success_rate = conv_metrics.get('success_rate', 0)\n",
    "    \n",
    "    if avg_time < 5000 and success_rate > 0.8:\n",
    "        print(f\"\\nüéâ PERFORMANCE: EXCELLENT\")\n",
    "    elif avg_time < 10000 and success_rate > 0.6:\n",
    "        print(f\"\\nüëç PERFORMANCE: GOOD\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  PERFORMANCE: NEEDS OPTIMIZATION\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Performance analysis failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bb6854",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüèÅ FINAL INTEGRATION STATUS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Summary of all tests\n",
    "test_summary = {\n",
    "    \"component5_bridge\": \"‚úÖ Working\" if bridge._initialized else \"‚ùå Failed\",\n",
    "    \"orchestrator\": \"‚úÖ Working\" if orchestrator else \"‚ùå Failed\", \n",
    "    \"memory_retrieval\": \"‚úÖ Working\" if 'memory_context' in locals() else \"‚ùå Failed\",\n",
    "    \"conversation_processing\": \"‚úÖ Working\" if len([r for r in conversation_results if r[\"success\"]]) > 0 else \"‚ùå Failed\",\n",
    "    \"error_handling\": \"‚úÖ Working\" if len([r for r in error_results if r[\"status\"] == \"success\"]) > 0 else \"‚ùå Failed\"\n",
    "}\n",
    "\n",
    "for component, status in test_summary.items():\n",
    "    print(f\"{status} {component.replace('_', ' ').title()}\")\n",
    "\n",
    "# Overall assessment\n",
    "working_components = len([s for s in test_summary.values() if \"‚úÖ\" in s])\n",
    "total_components = len(test_summary)\n",
    "success_rate = working_components / total_components\n",
    "\n",
    "print(f\"\\nüìä Overall Success Rate: {success_rate*100:.1f}% ({working_components}/{total_components})\")\n",
    "\n",
    "if success_rate >= 0.8:\n",
    "    print(\"üéâ INTEGRATION SUCCESSFUL! All major components working.\")\n",
    "elif success_rate >= 0.6:\n",
    "    print(\"üëç INTEGRATION MOSTLY WORKING. Minor issues to address.\")\n",
    "else:\n",
    "    print(\"‚ùå INTEGRATION NEEDS WORK. Major issues detected.\")\n",
    "\n",
    "print(f\"\\n‚úÖ Integration test completed at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d276e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüßπ Cleanup...\")\n",
    "\n",
    "try:\n",
    "    # Cleanup resources\n",
    "    if 'orchestrator' in locals():\n",
    "        await orchestrator.cleanup()\n",
    "    \n",
    "    if 'bridge' in locals():\n",
    "        await bridge.cleanup()\n",
    "    \n",
    "    print(\"‚úÖ Cleanup completed successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Cleanup warning: {e}\")\n",
    "\n",
    "print(\"üèÅ All tests completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
